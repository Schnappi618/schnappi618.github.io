[{"title":"MySQL慢查询SQL触发阈值邮件报警","url":"/2020/08/10/DB/MySQL慢查询SQL触发阈值邮件报警/","content":"\n\n\n这个只是我自己的一个解决思路，如果有更恰当的思路，欢迎评论或私聊呀～\n\n## 一、项目背景\n\n业务数据库被异常调用时导致慢查询量增大，影响到正常业务使用，业务只能通过nginx超时异常等来进行问题排查，增大了定位和处理问题的难度、时间，尤其商品库或者交易库可能会出现页面无法正常显示的情况。故业务需求为若主库和从库慢查询总量每分钟超过某个阈值之后则发送邮件报警。\n\n## 二、开发逻辑问题及处理\n### 1、问题梳理\n1. 由于主库和从库在不同主机上，故不能开启pt-kill的`--log-dsn`参数将pt-kill结果写入数据库中，否则会出现主从数据不一致，从而导致主从异常中断\n2. pt-kill在哪台主机上执行，如果pt-kill在主库、从库本身机器上执行，会将文件写入到本地，pt-kill效率的确最高，但后续如何将文件汇总到一起；而且最终需要将日志文件作为附件发送邮件，线上机器无法到外网，所以还需要分别将文件传输到中控机等可以访问外网的机器上\n3. 对应数据库的主库、从库可能会由于实例均衡发生变动，若直接在对应主机上启动pt-kill，会出现异常情况，并且还需要代码变动\n4. pt-kill日志文件时间问题，本次需求为超过1分钟的数量触发到阈值之后发送邮件报警，若所有pt-kill结果都放入一个文件，这个文件会越来越大，不仅处理时间会越来越长，而且获取1分钟内的记录计算数量可能会存在漏掉或重复计算的情况\n5. 邮件内容如何发送，虽使用附件将pt-kill日志发送，但仍需要将统计内容作为邮件正文\n\n### 2、问题处理\n1. 直接在中控机上执行对应的pt-kill命令\n2. 使用pt-kill的`--log`参数直接将kill掉的记录写入到本地文件中\n3. 使用多进程每一分钟启动对应的pt-kill进程，并写入到对应文件中，日志文件命名为`角色_端口_主机区分_时间戳_slow.log`。例如：主库某个时间的文件名为：`m_3306_733_20200810114116_slow.log`，表示端口为3306的主库，在主机后两位为733上2020年8月10日11时41分16秒生成的kill日志文件\n4. pt-kill进程结束后使用子进程grep对应文件来获取慢SQL数量，并记录下来\n5. 由于为1min便有新的日志文件生成，时间久了之后数据量会特别大，还需要一个定时任务去清除日志文件。这里直接使用了crontab清除每10分钟清除30min之前的日志文件\n6. 邮件正文通过html写为表格，详细慢查询SQL直接通过附件发送\n\n## 三、逻辑流程梳理\n1. 持续使用percona提供的pt-kill工具kill对应数据库集群(主库+从库)的超过2s的慢查询并记录到日志文件中\n    1. 在管理库上获取对应集群的主库和从库主机名等信息\n    2. 使用合适的pt-kill参数将每分钟kill掉的慢SQL记录到文件中\n2. 获取主库和从库总共kill的慢SQL数量\n    1. 获取每个主库和从库日志文件所记录的kill慢SQL数量\n    2. 获取所有主机被kill的慢SQL总数\n3. 如果超过设定的阈值，则发送邮件报警\n    1. 判断是否超过设置阈值\n    2. 超过则发送邮件报警\n\n## 四、主要功能代码\n**由于markdown粘贴代码，缩进可能有部分问题，复制粘贴后需注意一下，并且这里取消了log模块，可将需要内容打印到使用的log中去**\n``` python\n# 公共函数\n## 1. 获取数据库连接\nfrom sqlalchemy import create_engine\ndef adminMySQLConn(User,Pass,Host,Port,DBName):\n        try:\n            adminConn=\"mysql+pymysql://{}:{}@{}:{}/{}?charset=utf8mb4\".\\\n                    format(User,Pass,Host,Port,DBName)\n            adminEngine = create_engine(adminConn)\n            return adminEngine\n\n        except Exception as err:\n            self.log.error(\"adminMySQLConn: {}\".format(err))\n            #self.log.error(\"adminMySQLConn: {}\".format(err.message))\n\n## 2. 获取当前时间戳\nfrom datetime import datetime\ndef initCurrentDateTime():\n        try:\n            return datetime.now().strftime('%Y%m%d%H%M%S')\n        except Exception as err:\n            self.log.error(\"initCurrentDateTime: {}\".format(err.message))\n\n## 3. 远程/本地执行linux命令(在本地执行可以直接使用os.system或subprocess.getstatusoutput，但由于这里是个公共函数，其他程序可能需要远程执行，故这里统一使用paramiko执行)\nfrom paramiko import SSHClient, AutoAddPolicy\ndef executeSSH(ip, cmds):\n    try:\n            client = SSHClient()\n            client.set_missing_host_key_policy(AutoAddPolicy())\n            system('kinit -kt /etc/krb5.keytab')\n            client.connect(ip, look_for_keys=False, gss_auth=True, gss_kex=True)\n            stdin, stdout, stderr = client.exec_command(cmds)\n            # result = stdout.readlines()       # 获取命令执行结果,返回的数据是一个list\n            _result = stdout.read().decode()  # 命令执行结果\n            _status = stdout.channel.recv_exit_status()  # 命令执行状态码\n            client.close()\n            return _status, _result\n        except Exception as e:\n            # print(e)\n            raise e\n```\n\n### 1、获取初始化信息\n由于这里存在一个管理库，上面有所有数据库的信息，则通过pymysql去查看并获取对应信息即可。\n``` python\n# 输入信息，即GetHost中的info\nInputinfo = {\"rsPort\": 3306'}\n```\n\n``` python\n# tb_mysql_instance为管理表，其中：rsPort为端口，rsHost为对应数据库所在主机，rsRole为数据库角色：master主库，slave从库\nSQLlist = {\n    \"getHost\": \"select rsHost, rsPort, rsRole from tb_mysql_instance where rsPort = {} and rsRole in ('master', 'slave');\"\n}\n\ndef GetHost(**info):\n    port = info['rsPort']\n    insInfoList = []\n    adminConn = adminMySQLConn()\n    try:\n        executeSQL = SQLlist['getHost'].format(port)\n        insList = adminConn.execute(executeSQL).fetchall()\n        if insList:\n            datetime = initCurrentDateTime()\n            for insInfo in insList:\n                infoDict = dict(zip(insInfo.keys(), insInfo.values()))\n                if infoDict['rsRole'] == 'master':\n                    infoDict['logFile'] = \"m_{}_{}_{}_slow.log\".format(infoDict['rsPort'],''.join(infoDict['rsHost'].split('.')[2:]) , datetime)\n                else:\n                    infoDict['logFile'] = \"s_{}_{}_{}_slow.log\".format(infoDict['rsPort'],''.join(infoDict['rsHost'].split('.')[2:]) , datetime)\n                infoDict['ptkillLogFile'] = \"./SlowLog/{}\".format(infoDict['logFile'])\n                insInfoList.append(infoDict)\n            msg = \"Get {} pt-kill master and slave host info success.\".format(port)\n            return True, insInfoList\n        else:\n            msg = \"Get {} pt-kill master and slave host info failed. SQL:{} insList: \".format(port, executeSQL), insList\n            return False, msg\n\n    except Exception as err:\n        msg = \"Get {} pt-kill master and slave host info err: \".format(port), err\n        return False, msg\n```\n``` python\n# 输出结果示例：\n[{'rsHost': '1.1.1.1', 'rsPort': 3306, 'rsRole': 'master', 'logFile': 'm_3306_11_20200810084828_slow.log', 'ptkillLogFile': '/path/SlowLog/m_3306_11_20200810084828_slow.log'}, {'rsHost': '2.2.2.2', 'rsPort': 3306, 'rsRole': 'slave', 'logFile': 's_3306_22_20200810084828_slow.log', 'ptkillLogFile': '/path/SlowLog/s_3306_22_20200810084828_slow.log'}, {'rsHost': '3.3.3.3', 'rsPort': 3306, 'rsRole': 'slave', 'logFile': 's_3306_33_20200810084828_slow.log', 'ptkillLogFile': '/path/SlowLog/s_3306_33_20200810084828_slow.log'}]\n```\n### 2、执行pt-kill并获取慢SQL数量\n``` python\n# 后面的info都一直表示获取初始化信息后的里面的字典格式\n# 例如：{'rsHost': '1.1.1.1', 'rsPort': 3306, 'rsRole': 'master', 'logFile': 'm_3306_11_20200810084828_slow.log', 'ptkillLogFile': '/path/SlowLog/m_3306_11_20200810084828_slow.log'}\n\n# 子函数\n## 执行pt-kill命令，pt-kill一次只执行60s\ndef ExecutePtkillCmd(**info):\n    try:\n        ptkillCmd = \"/opt/soft/percona-toolkit-2.2.14/bin/pt-kill --no-version-check \" \\\n                    \"--host {rsHost} --port {rsPort} --user 'dba' --password '5d63f33c10b8f430'\" \\\n                    \" --busy-time 2 --match-state='Sending data|Sorting result' --victim all \" \\\n                    \"--interval 1 --run-time 60 --daemonize  --kill --print --log={ptkillLogFile}\".format(**info)\n        status, ret = executeSSH('10.148.16.25', ptkillCmd)\n        if status == 0:\n            msg = \"Execute {rsHost}:{rsPort} pt-kill command success.\".format(**info)\n            return True, msg\n        else:\n            msg = \"Execute {rsHost}:{rsPort} pt-kill command failed, Cmd:\".format(**info), ptkillCmd\n            return False, msg\n    except Exception as err:\n        msg = \"Execute {rsHost}:{rsPort} pt-kill command error.\".format(**info), err\n        return False, msg\n\n## 获取慢SQL数量，并写入info中\ndef GetFileRegixCount(**info):\n    try:\n        logPwd = info['ptkillLogFile']\n        process = Popen(['grep', '^# [0-9]\\{4\\}-[0-9]\\{2\\}-[0-9]\\{2\\}', logPwd], stdout=PIPE)\n        info['slowSQLCount'] = len((process.stdout).readlines())\n        msg = \"Get {rsHost}:{rsPort} slow log count success.\".format(**info)\n        return True, info\n    except Exception as err:\n        msg = \"Get {rsHost}:{rsPort} slow log count err:\".format(**info), err\n        log.error(msg)\n        return False, msg\n### 输出info格式类似为：\n{'rsHost': '1.1.1.1', 'rsPort': 3306, 'rsRole': 'master', 'logFile': 'm_3306_11_20200810084828_slow.log', 'ptkillLogFile': '/path/SlowLog/m_3306_11_20200810084828_slow.log', 'slowSQLCount': 0}\n\n## 每60s触发一次pt-kill的执行\nfrom time import sleep\ndef killSlowSql(info):\n    try:\n        status, msg = ExecutePtkillCmd(**info)\n        if status is False:\n            return status, msg\n        sleep(60) \n        return GetFileRegixCount(**info)\n    except Exception as err:\n        msg = \"kill {rsHost}:{rsPort} {ptkillLogFile} err:\".format(**info), err\n        return False, msg\n\n## 多进程执行pt-kill\nfrom multiprocessing import Pool\ndef main(*HostInfoList):\n    try:\n        pool = Pool(8)\n        res_l = []\n        infoList = []\n        for info in HostInfoList:\n            base = pool.apply_async(killSlowSql, (info, ))\n            res_l.append(base)\n        pool.close()\n        pool.join()\n        for res in res_l:\n            ret = res.get()\n            infoList.append(ret[1])\n        return True, infoList\n    except Exception as err:\n        return False, err\n```\n### 3、邮件正文html表格\n由于python自带html表格样式有些许丑，所以参考[这个小姐姐的表格前端页面](https://blog.csdn.net/u012111465/article/details/82713561)来进行了修改。\n\n``` python\nimport pandas as pd\nhead = \\\n        \"\"\"\n        <head>\n            <meta charset=\"utf-8\">\n            <STYLE TYPE=\"text/css\" MEDIA=screen>\n\n                table.dataframe {\n                    border-collapse: collapse;\n                    border: 2px solid #a19da2;\n                    /*居中显示整个表格*/\n                    margin: auto;\n                }\n\n                table.dataframe thead {\n                    border: 2px solid #91c6e1;\n                    background: #f1f1f1;\n                    padding: 10px 10px 10px 10px;\n                    color: #333333;\n                }\n\n                table.dataframe tbody {\n                    border: 2px solid #91c6e1;\n                    padding: 10px 10px 10px 10px;\n                }\n\n                table.dataframe tr {\n\n                }\n\n                table.dataframe th {\n                    vertical-align: top;\n                    font-size: 14px;\n                    padding: 10px 10px 10px 10px;\n                    color: #105de3;\n                    font-family: arial;\n                    text-align: center;\n                }\n\n                table.dataframe td {\n                    text-align: center;\n                    padding: 10px 10px 10px 10px;\n                }\n\n                body {\n                    font-family: 宋体;\n                }\n\n                h1 {\n                    color: #5db446\n                }\n\n                div.header h2 {\n                    color: #0002e3;\n                    font-family: 黑体;\n                }\n\n                div.content h2 {\n                    text-align: center;\n                    font-size: 28px;\n                    text-shadow: 2px 2px 1px #de4040;\n                    color: #fff;\n                    font-weight: bold;\n                    background-color: #008eb7;\n                    line-height: 1.5;\n                    margin: 20px 0;\n                    box-shadow: 10px 10px 5px #888888;\n                    border-radius: 5px;\n                }\n\n                h3 {\n                    font-size: 22px;\n                    background-color: rgba(0, 2, 227, 0.71);\n                    text-shadow: 2px 2px 1px #de4040;\n                    color: rgba(239, 241, 234, 0.99);\n                    line-height: 1.5;\n                }\n\n                h4 {\n                    color: #e10092;\n                    font-family: 楷体;\n                    font-size: 20px;\n                    text-align: center;\n                }\n\n                td img {\n                    /*width: 60px;*/\n                    max-width: 300px;\n                    max-height: 300px;\n                }\n\n            </STYLE>\n        </head>\n        \"\"\"\n\n# 转换为表格需要的输入\n## 输入格式类似为result=[[1,2,3],['a','b','c']], title=['id', 'name']\ndef convert_to_html(result,title):\n    d = {}\n    index = 0\n    for t in title:\n        d[t] = result[index]\n        index +=1\n    df = pd.DataFrame(d)\n    #如数据过长，可能在表格中无法显示，加上pd.set_option语句可以避免这一情况\n    pd.set_option('max_colwidth',200)\n    pd.set_option('colheader_justify', 'center')\n    df = df [title]\n    #h =df.to_html(index=False)\n    h =df.to_html(col_space=30,border=1,justify='center')\n    h2 = h.replace('class', 'cellspacing=\\\"0\\\" class')\n    return h2\n\n# 初始化表格\ndef formatHtmlTable(result, title):\n    df_html = convert_to_html(result,title)\n    body = \\\n        \"\"\"\n        <body>\n\n        <div align=\"center\" class=\"header\">\n            <!--标题部分的信息-->\n            <h1 align=\"center\">慢查询SQL邮件报警</h1>\n            详情请查看附件\n<!--            <h2 align=\"center\">具体SQL详情请查看附件</h2> -->\n        </div>\n\n        <div class=\"content\">\n            <!--正文内容-->\n            <h2> </h2>\n\n            <div>\n                <h4></h4>\n                {df_html}\n\n            </div>\n\n            <p style=\"text-align: center\">\n\n            </p>\n        </div>\n        </body>\n        \"\"\".format(df_html=df_html)\n    html_msg = \"<html>\" + head + body + \"</html>\"\n    html_msg = html_msg.replace('\\n','').encode(\"utf-8\")\n    return html_msg\n```\n### 4、邮件发送\n```python \nimport smtplib\nfrom email.mime.text import MIMEText\nfrom email.header import Header\nfrom email.mime.multipart import MIMEMultipart\n## 发送邮件，username和password为发送人邮箱的用户名和密码。注意密码为smtp的授权码\ndef sendMail(sender, receivers, message):\n    try:\n        username = '''''''xxxx@qq.com'\n        password = 'xxxxxx\n        smtp = smtplib.SMTP(host='xxxx.qq.com', port=25)\n        smtp.login(username, password)\n        rdict = smtp.sendmail(sender, receivers, message.as_string())\n        smtp.quit()\n        msg = \"send mail success\"\n        return True, msg\n\n    except smtplib.SMTPException:\n        msg = \"send mail failed\"\n        return False, msg\n\n## 发送报警\ndef sendMailAlert(*infoList):\n    sender ='xxx@qq.com'        # 发送人邮箱\n    receivers = ['yy@163.com']  # 接收人邮箱列表，可写多个\n    message = MIMEMultipart()\n    message['From'] = Header(\"lichunliang\", 'utf-8')  # 发送者别名\n    message['To'] = Header(\"business_rds\", 'utf-8')  # 接收者别名\n    subject = '慢查询邮件告警测试'\n    message['Subject'] = Header(subject, 'utf-8')\n#    message.attach(MIMEText(mail_msg1, 'plain', 'utf-8'))\n    sumCount = 0\n    for info in infoList:\n        sumCount += info[\"slowSQLCount\"]\n    if sumCount > 5:\n        retList = []\n        title = ['rsPort', 'rsRole', 'logFile', 'slowSQLCount']\n        for t in title:\n            ret = []\n            [ret.append(info[t]) for info in infoList]\n            retList.append(ret)\n        for info in infoList:\n            ## 发送附件\n            att1 = MIMEText(open(info['ptkillLogFile'], 'rb').read(), 'base64', 'utf-8')\n            att1[\"Content-Type\"] = 'application/octet-stream'\n            att1[\"Content-Disposition\"] = 'attachment; filename={}'.format(info['ptkillLogFile'].split('/')[-1])\n            message.attach(att1)\n        html_msg = formatHtmlTable(retList,title)\n        message.attach(MIMEText(html_msg, 'html', 'utf-8'))\n        return sendMail(sender, receivers, message)\n    else:\n        log.info('Dont need sendmail.')\n```\n## 五、邮件报警效果\n\n<img src=\"MySQL%E6%85%A2%E6%9F%A5%E8%AF%A2SQL%E8%A7%A6%E5%8F%91%E9%98%88%E5%80%BC%E9%82%AE%E4%BB%B6%E6%8A%A5%E8%AD%A6/alert1.png\" style=\"zoom:67%;\" />","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL使用tokuDB引擎无法备份问题排查","url":"/2020/08/06/DB/MySQL使用tokuDB引擎无法备份问题排查/","content":"\n## 一、问题背景\n\n​\t之前线上和线下测试环境数据库仅允许为MyISAM和InnoDB引擎存在，但本次数据迁移中存在tokuDB引擎的库，一直使用percona提供的xtrabackup每天进行数据备份，innobackup自动恢复数据。但由于该情况并不支持tokuDB引擎的备份，故本次数据迁移生成的十几个集群备份全部无效，后面决定使用mydumper来进行备份恢复。\n\n## 二、备份方案及问题处理\n\n### 1、备份恢复流程\n\n​\t使用mydumper+myloader来进行tokuDB引擎库的备份恢复，简易备份恢复流程如下：\n\n1. 使用mydumper备份：`mydumper -h x.x.x.x -P port -u root -p xxxx -t 16 -e -c -o /path/to/backup`\n\n   使用16个线程对某主机上某个端口的数据库来进行压缩备份，备份到目录'/path/to/backup'中\n\n2. 创建一个和备份库同版本的数据库\n\n3. 使用myloader恢复：`myloader --user root --password xxxxxxxx --port 3487 --host 127.0.0.1 -C --directory /work/dba/backupDataPath/data --threads 8 --verbose 3 > load.log 2>&1`\n\n   由于备份时进行了压缩，故恢复时需要用-C参数来进行解压，并输出恢复日志load.log\n\n4. 创建主从关系：主从信息位于备份目录下的data/metadata文件中，文件内容大致如下：\n\n   ``` bash\n   ## 如果想让恢复库为备份主机的从库，则用metadata中show master status中的信息创建主从关系，此时master_host为备份机IP；\n   ## 若需要恢复库和备份机为同一个主库，则使用metadata中show slave status的信息创建主从关系即可。\n   Started dump at: 2020-08-03 02:37:02\n   SHOW MASTER STATUS:\n           Log: mysql-bin.000671\n           Pos: 16910\n           GTID:\n   \n   SHOW SLAVE STATUS:\n           Host: x.x.x.x\n           Log: mysql-bin.000668\n           Pos: 51101690\n           GTID:\n   \n   Finished dump at: 2020-08-03 04:05:38\n   \n   \n   ## 登陆数据库，执行\n   change master to = 'x.x.x.x',\n    master_port=xxxx, \n    master_user='xx'\n    master_password='xxxxxxxxxx',\n    master_log_file='mysql-bin.xxxxx',\n    mysql_log_pos=xxxxxxxxxx;\n   \n   ## 开启主从同步\n   start slave;\n   \n   ```\n\n### 2、问题处理\n\n#### 1. 开启主从时出现1062报错\n\n**1. 报错信息**\n\n``` sql\nroot@(none))>show slave status\\G\n*************************** 1. row ***************************\n               Slave_IO_State: Waiting for master to send event\n                  Master_Host: x.x.x.x\n                  Master_User: xx\n                  Master_Port: 3487\n                Connect_Retry: 60\n              Master_Log_File: mysql-bin.000783\n          Read_Master_Log_Pos: 360153174\n               Relay_Log_File: relay-log.000002\n                Relay_Log_Pos: 283\n        Relay_Master_Log_File: mysql-bin.000668\n             Slave_IO_Running: Yes\n            Slave_SQL_Running: No\n              Replicate_Do_DB: \n          Replicate_Ignore_DB: \n           Replicate_Do_Table: \n       Replicate_Ignore_Table: \n      Replicate_Wild_Do_Table: \n  Replicate_Wild_Ignore_Table: \n                   Last_Errno: 1062\n                   Last_Error: Error 'Duplicate entry '426922153' for key 'PRIMARY'' on query. \n```\n\n**2. 问题原因**\n\n本次出现该问题是由于在备份过程中原数据库有数据写入，导致数据冲突。故使用备份数据进行恢复时出现'Duplicate entry'报错。在网上查找解决方法时发现其他人出现这个问题是由于两个库有想同表名、想同表结构的表同时进行恢复，这个还未进行测试验证。\n\n**3. 解决方法**\n\nmydumper备份时添加`--lock-all-tables`参数，即强制在备份开始时开启`flush table with read lock;`，则在备份时该库无法写入数据，所有的更新操作都会被阻塞，从而强制获得一致性备份数据。由于所有备份都是在从库执行，所以写入阻塞没有很大影响，但数据量较大时会导致主从延迟出现。如果主库备份数据，还是使用mysqldump来进行备份比较稳妥。后面可以考虑用mysqlpump来实现所有备份操作。\n\n开启备份库的全日制可以看到，在备份开始时开启了FTWRL，备份完成后释放。\n\n![](MySQL%E4%BD%BF%E7%94%A8tokuDB%E5%BC%95%E6%93%8E%E6%97%A0%E6%B3%95%E5%A4%87%E4%BB%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/1.png)\n\n","tags":["MySQL","tokuDB"],"categories":["MySQL"]},{"title":"ClickHouse存储引擎之ReplacingMergeTree引擎","url":"/2020/07/28/clickhouse/存储引擎/ClickHouse存储引擎之ReplacingMergeTree引擎/","content":"\n## 一、ReplacingMergeTree作用\n\n​\tClickHouse中最常用也是最基础的表引擎为MergeTree，在它的功能基础上添加特定功能就构成了MergeTree系列引擎。MergeTree支持主键，但主键主要用来缩小查询范围，且不具备唯一性约束，可以正常写入相同主键的数据。但在一些情况下，可能需要表中没有主键重复的数据。ReplacingMergeTree就是在MergeTree的基础上加入了去重的功能，但它仅会在合并分区时，去删除重复的数据，写入相同数据时并不会引发异常。\n\n## 二、功能示例\n\n创建一张ReplacingMergeTree的表和创建MergeTree类似，修改引擎即可。ReplacingMergeTree引擎创建规范为：`ENGINE = ReplacingMergeTree([ver])`，其中ver为选填参数，它需要指定一个UInt8/UInt16、Date或DateTime类型的字段，它决定了数据去重时所用的算法，如果没有设置该参数，合并时保留分组内的最后一条数据；如果指定了该参数，则保留ver字段取值最大的那一行。\n\n### 1、不指定ver参数\n\n``` sql\n-- 创建未指定ver参数ReplacintMergeTree引擎的表\nCREATE TABLE replac_merge_test\n(\n    `id` String, \n    `code` String, \n    `create_time` DateTime\n)\nENGINE = ReplacingMergeTree()\nPARTITION BY toYYYYMM(create_time)\nPRIMARY KEY id\nORDER BY (id, code)\n```\n\n**ReplacingMergeTree会根据ORDER BY所声明的表达式去重**\n\n``` sql\n-- 在上述表中插入数据\ninsert into replac_merge_test values ('A000', 'code1', now()),('A000', 'code1', '2020-07-28 21:30:00'), ('A001', 'code1', now()), ('A001', 'code2', '2020-07-28 21:30:00'), ('A0002', 'code2', now());\n-- 查询当前数据\nselect * from replac_merge_test;\n┌─id────┬─code──┬─────────create_time─┐\n│ A000  │ code1 │ 2020-07-28 21:23:48 │\n│ A000  │ code1 │ 2020-07-28 21:30:00 │\n│ A0002 │ code2 │ 2020-07-28 21:23:48 │\n│ A001  │ code1 │ 2020-07-28 21:23:48 │\n│ A001  │ code2 │ 2020-07-28 21:30:00 │\n└───────┴───────┴─────────────────────┘\n\n-- 强制进行分区合并\noptimize table replac_merge_test FINAL;\n-- 再次查询数据\nselect * from replac_merge_test;\n┌─id────┬─code──┬─────────create_time─┐\n│ A000  │ code1 │ 2020-07-28 21:30:00 │\n│ A0002 │ code2 │ 2020-07-28 21:23:48 │\n│ A001  │ code1 │ 2020-07-28 21:23:48 │\n│ A001  │ code2 │ 2020-07-28 21:30:00 │\n└───────┴───────┴─────────────────────┘\n```\n\n通过上面示例可以看到，id、code相同的字段'A000','code1'被去重剩余一条数据，由于创建表时没有设置ver参数，故保留分组内的最后一条数据(create_time字段)\n\n``` sql\n-- 再次使用insert插入一条数据\ninsert into replac_merge_test values ('A001', 'code1', '2020-07-28 21:30:00');\n\n-- 查询表中数据\nselect * from replac_merge_test;\n┌─id────┬─code──┬─────────create_time─┐\n│ A000  │ code1 │ 2020-07-28 21:30:00 │\n│ A0002 │ code2 │ 2020-07-28 21:23:48 │\n│ A001  │ code1 │ 2020-07-28 21:23:48 │\n│ A001  │ code2 │ 2020-07-28 21:30:00 │\n└───────┴───────┴─────────────────────┘\n┌─id───┬─code──┬─────────create_time─┐\n│ A001 │ code1 │ 2020-07-28 21:30:00 │\n└──────┴───────┴─────────────────────┘\n```\n\n可以看到，再次插入重复数据时，查询仍然会存在重复。在ClickHouse中，默认一条insert插入的数据为同一个数据分区，不同insert插入的数据为不同的分区，所以ReplacingMergeTree是以分区为单位进行去重的，也就是说只有在相同的数据分区内，重复数据才可以被删除掉。只有数据合并完成后，才可以使用引擎特性进行去重。\n\n### 2、指定ver参数\n\n``` sql\n-- 创建指定ver参数ReplacingMergeTree引擎的表\nCREATE TABLE replac_merge_ver_test\n(\n    `id` String, \n    `code` String, \n    `create_time` DateTime\n)\nENGINE = ReplacingMergeTree(create_time)\nPARTITION BY toYYYYMM(create_time)\nPRIMARY KEY id\nORDER BY (id, code)\n\n-- 插入测试数据\ninsert into replac_merge_ver_test values('A000', 'code1', '2020-07-10 21:35:30'),('A000', 'code1', '2020-07-15 21:35:30'),('A000', 'code1', '2020-07-05 21:35:30'),('A000', 'code1', '2020-06-05 21:35:30');\n\n-- 查询数据\nselect * from replac_merge_ver_test;\n┌─id───┬─code──┬─────────create_time─┐\n│ A000 │ code1 │ 2020-06-05 21:35:30 │\n└──────┴───────┴─────────────────────┘\n┌─id───┬─code──┬─────────create_time─┐\n│ A000 │ code1 │ 2020-07-10 21:35:30 │\n│ A000 │ code1 │ 2020-07-15 21:35:30 │\n│ A000 │ code1 │ 2020-07-05 21:35:30 │\n└──────┴───────┴─────────────────────┘\n\n-- 强制进行分区合并\noptimize table replac_merge_ver_test FINAL;\n\n-- 查询数据\nselect * from replac_merge_ver_test;\n┌─id───┬─code──┬─────────create_time─┐\n│ A000 │ code1 │ 2020-07-15 21:35:30 │\n└──────┴───────┴─────────────────────┘\n┌─id───┬─code──┬─────────create_time─┐\n│ A000 │ code1 │ 2020-06-05 21:35:30 │\n└──────┴───────┴─────────────────────┘\n```\n\n由于上述创建表是以create_time的年月来进行分区的，可以看出不同的数据分区，ReplacingMergeTree并不会进行去重，并且在相同数据分区内，指定ver参数后，会保留同一组数据内create_time时间最大的那一行数据。\n\n## 三、ReplacingMergeTree引擎总结\n\n- 使用ORDER BY排序键，作为判断数据是否重复的唯一键\n- 只有在合并分区时，才会触发数据的去重逻辑\n- 删除重复数据，是以数据分区为单位。同一个数据分区的重复数据才会被删除，不同数据分区的重复数据仍会保留\n- 在进行数据去重时，由于已经基于ORDER BY排序，所以可以找到相邻的重复数据\n- 数据去重策略为：\n  - 若指定了ver参数，则会保留重复数据中，ver字段最大的那一行\n  - 若未指定ver参数，则会保留重复数据中最末的那一行数据","tags":["clickhouse","engine","MergeTree"],"categories":["clickhouse"]},{"title":"ClickHouse存储引擎之MergeTree引擎——数据TTL","url":"/2020/07/26/clickhouse/存储引擎/ClickHouse存储引擎之MergeTree引擎——数据TTL/","content":"\n## 一、数据TTL\n\n​\tTTL(Time to Live)，表示数据的存活时间。在MergeTree中，可以为某个列字段或整张表设置TTL时间。若为列字段的TTL，当时间到期时，则会删除这一列的数据；若为表级别的TTL，当时间到期时，则会删除整张表的数据；若一张表同时设置了列级别和表级别的TTL，则会以先到期的为主。\n\n​\t无论是列级别还是表级别的TTL，都需要依托于某个DateTime或Date类型的字段，通过对这个时间字段的INTERVAL操作，来描述TTL的过期时间，设置TTL过期时间的INTERVAL完整操作包括：SECOND、MINUTE、HOUR、DAY、WEEK、MONTH、QUARTER和YEAR。例如：\n\n``` sql\n-- 表示数据存活时间为，time_col时间的三天内\nTTL time_col + INTERVAL 3 DAY\n\n-- 表示数据存活时间为，time_col一月内\nTTL time_col + INTERVAL 1 MONTH\n```\n\n## 二、列级别TTL\n\n​\t若设置了列级别的TTL，当列字段中的值过期时，ClickHouse会将他们替换成默认值。如果一个分区内，某一列的所有值都已过期，那么ClickHouse会从文件系统中删除这个分区目录下的列文件。\n\n​\t如果想要设置列级别的TTL，需要在定义表字段的时候，为列声明TTL表达式，主键字段不能被声明成TTL。示例数据如下：\n\n``` sql\n-- 创建有TTL列的表结构\nCREATE TABLE ttl_table_t1\n(\n    `id` String, \n    `create_time` DateTime, \n    `code` String TTL create_time + toIntervalSecond(10), \n    `type` UInt8 TTL create_time + toIntervalSecond(10)\n)\nENGINE = MergeTree\nPARTITION BY toYYYYMM(create_time)\nORDER BY id\n\n-- 可以看到，create_time为日期类型，列字段code和type都被设置了TTL时间，他们存活时间，都为create_time建立后向后10s\n-- 写入测试数据\nINSERT INTO ttl_table_t1 VALUES('A000', now(), 'c1', 1), ('A000', now() + INTERVAL 2 MINUTE, 'c1', 2);\n\n-- 查看数据\nselect * from ttl_table_t1;\n┌─id───┬─────────create_time─┬─code─┬─type─┐\n│ A000 │ 2020-07-27 21:29:15 │ c1   │    1 │\n│ A000 │ 2020-07-27 21:31:15 │ c1   │    2 │\n└──────┴─────────────────────┴──────┴──────┘\n\n```\n\nClickHouse看到数据已经过期的时候，将执行合并，合并的频率由`merge_with_ttl_timeout`参数控制，`SETTINGS merge_with_ttl_timeout = 86400 `默认为86400s即1天，如果这个值太低，表示ClickHouse需要执行许多计划外的合并，可能消耗大量的资源。\n\n如果在ClickHouse合并期间进行查询，可能会获得过期的数据，所以在select查询之前可使用`optimize`命令强制触发TTL清理机制。\n\n``` sql\n-- 查看merge_with_ttl_timeout参数的值\nselect * from system.merge_tree_settings where name='merge_with_ttl_timeout';\n┌─name───────────────────┬─value─┬─changed─┬─description───────────────────────────────────────────────────┐\n│ merge_with_ttl_timeout │ 86400 │       0 │ Minimal time in seconds, when merge with TTL can be repeated. │\n└────────────────────────┴───────┴─────────┴───────────────────────────────────────────────────────────────┘\n\n-- 10s后强制触发TTL清理，FINAL表示触发所有分区合并，没有FINAL表示触发一个分区合并\noptimize TABLE ttl_table_t1 FINAL;\n\n-- 再次查看数据\n-- 可以看到由于第一行满足TTL过期条件，所以被还原为了列的默认值\nselect * from ttl_table_t1;\n┌─id───┬─────────create_time─┬─code─┬─type─┐\n│ A000 │ 2020-07-27 21:29:15 │      │    0 │\n│ A000 │ 2020-07-27 21:31:15 │ c1   │    2 │\n└──────┴─────────────────────┴──────┴──────┘\n```\n\n​\t如果需要修改列字段的TTL或为已有字段添加TTL，可使用ALTER语句设置：`ALTER TABLE ttl_table_t1 MODIFY COLUMN code STRING TTL create_time + INTERVAL 1 DAY`，目前**ClickHouse没有提供取消列级别TTL的方法。**\n\n## 三、表级别TTL\n\n​\t如果需要为整张表设置TTL过期时间，则需要在MergeTree的表参数重增加TTL表达式，例如：\n\n``` sql\nCREATE TABLE ttl_table_t2\n(\n    `id` String, \n    `create_time` DateTime, \n    `code` String TTL create_time + toIntervalSecond(10), \n    `type` UInt8 TTL create_time + toIntervalSecond(10)\n)\nENGINE = MergeTree\nPARTITION BY toYYYYMM(create_time)\nORDER BY id\nTTL create_time + INTERVAL 1 DAY\n```\n\n​\t上面示例中整张表都被设置了TTL，当触发到TTL清理时，满足过期时间的数据行将被整行删除。表级别的TTL也支持修改，同样适用ALTER语句：`ALTER TABLE ttl_table_t2 MODIFY TTL create_time + INTERVAL 3 DAY`，**同样，表级别的TTL目前也不支持删除。**\n\n``` sql\n-- 执行上述alter语句修改后表结构如下：\nclickhouse-server_1 :) desc ttl_table_t2\n\nDESCRIBE TABLE ttl_table_t2\n\n┌─name────────┬─type─────┬─default_type─┬─default_expression─┬─comment─┬─codec_expression─┬─ttl_expression─────────────────────┐\n│ id          │ String   │              │                    │         │                  │                                    │\n│ create_time │ DateTime │              │                    │         │                  │                                    │\n│ code        │ String   │              │                    │         │                  │ create_time + toIntervalSecond(10) │\n│ type        │ UInt8    │              │                    │         │                  │ create_time + toIntervalSecond(10) │\n└─────────────┴──────────┴──────────────┴────────────────────┴─────────┴──────────────────┴────────────────────────────────────┘\n\n```\n\n## 四、TTL的运行原理\n\n​\t当一张MergeTree表被设置了TTL表达式，在写入数据时，会以数据分区为单位，在每个分区目录内生成一个`ttl.txt`的文件，以上面的表ttl_table_t2为例，它既包含了列级别TTL，还包含了表级别的TTL。\n\n``` sql\n-- 向ttl_table_t2表插入数据\ninsert into ttl_table_t2 VALUES('A000', now(), 'haha', 2), ('A001', now(), 'xx', 2) ;\n\n-- 查询\nselect * from ttl_table_t2\n\n┌─id───┬─────────create_time─┬─code─┬─type─┐\n│ A000 │ 2020-07-28 14:28:23 │ haha │    2 │\n│ A001 │ 2020-07-28 14:28:23 │ xx   │    2 │\n└──────┴─────────────────────┴──────┴──────┘\n\n-- 由于这里插入了两条数据，所以会有两个分区目录\n[root@xxxx ttl_table_t2]# ll\ntotal 8\ndrwxr-x--- 2 101 101 4096 Jul 28 14:28 202007_1_1_0\ndrwxr-x--- 2 101 101  272 Jul 28 14:28 202007_1_1_1\ndrwxr-x--- 2 101 101   10 Jul 28 14:28 detached\n-rw-r----- 1 101 101    1 Jul 28 14:28 format_version.txt\n```\n\n​\t在写入数据后，每个分区目录内都会生成ttl.txt文件：\n\n``` bash\n## tree查看当前分区目录结构,用202007_1_1_0分区为例\ntree ./202007_1_1_0\n.\n├── checksums.txt\n├── code.bin\n├── code.mrk2\n├── columns.txt\n├── count.txt\n├── create_time.bin\n├── create_time.mrk2\n├── id.bin\n├── id.mrk2\n├── minmax_create_time.idx\n├── partition.dat\n├── primary.idx\n├── ttl.txt\n├── type.bin\n└── type.mrk2\n\n## 查看ttl.txt信息\ncat ttl.txt \nttl format version: 1\n{\"columns\":[{\"name\":\"code\",\"min\":1595917713,\"max\":1595917713},{\"name\":\"type\",\"min\":1595917713,\"max\":1595917713}],\"table\":{\"min\":1596004103,\"max\":1596004103}}\n\n```\n\n​\t通过ttl.txt内容可以发现，MergeTree时通过一串JSON配置保存了ttl的相关信息，其中：\n\n- columns：用于保存列级别ttl的信息\n- table：用于表示表级别ttl的信息\n- min和max：保存了当前数据分区内，TTL指定日期字段的最小值、最大值分别与INVERTAL表达式计算后的时间戳。\n\n将table属性中的min和max时间戳格式化，并分别和create_time最小值与最大值对比：\n\n``` sql\nSELECT \n    toDateTime('1596004103') AS ttl_min, \n    toDateTime('1596004103') AS ttl_max, \n    ttl_min - MIN(create_time) AS expire_min, \n    ttl_max - MAX(create_time) AS expire_max\nFROM ttl_table_t2\n\n┌─────────────ttl_min─┬─────────────ttl_max─┬─expire_min─┬─expire_max─┐\n│ 2020-07-29 14:28:23 │ 2020-07-29 14:28:23 │      86400 │      86400 │\n└─────────────────────┴─────────────────────┴────────────┴────────────┘\n\n```\n\n****\n\n**TTL的处理逻辑：**\n\n- MergeTree以分区目录为单位，通过分区内的ttl.txt文件记录过期时间，并最为后续的判断依据\n- 当写入一批数据时，都会给予INTERVAL表达式的计算结果为这个分区生成对应的ttl.txt文件\n- 在MergeTree进行合并分区时，会触发删除TTL过期数据的逻辑\n- 在选择删除的分区时，使用了贪婪算法：尽可能找到会最早过期，合并次数最多的分区(MaxBlockNum)最大\n- 如果一个分区内某一列数据因为TTL到期被全部删除，在合并之后的新分区目录中，不会包含这个列字段的数据文件(column.bin和column.mrk)\n\n\n\nClickHouse针对列级别和表级别的TTL目前都没有提供删除TTL策略的方法，仅提供了全局开启/关闭TTL的方法：`SYSTEM START/STOP TTL MERGES;`，而且该配置并不能指定某张表开启或关闭TTL。","tags":["clickhouse","engine","MergeTree"],"categories":["clickhouse"]},{"title":"ClickHouse存储引擎之MergeTree引擎——数据标记","url":"/2020/07/20/clickhouse/存储引擎/ClickHouse存储引擎之MergeTree引擎——数据标记/","content":"\n## 一、数据标记文件的作用\n\n​\t在MergeTree中，保存数据的物理文件包括索引文件primary.idx、column.bin数据文件和column.mrk数据标记文件(若使用了自适应大小的索引间隔，则标记文件会为column.mrk2)，这三种文件帮助人们快速找到需要的数据。如果把MergeTree看为一本书，primary.idx一级索引文件类似于书的一级章节目录，column.bin文件中的数据类似书中具体的文字，而数据标记文件则将一级章节目录和具体文字关联起来。\n\n​\t对于数据标记而言，它记录了两个信息：一是一级章节对应的页码信息；二是对应的文字在某一页中的起始位置信息。通过数据标记文件就可以很快的翻到关注内容所在的页，并知道从第几行开始阅读。\n\n## 二、数据标记的生成规则\n\n​\t数据标记文件、一级索引的对应关系大致如下：\n\n<img src=\"ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMergeTree%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%A0%87%E8%AE%B0/biaoji_1.svg\" style=\"zoom:70%;\" />\n\n​\t从上图可以看出列数据标记和索引区间是对齐的，都按照index_granularity(默认8192)索引粒度间隔，故通过索引区间的下标编号就可以直接找到对应的数据标记。\n\n​\t数据标记文件也和column.bin文件一一对应，每一个列字段都有一个对应的column.mrk数据标记文件，用于记录数据在column.bin文件中的偏移量信息。一行标记数据用一个元组表示，元组内包含了两个整型数值的偏移量信息：某段数据区间内，对应的column.bin压缩文件中，压缩数据块的起始偏移量；未压缩数据的起始偏移量。对应关系如下表所示：\n\n| 编号 | 压缩文件中的偏移量 | 解压缩块中的偏移量 |\n| ---- | ------------------ | ------------------ |\n| 0    | 0                  | 0                  |\n| 1    | 0                  | 8192               |\n| 2    | 0                  | 16384              |\n| 3    | 0                  | 24576              |\n| 4    | 0                  | 32768              |\n| 5    | 0                  | 40960              |\n| 6    | 0                  | 49152              |\n| 7    | 0                  | 57344              |\n| 8    | 12016              | 0                  |\n| 9    | 12016              | 8192               |\n\n​\t这里使用了之前MergeTree引擎——数据存储中的示例数据，可以看到在示例数据中，第0个压缩块的大小是12000，而在上表中对应的第0个压缩数据块的截止偏移量是12016，在数据存储的文章中我们知道，压缩数据块包含了压缩数据和头信息，并且为了让读取粒度进一步精确到压缩数据块，加载数据还包含了下一个压缩数据块的头文件，一个压缩数据块的头信息固定由9个字节组成，压缩后大小为8字节，所以这里截止偏移量就为8+12000+8=12016.\n\n​\t由表中还可以看出，每一行标记数据都表示了一个片段的数据(默认8192行)在column.bin压缩文件中的读取位置信息。标记数据和一级索引数据不同，它不能常驻于内存中，clickhouse使用了LRU(最近最少使用)缓存策略加快其获取速度。\n\n## 三、数据标记的工作方式\n\n​\tMergeTree读取数据时，需要通过标记数据的位置信息再找到需要的数据，整个查找过程大致分为读取压缩数据块和读取数据两个步骤\n\n<img src=\"ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMergeTree%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%A0%87%E8%AE%B0/biaoji2.jpg\" style=\"zoom:67%;\" />\n\n​\t上图为ClickHouse官方提供的hits_v1测试表中，JavaEnable字段标记文件和压缩数据文件的对应关系示例。由于测试表中JavaEnable字段的数据类型为UInt8，该列每行数据大小为1字节，hits_v1表的索引粒度index_granularity为8192，所以一个索引片段的数据大小为8192字节。按照压缩数据块的生成规则，当数据大小在64KB～1MB之间时，生成一个压缩数据块(64K=65536字节，65536/5192=8)，所以在该JavaEnable的标记文件中，每8行标记数据对应一个压缩数据块，故从图中可以看到，在标记文件中，压缩文件中8行数据的偏移量相同，这8行标记指向了同一个压缩数据块。由于每一个片段的数据大小都为8192字节，所以解压缩块中每8行的偏移量都按照8192的大小递增，到第9行时，又会置为0，这是由于从这里开始，又生成了下一个压缩数据块。\n\n**MergeTree定位压缩数据块并读取数据：**\n\n1. 读取压缩数据块\n\n   在查询某一列数据时，MergeTree不需要一次性加载所有column.bin文件，而可以根据需要，借助标记文件中保存的压缩数据偏移量只加载特定的数据块。\n\n   在上图示例中，上下相邻两个压缩文件的起始偏移量，构成了获取当前标记对应压缩块的偏移量区间。由当前标记数据开始，向下找到不同的压缩文件偏移量为止，此时获得的一组偏移量区间，就是压缩数据块在column.bin数据文件中的偏移量。例如在上图中，读取.bin文件中[0, 12016]字节数据，就能得到第0个压缩数据块的数据。\n\n2. 读取数据\n\n   在读取数据时，MergeTree也可以根据需要借助标记文件中保存的解压缩块中的偏移量，以index_granularity的索引粒度加载特定的一小段。标记数据中，上下相邻的两个解压缩块中的偏移起始量，构成了获取当前标记对应数据的偏移量区间。通过这个区间，能在它的压缩块解压之后，按照偏移量按需读取数据。例如，在图中，通过[0, 8192]便能够读取压缩块0中的第一个数据片段。","tags":["clickhouse","engine","MergeTree"],"categories":["clickhouse"]},{"title":"ClickHouse存储引擎之MergeTree引擎——数据存储","url":"/2020/07/12/clickhouse/存储引擎/ClickHouse存储引擎之MergeTree引擎——数据存储/","content":"\n## 一、按列存储\n\n​\t在MergeTree中，数据按列存储，每个字段也独立单独存储，每个列字段均拥有一个对应的column.bin数据文件，这些数据文件便为数据的物理存储。数据文件以分区目录的形式被组织存放，所以每个分区目录中的bin文件只保存了当前分区片段内的该列数据。按列独立存储有利于更好的进行数据压缩(相同类型数据存放在一起)，还可以最小化需扫描数据的范围。\n\n​\tMergeTree会将经过压缩的数据存放到对应column.bin文件中，默认使用LZ4算法，然后将数据按照声明的ORDER BY排序。最后，数据会以压缩数据块的方式被有序的写入数据文件中的。\n\n## 二、压缩数据块\n\n### 1、简介\n\n​\t一个压缩数据块由头信息和压缩数据两部分组成。头信息固定使用9位字节表示，具体由1个UInt8(1字节)和2个UInt32(4字节)整型组成，分别代表了使用的压缩算法类型、压缩后的数据大小和压缩前的数据大小，具体格式如图所示：\n\n<img src=\"ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMergeTree%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/cunchu_1.svg\" width=\"50%\" />\n\n​\t从上图可以看出，column.bin文件由多个压缩数据块组成，每个压缩数据块的头部信息是基于CompressionMethod_CompressedSize_UncompressedSize公式生成，可通过ClickHouse提供的clickhouse-compressor工具查询到某个.bin文件中压缩数据的统计信息。这里以官方提供的测试数据hit_v1为例，执行该命令：\n\n``` bash\nclickhouse-compressor --stat <  /var/lib/clickhouse/data/datasets/hits_v1/201403_1_32_2/JavaEnable.bin \n## 结果如下，每一行数据表示一个压缩数据块的头信息，分表表示该压缩数据块中未压缩数据大小和压缩后数据大小(打印信息和物理存储的顺序刚好相反)\n65536   12000\n65536   14661\n65536   4936\n65536   7506\n65536   18660\n65536   14892\n65536   17474\n65536   13464\n65536   14999\n...\n72776   1546\n68558   12639\n72089   11184\n71612   6945\n65857   11135\n7963    1559\n```\n\n​\t每个压缩数据块的体积，按照其压缩前的数据字节大小，被严格控制在64KB～1MB之间，上下限大小由`min_compress_block_size(默认65536)`和`max_compress_block_size(默认1048576)`参数指定。而每一个压缩数据块最终大小，则和一个index_granularity内实际的数据大小有关。\n\n``` sql\nclickhouse-server_1 :) select * from system.settings where name like '%_compress_block_size%'\\G\n\nSELECT *\nFROM system.settings\nWHERE name LIKE '%_compress_block_size%'\n\nRow 1:\n──────\nname:        min_compress_block_size\nvalue:       65536\nchanged:     0\ndescription: The actual size of the block to compress, if the uncompressed data less than max_compress_block_size is no less than this value and no less than the volume of data for one mark.\nmin:         ᴺᵁᴸᴸ\nmax:         ᴺᵁᴸᴸ\nreadonly:    0\n\nRow 2:\n──────\nname:        max_compress_block_size\nvalue:       1048576\nchanged:     0\ndescription: The maximum size of blocks of uncompressed data before compressing for writing to a table.\nmin:         ᴺᵁᴸᴸ\nmax:         ᴺᵁᴸᴸ\nreadonly:    0\n\n2 rows in set. Elapsed: 0.002 sec. \n```\n\n### 2、压缩规则及流程\n\n​\tMergeTree在数据存储过程中，会遵循以下规则：\n\n- 单个索引粒度间隔数据size < 64KB：如果单个索引粒度数据大小小于64KB，则继续获取下一个索引粒度的数据，一直到size >= 64KB，生成下一个压缩数据块。\n- 单个索引粒度间隔数据 64KB <= size <= 1MB：如果单个索引粒度数据大小大于64KB，小于1MB，则直接生成下一个压缩数据块\n- 单个索引粒度间隔数据 size > 1MB：如果单个索引粒度数据大小超过1MB，则先按照1MB大小截断并生成下一个压缩数据块，剩余数据按照这三个规则对应执行。这时就会出现一批数据生成多个压缩数据块的情况。\n\n![](ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMergeTree%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/cunchu_2.svg)\n\n### 3、总结\n\n​\t一个column.bin文件是由一个到多个压缩数据块组成的，每个压缩数据块大小在64KB～1MB之间。多个压缩数据块之间，按照写入顺序首尾相接，紧密排列在一起。数据被压缩后可以减少数据大小，降低存储空间并且加快数据的传输效率，但数据的压缩和解压动作，本身也会带来额外的性能损耗，所以需要控制被压缩数据的大小。另外，在具体读取某一列的压缩数据时，首先需要将压缩数据(包含了整个压缩数据块以及下个压缩数据块的头文件)加载到内存并解压，再进行后续的数据处理。通过压缩数据块，可以在不读取整个.bin文件的情况下将读取粒度降低到压缩数据块级别，进一步缩小了数据读取的范围。\n\n<img src=\"ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMergeTree%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/cunchu_3.png\" style=\"zoom:67%;\" />\n\n","tags":["clickhouse","engine","MergeTree"],"categories":["clickhouse"]},{"title":"简述ClickHouse数据类型","url":"/2020/07/12/clickhouse/简述ClickHouse数据类型/","content":"\n​\tClickHouse作为一个DBMS，提供了DDL和DML的功能，并支持部分标准的SQL语法。但ClickHouse在基础数据方面，既提供了常规的数据类型、字符串类型格式，又提供了一些常用的复合类型(数组、元组等)，并且与常规的数据库，在DML的使用上也存在不同(例如：UPDATE和DELETE是借助ALTER实现的)。本文将简单介绍ClickHouse所提供的各种数据类型。\n\n## 一、ClickHouse的数据类型\n\n​\t**ClickHouse提供了许多数据类型，可以分为基础类型、符合类型和特殊类型**，可进入clickhouse数据库中，通过`select * from system.data_type_families`查询所支持的所有数据类型。\n\n\n\n## 二、基础数据类型\n\n​\tClickHouse基础数据类型可分为数值、字符串和时间三种类型，没有Boolean类型，可用整型的0和1来替代。\n\n### 1、数值型\n\n数值型可分为Int、Float和Decimal三种类型\n\n#### 1.1 Int\n\n​\t在MySQL中，使用Tinyint、smallint、int和bigint来指代整数类型的取值。ClickHouse中使用了Int8、Int16、Int32、Int64来分别指代不同大小的Int类型(末尾数字表明占用字节大小，1字节=8位)，具体对比关系如下：\n\n|  名称  | 字节大小 | 范围                                      |       MySQL       |\n| :----: | :------: | ----------------------------------------- | :---------------: |\n|  Int8  |    1     | -128到127                                 |      Tinyint      |\n| Int16  |    2     | -32768到32767                             |     Smallint      |\n| Int32  |    4     | -2147483648到214783647                    |        Int        |\n| Int64  |    8     | -9223372036854775808到9223372036854775807 |      Bigint       |\n| UInt8  |    1     | 0到255                                    | Tinyint Unsinged  |\n| UInt16 |    2     | 0到65535                                  | Smallint Unsigned |\n| UInt32 |    4     | 0到4294967295                             |   Int Unsigned    |\n| UInt64 |    8     | 0到18446744073709551615                   |  Bigint Unsigned  |\n\n#### 1.2 Float\n\n​\tClickHouse使用了Float32和Float64来代表单精度浮点数一级双精度浮点数，具体对比关系如下，使用浮点数会引起四舍五入的误差：\n\n|  名称   | 大小(字节) | 有效精度(位数) | C语言类型 |\n| :-----: | :--------: | :------------: | :-------: |\n| Float32 |     4      |       7        |   float   |\n| Float64 |     8      |       16       |  Double   |\n\n``` sql\n-- 1. 转换为Float32类型\nclickhouse-server_1 :) select toFloat32('0.123456789098765432') as a, toTypeName(a);\n\nSELECT \n    toFloat32('0.123456789098765432') AS a, \n    toTypeName(a)\n\n┌──────────a─┬─toTypeName(toFloat32('0.123456789098765432'))─┐\n│ 0.12345679 │ Float32                                       │\n└────────────┴───────────────────────────────────────────────┘\n\n1 rows in set. Elapsed: 0.002 sec. \n\n\n-- 2. 转换为Float64类型\nclickhouse-server_1 :) select toFloat64('0.123456789098765432') as a, toTypeName(a);\n\nSELECT \n    toFloat64('0.123456789098765432') AS a, \n    toTypeName(a)\n\n┌───────────────────a─┬─toTypeName(toFloat64('0.123456789098765432'))─┐\n│ 0.12345678909876544 │ Float64                                       │\n└─────────────────────┴───────────────────────────────────────────────┘\n\n1 rows in set. Elapsed: 0.003 sec.\n```\n\n​\t和标准的SQL相比，ClickHouse还支持了以下类别的浮点数：\n\n- Inf：正无穷\n\n  ``` sql\n  clickhouse-server_1 :) select 0.5/0\n  \n  SELECT 0.5 / 0\n  \n  ┌─divide(0.5, 0)─┐\n  │            inf │\n  └────────────────┘\n  \n  1 rows in set. Elapsed: 0.007 sec. \n  ```\n\n- -Inf：负无穷\n\n  ``` sql\n  clickhouse-server_1 :) select -0.5 / 0\n  \n  SELECT -0.5 / 0\n  \n  ┌─divide(-0.5, 0)─┐\n  │            -inf │\n  └─────────────────┘\n  \n  1 rows in set. Elapsed: 0.001 sec.\n  ```\n\n- NaN：非数字\n\n  ``` sql\n  clickhouse-server_1 :) select 0 / 0\n  \n  SELECT 0 / 0\n  \n  ┌─divide(0, 0)─┐\n  │          nan │\n  └──────────────┘\n  \n  1 rows in set. Elapsed: 0.002 sec. \n  ```\n\n#### 1.3 Decimal\n\n​\t在高精度的数值运算中，会使用Decimal类型。ClickHouse提供了Decimal32、Decimal64和Decimal128三种精度的定点数，可通过`Decimal(P, S)`或简写`Decimal32(S), Decimal64(S), Decimal128(S)`来表示定义，参数含义如下：\n\n- P表示精度，有效范围为[1, 38]，决定总位数(整数部分+小数部分)\n- S表示规模，有效范围为[0, P]，决定小数位数\n\n简写方式和原生方式的对应如下：\n\n|     简写      |       原生        |                  范围                   |\n| :-----------: | :---------------: | :-------------------------------------: |\n| Decimal32(S)  |  Decimal(1~9, S)  |  $-1 * 10^(9 - S)$ 到 $1 * 10^(9 - S)$  |\n| Decimal64(S)  | Decimal(10~18, S) | $-1 * 10^(18 - S)$ 到 $1 * 10^(18 - S)$ |\n| Decimal128(S) | Decimal(19~38, S) | $-1 * 10^(38 - S)$ 到 $1 * 10^(38 - S)$ |\n\n​\t使用两个不同精度的定点数进行元算的话，他们小数位数S会发生变化：\n\n- 加法：S = max(S1, S2)\n- 减法：S = max(S1, S2)\n- 乘法：S = S1 + S2\n- 除法：S = S1  (S1 为被除数，且被除数S1必须大于除数S2，即S1 / S2)\n\n``` sql\n-- 1. 加法示例\nclickhouse-server_1 :) select toDecimal32(2,4) + toDecimal64(2,2)\n\nSELECT toDecimal32(2, 4) + toDecimal64(2, 2)\n\n┌─plus(toDecimal32(2, 4), toDecimal64(2, 2))─┐\n│                                     4.0000 │\n└────────────────────────────────────────────┘\n\n1 rows in set. Elapsed: 0.006 sec. \n\n\n-- 2. 减法示例\nclickhouse-server_1 :) select toDecimal32(4, 6) - toDecimal64(2, 2)\n\nSELECT toDecimal32(4, 6) - toDecimal64(2, 2)\n\n┌─minus(toDecimal32(4, 6), toDecimal64(2, 2))─┐\n│                                    2.000000 │\n└─────────────────────────────────────────────┘\n\n1 rows in set. Elapsed: 0.003 sec. \n\n\n-- 3. 乘法示例\nclickhouse-server_1 :) select toDecimal64(4, 4) * toDecimal32(2, 2)\n\nSELECT toDecimal64(4, 4) * toDecimal32(2, 2)\n\n┌─multiply(toDecimal64(4, 4), toDecimal32(2, 2))─┐\n│                                       8.000000 │\n└────────────────────────────────────────────────┘\n\n1 rows in set. Elapsed: 0.002 sec. \n\n\n-- 4. 除法示例\nclickhouse-server_1 :) select toDecimal64(4, 4) / toDecimal32(2, 2)\n\nSELECT toDecimal64(4, 4) / toDecimal32(2, 2)\n\n┌─divide(toDecimal64(4, 4), toDecimal32(2, 2))─┐\n│                                       2.0000 │\n└──────────────────────────────────────────────┘\n\n1 rows in set. Elapsed: 0.003 sec.\n```\n\n**溢出检查：**\n\n对Decimal进行操作时，数值可能会发生溢出。小数部分过多数字会被丢弃(不是四舍五入)，整数数字过多会导致异常。可通过设置`decimal_check_overflow`来关闭溢出检查，但溢出会导致结果不正确，而且会让计算变慢。在比较计算上也会发生溢出。\n\n``` sql\n-- 1. 数值溢出，x/3的结果本应为无限循环小数，只保留了S位，其余小数被丢弃\nclickhouse-server_1 :) SELECT toDecimal32(2, 4) AS x, x / 3\n\nSELECT \n    toDecimal32(2, 4) AS x, \n    x / 3\n\n┌──────x─┬─divide(toDecimal32(2, 4), 3)─┐\n│ 2.0000 │                       0.6666 │\n└────────┴──────────────────────────────┘\n\n1 rows in set. Elapsed: 0.002 sec. \n\n\n-- 2. 整数部分溢出导致报错\nclickhouse-server_1 :) SELECT toDecimal32(4.2, 8) AS x, x * x\n\nSELECT \n    toDecimal32(4.2, 8) AS x, \n    x * x\n\nReceived exception from server (version 20.3.4):\nCode: 69. DB::Exception: Received from localhost:9000. DB::Exception: Scale 16 is out of bounds. \n\n0 rows in set. Elapsed: 0.005 sec. \n\nclickhouse-server_1 :) SELECT toDecimal32(4.2, 8) AS x, 6 * x\n\nSELECT \n    toDecimal32(4.2, 8) AS x, \n    6 * x\n\nReceived exception from server (version 20.3.4):\nCode: 407. DB::Exception: Received from localhost:9000. DB::Exception: Decimal math overflow. \n\n0 rows in set. Elapsed: 0.002 sec.\n\n-- 3. 关闭溢出检查\nclickhouse-server_1 :) SET decimal_check_overflow = 0;\n\nSET decimal_check_overflow = 0\n\nOk.\n\n0 rows in set. Elapsed: 0.001 sec. \n\nclickhouse-server_1 :) SELECT toDecimal32(4.2, 8) AS x, 6 * x\n\nSELECT \n    toDecimal32(4.2, 8) AS x, \n    6 * x\n\n┌──────────x─┬─multiply(6, toDecimal32(4.2, 8))─┐\n│ 4.20000000 │                     -17.74967296 │\n└────────────┴──────────────────────────────────┘\n\n1 rows in set. Elapsed: 0.002 sec. \n\n\n-- 4. 比较，溢出提示Can't compare\nclickhouse-server_1 :) SELECT toDecimal32(1, 8) < 100\n\nSELECT toDecimal32(1, 8) < 100\n\nReceived exception from server (version 20.3.4):\nCode: 407. DB::Exception: Received from localhost:9000. DB::Exception: Can't compare. \n\n0 rows in set. Elapsed: 0.010 sec. \n```\n\n****\n\n### 2、字符串类型\n\n字符串类型可分为String、FixedString和UUID类型。\n\n#### 2.1 String\n\n字符串由String类型定义，无长度限制。在使用时也不需要声明大小，代替了其他数据库上的Varchar、Text、Blob等自负类型。而且String类型不限制字符集限制，可以写入任意编码的字符串，但为了标准统一化开发管理，官方建议一套程序中应使用统一的编码类型。\n\n#### 2.2 FixedString\n\nFixedString和传统的char类型类似，用来定义一些固定长度的字符串。通过`FixedString(N)`来定义声明，N表示字符串长度，当数据长度小于N字节时，会降低一定效率。但Char类型通常使用空格填充末尾字符，而FixedString用null字节来填充。\n\n- 当向ClickHouse中插入数据时\n  - 如果字符串包含字节数少于N，将用null字节来填充\n  - 如果字符串包含字节数大于N，将抛出`Too large value for FixedString(N)`的异常\n- 当查询数据时\n  - ClickHouse不会删除字符串末尾的空字节，如果使用WHERE子句，则**需要手动添加空字节来匹配FixedString的值**\n\n``` sql\n-- 1. 创建一个用来测试的表，并插入测试数据，若没有test库则需要create database test来进行创建\nclickhouse-server_1 :) use test\n\nclickhouse-server_1 :) create table FixedStringTest ( a FixedString(2) ) engine=MergeTree order by a\n\n\n-- 2. 插入正常数据\nclickhouse-server_1 :) insert into FixedStringTest values ('a')\n\n\n-- 3. 插入大于N数据\nclickhouse-server_1 :) insert into FixedStringTest values ('abc')\n\n\n-- 4. 查询数据\n-- where查询时并不会自动删除后面的null，所以无法得到想要的结果\nclickhouse-server_1 :) select * from FixedStringTest where a = 'a'\n\nSELECT *\nFROM FixedStringTest\nWHERE a = 'a'\n\nOk.\n\n0 rows in set. Elapsed: 0.002 sec. \n\n-- 查询可看到，长度为2\nclickhouse-server_1 :) select a, length(a) from FixedStringTest\n\nSELECT \n    a, \n    length(a)\nFROM FixedStringTest\n\n┌─a─┬─length(a)─┐\n│ a │         2 │\n└───┴───────────┘\n\n1 rows in set. Elapsed: 0.002 sec. \n\n-- 需手动填充空字节用于where匹配\nclickhouse-server_1 :) select * from FixedStringTest where a = 'a\\0'\n\nSELECT *\nFROM FixedStringTest\nWHERE a = 'a\\0'\n\n┌─a─┐\n│ a │\n└───┘\n\n1 rows in set. Elapsed: 0.002 sec. \n```\n\n#### 2.3 UUID\n\nUUID经常会在数据库中使用，有时候还会作为主键，ClickHouse直接将UUID作为了一种数据类型。UUID一共有32位，格式为`8-4-4-4-12`,如果UUID类型的字段在写入数据时没有被赋值，则会按照格式用0来填充。ClickHouse还提供了`generateUUIDv4`来生成随机的UUID。\n\n``` sql\n-- 1. 创建测试表\nCREATE TABLE t_uuid (x UUID, y String) ENGINE=TinyLog\n\n-- 2. 插入UUID\nINSERT INTO t_uuid SELECT generateUUIDv4(), 'Example 1'\n\n-- 3. 查询\nclickhouse-server_1 :) select * from t_uuid\n\nSELECT *\nFROM t_uuid\n\n┌────────────────────────────────────x─┬─y─────────┐\n│ a603876a-38cb-460a-bafb-a08d4ab1b9c4 │ Example 1 │\n└──────────────────────────────────────┴───────────┘\n\n1 rows in set. Elapsed: 0.002 sec. \n\n-- 4. 不指定UUID插入数据\nINSERT INTO t_uuid (y) VALUES ('Example 2')\n\n-- 查询结果\nclickhouse-server_1 :) select * from t_uuid\n\nSELECT *\nFROM t_uuid\n\n┌────────────────────────────────────x─┬─y─────────┐\n│ a603876a-38cb-460a-bafb-a08d4ab1b9c4 │ Example 1 │\n│ 00000000-0000-0000-0000-000000000000 │ Example 2 │\n└──────────────────────────────────────┴───────────┘\n\n2 rows in set. Elapsed: 0.002 sec. \n```\n\n### 3、时间类型\n\n时间类型分为DateTime、DateTime64和Date三种。ClickHouse目前不存在时间戳类型，时间类型的最高精度到秒，所以若需要毫秒、微秒等时间，只能用UInt类型实现\n\n#### 3.1 DateTime\n\nDateTime类型精确到秒，可表示的时间范围为`['1970-01-01 00:00:00', '2105-12-31 23:59:59']`，创建表时，可以为DateTime的列显示设置失去，如果未为表设置失去，启动ClickHouse服务时，它将使用系统设置中的timezone参数，也可以使用`--use_client_time_zone`参数来启动clickhouse-client，默认格式为`YYYY-MM-DD hh:mm:ss`输出至，也可以使用`formatDateTime`函数来更改输出，插入数据时格式则取决于`date_time_input_format`的设置。\n\n**1. 创建设置了DateTime类型列的表并插入数据**\n\n``` sql\n-- 创建表\nCREATE TABLE dt ( `timestamp` DateTime('Asia/Shanghai'), `event_id` UInt8 ) ENGINE = TinyLog;\n\n-- 插入数据\nINSERT INTO dt Values (1546300800, 1), ('2020-07-12 00:00:00', 2);\n\n-- 查询数据\nclickhouse-server_1 :) select * from dt;\n\nSELECT *\nFROM dt\n\n┌───────────timestamp─┬─event_id─┐\n│ 2019-01-01 08:00:00 │        1 │\n│ 2020-07-12 00:00:00 │        2 │\n└─────────────────────┴──────────┘\n\n2 rows in set. Elapsed: 0.002 sec.\n```\n\n- 将datetime插入为整数时，它会被视为Unix时间戳(UTC)，1546300800表示'2019-01-01 00:00:00'UTC，但由于timestamp列已指定了时区`Asia/Shanghai`，所以会显示为东八区时间`2019-01-01 08:00:00`\n\n**2. 指定时区删选DateTime值**\n\n``` sql\nSELECT * FROM dt WHERE timestamp = toDateTime('2020-07-12 00:00:00', 'Asia/Shanghai')\n-- 结果为\n┌───────────timestamp─┬─event_id─┐\n│ 2020-07-12 00:00:00 │        2 │\n└─────────────────────┴──────────┘\n\n-- 也可通过where字符串值过滤\nSELECT * FROM dt WHERE timestamp = '2020-07-12 00:00:00'\n┌───────────timestamp─┬─event_id─┐\n│ 2020-07-12 00:00:00 │        2 │\n└─────────────────────┴──────────┘\n```\n\n**3. 获取DateTime列和时区类型**\n\n``` sql\nSELECT toDateTime(now(), 'Asia/Shanghai') AS column, toTypeName(column) AS x\n-- 结果\n┌──────────────column─┬─x─────────────────────────┐\n│ 2020-07-12 12:41:28 │ DateTime('Asia/Shanghai') │\n└─────────────────────┴───────────────────────────┘\n```\n\n**4. 转换列时区**\n\n``` sql\nSELECT toDateTime(timestamp, 'Europe/London') as lon_time, toDateTime(timestamp, 'Europe/Moscow') as mos_time FROM dt\n-- 结果\n┌────────────lon_time─┬────────────mos_time─┐\n│ 2019-01-01 00:00:00 │ 2019-01-01 03:00:00 │\n│ 2020-07-11 17:00:00 │ 2020-07-11 19:00:00 │\n└─────────────────────┴─────────────────────┘\n```\n\n#### 3.2 DateTime64\n\nDateTime64在DateTime类型基础上增加了精度设置，可以记录到亚秒，其余使用方法和DateTime相同。\n\n``` sql\n-- 创建测试表\nCREATE TABLE dt64 (`timestamp` DateTime64(3, 'Asia/Shanghai'), `event_id` UInt8 ) ENGINE = TinyLog\n\n-- 插入测试数据\nINSERT INTO dt64 Values (1546300800000, 1), ('2019-01-01 00:00:00', 2)\n\n-- 查询结果\nselect * from dt64\n-- 结果为\n┌───────────────timestamp─┬─event_id─┐\n│ 2019-01-01 08:00:00.000 │        1 │\n│ 2019-01-01 00:00:00.000 │        2 │\n└─────────────────────────┴──────────┘\n```\n\n#### 3.3 Date\n\nDate类型不包含具体的时间，只精确到天，存储的日期值不带时区，同样支持字符串的形式写入。\n\n``` sql\n-- 创建测试表\ncreate table date_test(`c1` Date, `event_id` UInt8 ) Engine = TinyLog\n\n-- 插入数据，即使插入包含具体时间的值，也只会写入日期\ninsert into date_test values ('2019-01-01 00:00:00', 1), ('2020-07-12', 2)\n\n-- 查询\nselect * from date_test\n-- 结果为\n┌─────────c1─┬─event_id─┐\n│ 2019-01-01 │        1 │\n│ 2020-07-12 │        2 │\n└────────────┴──────────┘\n```\n\n## 三、复合类型\n\n除了数值、字符串和时间这些基础数据类型之外，ClickHouse还提供了数组、元组、枚举和嵌套四种复合类型。\n\n### 1、数组Array\n\n数组有两种定义形式：array(T)和[]\n\n``` sql\nselect array(1, 2) as a, toTypeName(a)\n-- 结果\n┌─a─────┬─toTypeName([1, 2])─┐\n│ [1,2] │ Array(UInt8)       │\n└───────┴────────────────────┘\n\nselect [1,2] as a, toTypeName(a)\n-- 结果\n┌─a─────┬─toTypeName([1, 2])─┐\n│ [1,2] │ Array(UInt8)       │\n└───────┴────────────────────┘\n```\n\n可以看出，在查询时并不需要主动声明数组的元素类型，这是因为ClickHouse的数组拥有类型推断的能力。但在快速创建数组时，ClickHouse会自动将参数定义为最小的可表达的数据类型。例如若数组中存在NULL值，数组元素类型会变为Nullable。**但在进行表定义时，数组需要指定明确的元素类型**\n\n``` sql\nSELECT array(1, 2, NULL) AS x, toTypeName(x)\n-- 结果\n┌─x──────────┬─toTypeName([1, 2, NULL])─┐\n│ [1,2,NULL] │ Array(Nullable(UInt8))   │\n└────────────┴──────────────────────────┘\n\n-- 建表时需要指定类型\ncreate table array_test(c1 Array(String)) engine = TinyLog     ## 可创建成功，数据写入过程中会进行类型检查\n\ncreate table array_test(c1 Array) engine = TinyLog     ## 会创建失败\n-- 结果\nReceived exception from server (version 20.3.4):\nCode: 42. DB::Exception: Received from localhost:9000. DB::Exception: Array data type family must have exactly one argument - type of elements. \n```\n\n当一个数组内包含了多种数据类型，则ClickHouse会引发异常。\n\n``` sql\nselect array(1, 'a')\n-- 结果\nReceived exception from server (version 20.3.4):\nCode: 386. DB::Exception: Received from localhost:9000. DB::Exception: There is no supertype for types UInt8, String because some of them are String/FixedString and some of them are not. \n```\n\n### 2、元组Tuple\n\n元组类型有1～n个元素组成，每个元素都是一个单独的类型。与数组类似，元组也可用两种方式定义：tuple(T)或(t1, t2, ...)\n\n``` sql\nSELECT tuple(1,'a') AS x, toTypeName(x)\n-- 结果\n┌─x───────┬─toTypeName(tuple(1, 'a'))─┐\n│ (1,'a') │ Tuple(UInt8, String)      │\n└─────────┴───────────────────────────┘\n\nSELECT tuple(1, NULL) AS x, toTypeName(x)\n┌─x────────┬─toTypeName(tuple(1, NULL))──────┐\n│ (1,NULL) │ Tuple(UInt8, Nullable(Nothing)) │\n└──────────┴─────────────────────────────────┘\n```\n\n定义表字段时，同样需要指定明确的元素类型\n\n``` sql\ncreate table tuple_test ( c1 Tuple(String, Int8)) Engine = TinyLog\n-- 插入数据时也会进行类型检查\ninsert into tuple_test values(('abc', 123))    ## 可插入成功\n\ninsert into tuple_test values(('abc', 'def'))\t## 会提示类型报错\n-- 结果\nException on client:\nCode: 6. DB::Exception: Cannot parse string 'def' as Int8: syntax error at begin of string. Note: there are toInt8OrZero and toInt8OrNull functions, which returns zero/NULL instead of throwing exception.\n```\n\n### 3、枚举Enum\n\nClickHouse提供了Enum8和Enum16两种枚举类型，ClickHouse可自动选择Enum插入数据的类型，也可以手动指定。他们仅取值范围不同：\n\n- Enum8包含[-128, 127]范围内列举的256个值-\n- Enum16最多包含[-32768, 32767]范围内列举的65536个值\n\n命名值必须声明为`'string: Int'的Key/Value`键值对形式，所以Enum8和Enum16分别为`(String: Int8)`和`(String: Int16)`.\n\n在使用枚举类型时，有以下限制：\n\n- Key和Value不允许重复，需保证唯一性\n- Key和Value值都不能为Null，但Key允许是空字符串\n\n``` sql\n-- 创建测试表\nCREATE TABLE t_enum (x Enum('hello' = 1, 'world' = 2)) ENGINE = TinyLog\n\n-- 插入数据\nINSERT INTO t_enum VALUES ('hello'), ('world'), ('hello')\n-- 插入成功\n\n-- 若插入enum之外的key，则会抛出异常\nINSERT INTO t_enum values('a')\n-- 结果：\nException on client:\nCode: 36. DB::Exception: Unknown element 'a' for type Enum8('hello' = 1, 'world' = 2)\n\n-- 查询数据，会输出字符串类型的Key值\nSELECT * FROM t_enum\n┌─x─────┐\n│ hello │\n│ world │\n│ hello │\n└───────┘\n\n-- 若需要查看对应的value值，则需要将Enum值转换为整数类型，CAST(x, T)则将x类型转换为T类型\nSELECT CAST(x, 'Int8') FROM t_enum\n┌─CAST(x, 'Int8')─┐\n│               1 │\n│               2 │\n│               1 │\n└─────────────────┘\n\n-- 若在select中直接创建Enum类型，仍然需要CAST函数转换\nSELECT toTypeName(CAST('hello', 'Enum(\\'hello\\' = 1, \\'world\\' = 2)'))\n┌─toTypeName(CAST('hello', 'Enum(\\'hello\\' = 1, \\'world\\' = 2)'))─┐\n│ Enum8('hello' = 1, 'world' = 2)                                 │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n### 4、嵌套Nested\n\n一个数据表可以定义任意多个嵌套类型字段，但每个字段只能有一层潜逃，即嵌套字段内不能继续使用嵌套类型。ClickHouse的嵌套类型本质是一个多维数组的结构，即嵌套表中的每个字段都是一个数组。\n\n``` sql\n-- 创建测试表\ncreate table nested_test(name String, age UInt8, dept Nested(id UInt8, name String)) Engine = TinyLog\n\n-- 插入数据\ninsert into nested_test values ('alice', 18, [10000, 10001], ['aaa', 'bbb'])\n\n-- 插入数据时，同一行数据中嵌套类型的数组字段长度必须相同，否则会抛出以下异常\ninsert into nested_test values ('bob', 22, [10000], ['aaa', 'bbb'])\nReceived exception from server (version 20.3.4):\nCode: 190. DB::Exception: Received from localhost:9000. DB::Exception: Elements 'dept.id' and 'dept.name' of Nested data structure 'dept' (Array columns) have different array sizes.. \n\n-- 查询数据\nselect name, dept.id, dept.name from nested_test;\n┌─name──┬─dept.id─┬─dept.name─────┐\n│ alice │ [16,17] │ ['aaa','bbb'] │\n└───────┴─────────┴───────────────┘\n```\n\n## 四、其他类型\n\n​\tClickHouse除了上述类型之外，还定义了一些其他字段类型作为对基础数据的进一步修饰和封装。\n\n### 1、Nullable\n\n​\tNullable并不能算一种独立的数据类型，它需要和基础数据类型配合使用，并不能用于数组和元组这些复合类型，通过Nullable修饰之后，该基础类型字段可以输入Null值。\n\n​\t使用了Nullable修饰后，该字段不能作为索引字段，并且会使查询和写入性能变慢。这是由于一般情况下每个字段的数据会存储在对应的column.bin文件中，如果该字段被Nullable修饰，会额外生成column.null.bin文件专门保存null值，这表示读取和写入，需要一倍的额外文件操作。故官方并不建议经常使用Nullable类型\n\n``` sql\n-- 创建测试表\nCREATE TABLE t_null(x Int8, y Nullable(Int8)) ENGINE TinyLog\n\n-- 插入数据\nINSERT INTO t_null VALUES (1, NULL), (2, 3)\n\n-- 查询\nselect * from t_null\n┌─x─┬────y─┐\n│ 1 │ ᴺᵁᴸᴸ │\n│ 2 │    3 │\n└───┴──────┘\n```\n\n### 2、Domain\n\nDomain类型分为IPv4和IPv6两种，本质是对整型和字符串型的进一步封装，虽然Domain类型看起来和String类型相同，但它并不是字符串类型，不支持隐式的自动类型转换，如果需要返回IP的字符串形式，需要调用`IPv4NumToString`或`IPv6NumToString`函数进行转换。IPv4类型是基于UInt32封装，IPv6基于FixedString(16)封装。他们使用方式相同，以下用IPv4作为示例。\n\n``` sql\n-- 创建测试表\nCREATE TABLE hits (url String, from IPv4) ENGINE = MergeTree() ORDER BY url;\n\n-- 插入数据\ninsert into hits values('www.zzdb.com', '1.1.1.1'),('test.db.com', '2.2.2.2')\n\n-- Domain格式会进行数据类型检查\ninsert into hits values ('www.test.com', '192.168.1')\nException on client:\nCode: 441. DB::Exception: Invalid IPv4 value.\n\n-- 查询数据\nselect * from hits\n┌─url──────────┬────from─┐\n│ test.db.com  │ 2.2.2.2 │\n│ www.zzdb.com │ 1.1.1.1 │\n└──────────────┴─────────┘\n\n-- 转换为字符串类型\nSELECT toTypeName(s), IPv4NumToString(from) as s FROM hits LIMIT 1;\n┌─toTypeName(IPv4NumToString(from))─┬─s───────┐\n│ String                            │ 2.2.2.2 │\n└───────────────────────────────────┴─────────┘\n```\n\n","tags":["clickhouse"],"categories":["clickhouse"]},{"title":"ClickHouse存储引擎之MergeTree引擎——索引","url":"/2020/07/05/clickhouse/存储引擎/ClickHouse存储引擎之MergeTree引擎——索引/","content":"\n## 一、一级索引\n\n​\tMergeTree的主键使用PRIMARY KEY来定义，MergeTree会根据index_granularity间隔(默认8192行)，为数据表生成一级索引并保存到primary.idx文件里，索引数据会按照PRIMARY KEY排序，所以，ClickHouse中经常通过ORDER BY来代替主键。此时，索引(primary.idx)和数据文件(column.bin)会按照相同的规则排序\n\n​\tClickHouse的一级索引使用了稀疏索引实现，即每一行索引表计对应的是一段数据，而不是一行数据。它使用少量的索引标记就可以记录大量数据的区间位置信息。\n\n### 1、索引粒度\n\n​\tClickHouse通过`index_granularity`参数来控制索引粒度，默认为8192，最新版本可以使用自适应索引粒度大小，则标记文件会被命名为(column.mrk2)。数据会以该参数的大小被标记为多个小区间，每个区间默认最多8192行数据，MergeTree使用MarkRange来表示一个具体区间，并通过start和end表示具体范围。\n\n​\t在ClickHouse中，索引粒度不仅影响一级索引(primary.idx)，同时也影响数据标记文件(column.mrk)和数据文件(column.bin)。这是由于MergeTree无法只通过索引来完成查询工作，通过标记文件建立以稀疏索引(primary.idx)和对应数据文件(column.bin)的映射关系，MergeTree会先通过稀疏索引(primary.idx)找到对应数据的偏移量信息(column.mrk)，再通过偏移量直接从数据文件(column.bin)读取数据。所以一级索引和数据标记的间隔粒度相同，均有`index_granularity`参数决定，数据文件也会依据该参数生成压缩数据块。\n\n<img src=\"ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMergeTree%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E7%B4%A2%E5%BC%95/suoyin_1.png\" alt=\"MergeTree按照索引粒度划分数据\" style=\"zoom:50%;\" />\n\n### 2、索引数据的生成规则\n\n​\tMergeTree需要间隔index_granularity行数据才会生成一条索引记录，索引值会依据声明的主键字段来获取。例如官方提供的测试数据表hits_v1使用了年月分区(PARTITION BY toYYYYMM(EventDate))，如果使用CounterID作为主键，则每间隔8192行数据就会取一次CounterID的值作为索引值，索引数据最终写入parimary.idx文件中保存。\n\n<img src=\"ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMergeTree%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E7%B4%A2%E5%BC%95/suoyin_2.png\" style=\"zoom:60%;\" />\n\n​\t以上是使用单个字段作为主键的情况，若使用多个主键，例`ORDER BY(CounterID, EventDate)`，则每间隔8192行同时取CounterID和EventDate两列值作为索引，上述例子，索引值将为`572014-03-1716352014-03-1832662014-03-19`\n\n## 二、索引的查询过程\n\n​\tMarkRange在ClickHouse中用来定义标记区间，MergeTree按照index_granularity设置的索引粒度，将一段完整的数据划分成了多个小的间隔数据段，一个数据段则是一个MarkRange，它与索引编号对应，使用start和end两个属性表示区间范围，通过start和end对应的索引编号的取值，可以得到它所对应的数值区间，数值区间则表示了该MarkRange的数据范围。\n\n​\t假如一份测试数据，共有192条记录。其中主键ID为String类型，ID取值从A000开始，后面依次为A001、A002...A191。MergeTree的索引粒度为index_granularity=3，根据索引的生成规则，primary.idx文件内的索引数据会为`A000A003A006A009A012...A186A189`\n\n​\t根据索引数据，MergeTree会将此数据片段分为192/3 = 64个小的MarkRange，两个相邻MarkRange相距步长为1，所有MarkRange(整个数据片段)的最大数值区间为[A000, +inf)。MarkRange和数值区间范围示意图如下：\n\n<img src=\"ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMergeTree%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E7%B4%A2%E5%BC%95/suoyin_3.png\" style=\"zoom:60%;\" />\n\n​\t索引的查询其实为基于主键的查询条件转换的条件区间和MarkRange对应的数值区间这两个区间的交集判断。整个查询过程可分为以下三个步骤：\n\n1. 生成查询条件区间。\n\n   例如：\n\n   条件为 `WHERE ID = 'A003'`,条件区间会转换为`['A003', 'A003']`;\n\n   条件为`WHEER ID > 'A000'`,条件区间会转换为`['A000', +inf]`;\n\n2. 递归交集判断：以递归的形式，依次对MarkRange的数值区间与条件区间做交集判断。从最大的MarkRange区间`[A000,+inf]`开始\n\n   1. 如果不存在交集，则直接去掉整段MarkRange数据\n   2. 存在交集，且MarkRange步长大于8(end - start)，则将此区间进一步拆分成8个字区间(由merge_tree_coarse_index_granularity指定，默认为8)，不断重复，做交集判断\n   3. 存在交集，并且MarkRange不可被再分解(步长小于8)，则记录MarkRange并返回\n\n3. 合并MarkRange区间：将最终匹配的MarkRange聚合\n\n\n\n大致流程图如下：\n\n<img src=\"ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMergeTree%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E7%B4%A2%E5%BC%95/suoyin_4.png\" style=\"zoom:80%;\" />\n\n## 二、二级索引\n\nMergeTree还支持二级索引，但目前还处于测试阶段，官方不建议大量使用。\n\n### 1、定义方式\n\nMergeTree二级索引又叫跳数索引，是由数据按索引粒度分割后的每部分在指定表达式上的汇总信息组成，这些汇总信息有助于用where条件过滤时跳过不满足的数据，从而减少select查询从磁盘读取的数据量以及数据扫描的范围。\n\n跳数索引默认是关闭的，需要执行`SET allow_experimental_data_skipping_indices = 1`开启，在创建表时指定，定义语法为：\n\n`INDEX index_name expr TYPE index_type(...) GRANULARITY granularity_value`\n\n当建表语句中声明了跳数索引，则会额外生成相对应的索引和标记文件(skp_idx\\_[column].idx和skp_idx\\_[column].mrk)\n\n### 2、granularity与index_granularity的关系\n\n不同的二级索引中，除了各个索引不同类型的参数以外，都共同拥有granularity参数。对于跳数索引，index_granularity定义了数据粒度，二granularity定义了聚合信息汇总的力度。即granularity定义了一行跳数索引能够跳过多少个index_granularity区间的数据。\n\n跳数索引的生成规则可以大概解释为：\n\n1. 按照index_granularity粒度间隔将数据划分为n段，总共有[0, n-1]个区间(n = total_rows / index_granularity，向上取整)\n2. 根据索引定义声明，从0区间开始，一次按照index_granularity粒度从数据中获取聚合信息，每次向前移动1步(n + 1)，聚合信息逐步累加\n3. 当移动到granularity次区间时，则进行数据汇总并生成一行跳数索引数据\n\n**示例：**\n\n以minmax索引为例，它聚合了一个index_granularity区间内的最大和最小数据，假设index_granulariyt=8192且granulariyt=3，则数据按照index_granularity划分为n等份，MergeTree从第0段分区开始，依次获取聚合信息，当获取到第三个分区(granularity=3)，则汇总并生成第一行minmax索引(前3段minmax汇总后取值为[1, 9])，如下图所示：\n\n<img src=\"ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMergeTree%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E7%B4%A2%E5%BC%95/suoyin_5.svg\" style=\"zoom:80%;\" />\n\n### 3、跳数索引的类型\n\n​\t目前，MergeTree支持4中跳数座因，分别是minmax、set、ngrambf_v1和tokenbf_v1，一张数据表支持同时声明多个跳数索引。\n\n- `minmax`：minmax索引记录了一段数据内的最小值和最大值，用于快速跳过无用的数据区间\n\n  - `INDEX a ID TYPE minmax GRANULARITY 5` 表示minmax索引会记录每5个index_granularity区间数据中的最大值和最小值\n\n- `set`：存储指定字段或表达式的唯一值，完整形式为`set(max_rows)`，max_rows表示在一个index_granularity内，索引最多纪录的数据行数，如果max_rows=0，则表示无限制\n\n  - `INDEX b(length(ID) * 8) TYPE set(100) GRANULARITY 5` 表示该索引会记录数据中ID长度*8之后的取值，并且每个index_granularity最多纪录100条\n\n- `ngrambf_v1`：记录了数据块中n元短语的布隆表过滤器(简单来讲，布隆表过滤器本质是由仅包含0和1位值的列表组成，默认均为0，利用哈希函数对数据值进行处理，并将结果位置上对应位的值改为1，由于存在哈希冲突，所以只能判断不在列表中和可能在列表中)，只支持String和FixedString数据类型，可用于优化like、in、equals、notIn、notEquals的查询性能，完整形式为`ngrambf_v1(n, size_of_bloom_filter_in_bytes, number_of_hash_functions, random_seed)`，各参数含义为：\n\n  - n: token长度，依据n长度将数据切割为token短语\n  - size_of_bloom_filter_in_bytes: 布隆过滤器的大小\n  - number_of_hash_functions: 布隆过滤器中使用Hash函数的个数\n  - random_seed: Hash函数的随机种子\n\n  例如：`INDEX c(ID, Code) TYPE ngrambf_v1(3, 256, 2, 0) GRANULARITY 5` 表示依照3的粒度将数据切割成短语token，token经过两个Hash函数映射后再被写入，布隆过滤器大小伟256字节\n\n- `tokenbf_v1`：和ngrambf_v1类似，但它会自动按照非字符、数字的字符串切割token\n\n","tags":["clickhouse","engine","MergeTree"],"categories":["clickhouse"]},{"title":"ClickHouse存储引擎之MergeTree引擎——数据分区","url":"/2020/06/27/clickhouse/存储引擎/ClickHouse存储引擎之MergeTree引擎——数据分区/","content":"\n​\t从[ClickHouse存储引擎之MergeTree引擎——概述]([https://schnappi618.github.io/2020/06/11/clickhouse/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMergeTree%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E6%A6%82%E8%BF%B0/](https://schnappi618.github.io/2020/06/11/clickhouse/存储引擎/ClickHouse存储引擎之MergeTree引擎——概述/))中可以知道，在MergeTree存储引擎中，数据是以分区目录的形式存放的。基于该原理，在进行数据查询时，可以仅查询最小的分区目录。\n\n## 一、MergeTree数据分区规则\n\n### 1、测试示例\n\n​\t下面仍然使用上一篇的测试数据来继续说明MergeTree的数据分区方式和规则\n\n1. 原始数据情况\n\n``` bash\n# 初始化数据后的数据目录如下\n[root@xxxx partitioned_by_week]# ll\ntotal 4\ndrwxr-x--- 2 101 101 221 Jun 13 17:18 19991227_1_1_0\ndrwxr-x--- 2 101 101 221 Jun 13 17:18 20000103_2_2_0\ndrwxr-x--- 2 101 101  10 Jun 13 17:15 detached\n-rw-r----- 1 101 101   1 Jun 13 17:15 format_version.txt\n\n# 目前partitioned_by_week表的数据内容为\n## 查询该表的测试数据\nclickhouse-server_1 :) select * from partitioned_by_week;\n\nSELECT *\nFROM partitioned_by_week\n\n┌──────────d─┬─x─┐\n│ 2000-01-03 │ 3 │\n└────────────┴───┘\n┌──────────d─┬─x─┐\n│ 2000-01-01 │ 1 │\n│ 2000-01-02 │ 2 │\n└────────────┴───┘\n\n3 rows in set. Elapsed: 0.004 sec. \n## 表结构如下\nclickhouse-server_1 :) show create table partitioned_by_week;\n\nSHOW CREATE TABLE partitioned_by_week\n\n┌─statement────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n│ CREATE TABLE test.partitioned_by_week (`d` Date, `x` UInt8) ENGINE = MergeTree PARTITION BY toMonday(d) ORDER BY x SETTINGS index_granularity = 8192 │\n└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n\n1 rows in set. Elapsed: 0.003 sec. \n```\n\n2. 插入一条新的数据\n\n``` sql\n-- 插入一条新的数据('2000-01-05', 4)\nclickhouse-server_1 :) insert into partitioned_by_week (d, x) values('2000-01-05', 4)\n\nINSERT INTO partitioned_by_week (d, x) VALUES\n\nOk.\n\n1 rows in set. Elapsed: 0.004 sec. \n\n```\n\n3. 数据内容及数据目录如下\n\n``` bash\n# 查询数据情况\nclickhouse-server_1 :) select * from partitioned_by_week\n\nSELECT *\nFROM partitioned_by_week\n\n┌──────────d─┬─x─┐\n│ 2000-01-03 │ 3 │\n└────────────┴───┘\n┌──────────d─┬─x─┐\n│ 2000-01-01 │ 1 │\n│ 2000-01-02 │ 2 │\n└────────────┴───┘\n┌──────────d─┬─x─┐\n│ 2000-01-05 │ 4 │\n└────────────┴───┘\n\n4 rows in set. Elapsed: 0.009 sec.\n# 查询数据分区情况，active = 1表示启用中\nclickhouse-server_1 :) SELECT partition,name,active FROM system.parts WHERE table = 'partitioned_by_week'\n\nSELECT \n    partition, \n    name, \n    active\nFROM system.parts\nWHERE table = 'partitioned_by_week'\n\n┌─partition──┬─name───────────┬─active─┐\n│ 1999-12-27 │ 19991227_1_1_0 │      1 │\n│ 2000-01-03 │ 20000103_2_2_0 │      1 │\n│ 2000-01-03 │ 20000103_3_3_0 │      1 │\n└────────────┴────────────────┴────────┘\n\n3 rows in set. Elapsed: 0.012 sec. \n\n# 数据目录情况\n[root(host/tjtx148-16-25.58os.org)@tjtx162-17-78 partitioned_by_week]# ll\ntotal 4\ndrwxr-x--- 2 101 101 221 Jun 13 17:18 19991227_1_1_0\ndrwxr-x--- 2 101 101 221 Jun 13 17:18 20000103_2_2_0\ndrwxr-x--- 2 101 101 221 Jun 27 10:20 20000103_3_3_0\ndrwxr-x--- 2 101 101  10 Jun 13 17:15 detached\n-rw-r----- 1 101 101   1 Jun 13 17:15 format_version.txt\n```\n\n4. 查询并查看执行计划\n\n``` sql\n-- 查询一条数据\nclickhouse-server_1 :) select x from partitioned_by_week where d = '2000-01-05'\n\nSELECT x\nFROM partitioned_by_week\nWHERE d = '2000-01-05'\n\n┌─x─┐\n│ 4 │\n└───┘\n\n1 rows in set. Elapsed: 0.002 sec.\n\n\n2020.06.27 10:29:58.383307 [ 81 ] {f0a4f689-76f3-4342-ab8f-2e8349ca5970} <Debug> executeQuery: (from 127.0.0.1:58492) SELECT x FROM partitioned_by_week WHERE d = '2000-01-05'\n-- clickhouse将where条件自动优化为了PREWHERE，用来做数据过滤\n2020.06.27 10:29:58.383577 [ 81 ] {f0a4f689-76f3-4342-ab8f-2e8349ca5970} <Debug> InterpreterSelectQuery: MergeTreeWhereOptimizer: condition \"d = '2000-01-05'\" moved to PREWHERE\n2020.06.27 10:29:58.383734 [ 81 ] {f0a4f689-76f3-4342-ab8f-2e8349ca5970} <Trace> AccessRightsContext (default): Access granted: SELECT(d, x) ON test.partitioned_by_week\n-- 没有使用主键索引\n2020.06.27 10:29:58.383836 [ 81 ] {f0a4f689-76f3-4342-ab8f-2e8349ca5970} <Debug> test.partitioned_by_week (SelectExecutor): Key condition: unknown\n-- 分区索引被启动\n2020.06.27 10:29:58.383859 [ 81 ] {f0a4f689-76f3-4342-ab8f-2e8349ca5970} <Debug> test.partitioned_by_week (SelectExecutor): MinMax index condition: (column 0 in [10961, 10961])\n-- 借助date类型的分区索引，本次查询仅扫描了一个分区目录\n2020.06.27 10:29:58.383878 [ 81 ] {f0a4f689-76f3-4342-ab8f-2e8349ca5970} <Debug> test.partitioned_by_week (SelectExecutor): Selected 1 parts by date, 1 parts by key, 1 marks to read from 1 ranges\n-- 最终需要读取到内存的预估数据量是1行\n2020.06.27 10:29:58.383924 [ 81 ] {f0a4f689-76f3-4342-ab8f-2e8349ca5970} <Trace> test.partitioned_by_week (SelectExecutor): Reading approx. 8192 rows with 1 streams\n2020.06.27 10:29:58.383968 [ 81 ] {f0a4f689-76f3-4342-ab8f-2e8349ca5970} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\n2020.06.27 10:29:58.384464 [ 81 ] {f0a4f689-76f3-4342-ab8f-2e8349ca5970} <Information> executeQuery: Read 1 rows, 3.00 B in 0.001 sec., 915 rows/sec., 2.68 KiB/sec.\n2020.06.27 10:29:58.384501 [ 81 ] {f0a4f689-76f3-4342-ab8f-2e8349ca5970} <Debug> MemoryTracker: Peak memory usage (for query): 0.00 B.\n2020.06.27 10:29:58.384574 [ 81 ] {} <Debug> MemoryTracker: Peak memory usage (total): 0.00 B.\n2020.06.27 10:29:58.384595 [ 81 ] {} <Information> TCPHandler: Processed in 0.002 sec.\n```\n\n### 2、MergeTree数据分区规则\n\n​\t从插入数据过程中，数据分区目录的变化可以看出，MergeTree的分区目录不是在表创建的时候就存在的，而是在写入数据的过程中被创建出来，也就是说如果仅创建了表结构，没有任何数据的时候，是不会有分区目录存在的。\n\n- MergeTree数据分区目录命名规则\n\n  利用上面的示例数据，我们可以看到数据目录都是类似于`19991227_1_1_0`的格式，它们是由MergeTree自己的规则来命名的，规则为`PartitionID_MinBlockNum_MaxBlockNum_Level`\n\n  示例数据中19991227 表示分区目录的ID，1_1 分别表示最小的数据块编号和最大的数据块编号，最后的_0 表示目前分区合并的层级\n\n****\n\n​\t各部分的含义及命名规则如下：\n\n- `PartitionID`：MergeTree数据分区的规则是由分区ID来决定，分区ID的值则是由插入数据时分区键的取值来决定的。分区键支持使用任何一个或一组字段表达式来声明，针对取值数据类型的不同，分区ID的生成逻辑目前有四种规则\n\n  - 不指定分区键：如果建表时未指定分区键，则分区ID默认使用all，所有数据都被写入all分区中\n\n  - 整型字段：如果分区键取值是整型字段，并且无法转换为YYYYMMDD的格式，则会按照该整型字段的字符形式输出，作为分区ID取值\n\n  - 日期类型：如果分区键属于日期格式，或可以转换为YYYYMMDD格式的整型，则按照YYYYMMDD格式化后的字符形式输出，作为分区ID取值\n\n  - 其他类型：如果使用其他类似Float、String等类型作为分区键，会通过对其插入数据的128位Hash值作为分区ID的取值  \n\n  - ![](ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMergeTree%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA/fenqu_1.png)\n\n    \n\n- `MinBlockNum`和`MaxBlockNum`：BlockNum是一个整型的自增长型编号，该编号在单张MergeTree表中从1开始全局累加，当有新的分区目录创建后，该值就加1，对新的分区目录来讲，MinBlockNum和MaxBlockNum取值相同。例如上面示例数据为`19991227_1_1_0`和`20000103_2_2_0`，但当分区目录进行合并后，取值规则会发生变化\n\n- `Level`：表示合并的层级。相当于某个分区被合并的次数，它不是以表全局累加，而是以分区为单位，初始创建的分区，初始值为0，相同分区ID发生合并动作时，在相应分区内累计加1\n\n## 二、MergeTree数据分区合并规则\n\n​\t示例数据以周为分区，可以看出`2000-01-02, 2`和`2000-01-03, 3`两条数据最终产生了两个相同分区ID的数据目录`20000103_2_2_0`和`20000103_3_3_0`，由于它们是通过两条不同的sql插入进去的数据，所以，在ClickHouse中，即使数据属于相同分区，不同批次写入的数据，MergeTree都会生成不同的分区目录，对于同一个分区而言，会存在多个分区目录的情况。\n\n​\tMergeTree可以通过分区合并将属于相同分区的多个目录合并为一个新的目录(官方描述在10到15分钟内会进行合并<控制该值的参数目前还未找到>，也可直接执行optimize语句)，已经存在的就目录在之后某个时刻通过后台任务被删除(默认8分钟之后，暂未找到控制该值的参数)。\n\n### 1、合并分区后的命名规则\n\n​\t同个分区的数据目录合并后会产生一个新的目录，目录中的索引和数据文件也会进行合并，新目录的命名规则如下：\n\n- PartitionID：分区ID保持不变\n- MinBlockNum：取同一个分区内所有目录中最小的MinBlockNum值\n- MaxBlockNUm：取同一个分区内所有目录中最大的MaxBlockNum值\n- Level：取同一个分区内最大Level值并加1\n\n### 2、示例\n\n​\t按照示例的两个数据目录以及合并的命名规则，可以得到新的数据目录中PartitionID仍然为`20000103`，MinBlockNum取两个目录中该值的最小值为2，MaxBlockNum取该值的最大值为3，Level原目录都为0加1等于1，故合并后的目录名称为`20000103_2_3_1`。\n\n<img src=\"ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMergeTree%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA/fenqu_2.png\" style=\"zoom:50%;\" />\n\n​\t再次插入一个20000103分区的数据进行合并后的目录名称会为`20000103_2_4_2`，过程如下：\n\n1. 插入数据\n\n``` sql\n-- 插入一条新的数据\nclickhouse-server_1 :) insert into partitioned_by_week(d, x) values('2000-01-04', 4)\n\nINSERT INTO partitioned_by_week (d, x) VALUES\n\nOk.\n\n1 rows in set. Elapsed: 0.002 sec. \n\nclickhouse-server_1 :) select * from partitioned_by_week\n\nSELECT *\nFROM partitioned_by_week\n\n┌──────────d─┬─x─┐\n│ 2000-01-03 │ 3 │\n│ 2000-01-05 │ 4 │\n└────────────┴───┘\n┌──────────d─┬─x─┐\n│ 2000-01-01 │ 1 │\n│ 2000-01-02 │ 2 │\n└────────────┴───┘\n┌──────────d─┬─x─┐\n│ 2000-01-04 │ 4 │\n└────────────┴───┘\n\n5 rows in set. Elapsed: 0.002 sec. \n```\n\n2. 产生新的数据目录\n\n``` bash\n[root@xxxx test]# ll partitioned_by_week/\ntotal 4\ndrwxr-x--- 2 101 101 221 Jun 13 17:18 19991227_1_1_0\ndrwxr-x--- 2 101 101 221 Jun 27 11:26 20000103_2_3_1\ndrwxr-x--- 2 101 101 221 Jun 27 12:12 20000103_4_4_0\ndrwxr-x--- 2 101 101  10 Jun 13 17:15 detached\n-rw-r----- 1 101 101   1 Jun 13 17:15 format_version.txt\n```\n\n3. 进行合并\n\n``` sql\nclickhouse-server_1 :) optimize table partitioned_by_week\n\nOPTIMIZE TABLE partitioned_by_week\n\nOk.\n\n0 rows in set. Elapsed: 0.002 sec.\n```\n\n4. 合并后数据目录发生变化\n\n``` bash\n# 旧数据目录20000103_2_3_1和20000103_4_4_0会在一段时间后被后台删除\n[root@xxxx test]# ll partitioned_by_week/\ntotal 4\ndrwxr-x--- 2 101 101 221 Jun 13 17:18 19991227_1_1_0\ndrwxr-x--- 2 101 101 221 Jun 27 11:26 20000103_2_3_1\ndrwxr-x--- 2 101 101 221 Jun 27 12:14 20000103_2_4_2\ndrwxr-x--- 2 101 101 221 Jun 27 12:12 20000103_4_4_0\ndrwxr-x--- 2 101 101  10 Jun 13 17:15 detached\n-rw-r----- 1 101 101   1 Jun 13 17:15 format_version.txt\n```\n\n​\t可以看到，分区目录发生合并之后，旧分区目录不会被立即删除，此时旧分区目录在`system.parts`分区详情表中状态会处于未激活状态(active=0)，故查询数据时，这部分分区的数据会被自动过滤。","tags":["clickhouse","engine","MergeTree"],"categories":["clickhouse"]},{"title":"ClickHouse存储引擎之MergeTree引擎——概述","url":"/2020/06/11/clickhouse/存储引擎/ClickHouse存储引擎之MergeTree引擎——概述/","content":"\n## 一、MergeTree系列引擎概述\n\n​\t在ClickHouse中，存储引擎决定了一张表拥有哪些特性以及读写数据的方式等。在所有的存储引擎中，MergeTree及其*MergeTree系列是最强大的表引擎，它适用于一些高负载任务，可以快速插入数据并在后台进行数据处理，还支持了主键索引、分区、数据复制等一些其他引擎不支持的功能。\n\n​\t该类型的引擎包括：\n\n- MergeTree\n\n- Replacing MergeTree\n\n- Summing MergeTree\n\n- Aggregating MergeTree\n\n- Collapsing MergeTree\n\n- Versioned Collapsing MergeTree\n\n- Graphite MergeTree\n\n  其中，MergeTree引擎具备了这一系列引擎的基本特征，是*MergeTree系列引擎的基础，需要注意的是***MergeTree引擎并不属于*MergeTree系列**\n\n## 二、MergeTree(合并树)引擎\n\n​\tMergeTree插入的数据会直接写入文件系统，故它仅适用于批量插入数据，而不适合频繁插入单行数据的情况，MergeTree在写入一批数据时，数据会以不可修改的数据片段形式写入到磁盘中，同时为了避免数据片段过多，ClickHouse会通过后台线程，定期合并数据片段，属于相同分区的数据片段会被合并为一个新的片段。\n\n### 1、创建方式\n\n``` sql\n-- MergeTree引擎表的创建格式为\nCREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]\n(\n    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1] [TTL expr1],\n    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2] [TTL expr2],\n    ...\n    INDEX index_name1 expr1 TYPE type1(...) GRANULARITY value1,\n    INDEX index_name2 expr2 TYPE type2(...) GRANULARITY value2\n) ENGINE = MergeTree()\nORDER BY expr\n[PARTITION BY expr]\n[PRIMARY KEY expr]\n[SAMPLE BY expr]\n[TTL expr [DELETE|TO DISK 'xxx'|TO VOLUME 'xxx'], ...]\n[SETTINGS name=value, ...]\n```\n\n****\n\n### 2、配置参数介绍\n\n1. 必填项：\n\n- `ENGINE`：指定使用的引擎。\n- `ORDER BY`：排序键，用于指定在一个数据片段内，使用的排序方式。\n  - 当未指定排序键时，默认会使用主键排序，同样的，当未指定主键时，默认会使用排序键作为主键\n  - 可以是单列名称或多列字段的元组格式。例如：`ORDER BY (CounterId)`或``ORDER BY (CounterID, EventDate)`\n  - 当使用多列字段排序，例如`ORDER BY (CounterID, EventDate)`，在单个数据片段内，会先根据CounterID字段排序，CounterID相同的数据再按照EventDate排序\n\n2. 可选项：\n\n- `PARITION BY`：分区键\n- `PRIMARY KEY`：主键，指定后会按照主键字段生成一级索引，用于加速表查询。默认情况下与`ORDER BY`子句相同，否则的话主键表达式必须为排序表达式元组的前缀。主键声明后，单个数据片段内会按照主键字段升序排序。**MergeTree主键允许数据重复。**\n- `SAMPLE BY`：抽样表达式。若指定了该选项，则主键也必须包含它。例如：`...ENGINE = MergeTree() ORDER BY (CounterID, EventDate, intHash32(UserID)) SAMPLE BY intHash32(UserID)`\n- `TTL`：数据生存期，用于指定数据的存储时间。\n  - 表达式中必须包含一个`Date`或`DateTime`类型的列，例如：`TTL date + INTERVAL 1 DAY`，默认当表中数据达到这个时间时，会删除对应的数据信息\n  - 也可对满足该表达式的数据进行对应操作，例如：`TTL date + INTERVAL 1 MONTH DELETE|TO DISK 'xxx'`，对满足表达式的数据，表中删除过期的行并移动到指定的磁盘上\n  - 可以指定多个规则的操作，但只能有一个`DELETE`操作\n- `SETTING`：控制MergeTree的其他可选参数\n  - `index_granularity`：索引粒度，默认值为8192。表示在默认情况下，clickhouse每间隔8192条数据生成一条索引\n  - `index_granularity_bytes`：索引粒度，早期版本只允许`index_granularity`参数按照间隔数据条数设置索引粒度，后续版本支持该参数设置数据量大小限制索引粒度，默认值为10M，设置为0表示不启动根据数据量自适应功能\n  - `enable_mixed_granularity_parts`：表示是否开启自适应限制索引粒度的功能，默认开启\n  - `merge_with_ttl_timeout`：TTL合并频率的最小时间间隔，默认值为86400(1天)\n  - `use_minimalistic_part_header_in_zookeeper`：设置数据片段头部在zookeeper中的存储方式\n  - `min_merge_bytes_to_use_direct_io`：当数据量大于这个值时，使用直接I/O来读取数据并进行合并操作，默认值为10G，设置为0时表示禁用直接I/O\n  - `storage_policy`：设置存储策略\n\n## 三、MergeTree存储结构\n\n``` sql\n-- 创建测试数据库\nclickhouse-server_1 :) CREATE TABLE test.partitioned_by_week(d Date, x UInt8) ENGINE = MergeTree PARTITION BY toMonday(d) ORDER BY x;\n\nCREATE TABLE test.partitioned_by_week\n(\n    `d` Date, \n    `x` UInt8\n)\nENGINE = MergeTree\nPARTITION BY toMonday(d)\nORDER BY x\n\nOk.\n\n0 rows in set. Elapsed: 0.002 sec. \n\n-- 插入两条测试数据\nclickhouse-server_1 :) INSERT INTO test.partitioned_by_week VALUES ('2000-01-01', 1), ('2000-01-02', 2), ('2000-01-03', 3);\n\nINSERT INTO test.partitioned_by_week VALUES\n\nOk.\n\n3 rows in set. Elapsed: 0.070 sec. \n\n-- test库下的表\nclickhouse-server_1 :) show tables;\n\nSHOW TABLES\n\n┌─name────────────────┐\n│ partitioned_by_week │\n└─────────────────────┘\n\n1 rows in set. Elapsed: 0.007 sec. \n```\n\n​\t执行上述操作后，查看clickhouse中test库下的数据目录如下：\n\n<img src=\"ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMergeTree%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E6%A6%82%E8%BF%B0/mergetree1.png\" style=\"zoom:45%;\" />\n\n​\t可以看出，一张表完整的物理结构由表目录、分区目录、数据文件作为层级组成，他们各自的作用如下：\n\n- partition：分区目录\n\n  - 测试数据中分区目录为`19991227_1_1_0`和`20000103_2_2_0`，属于相同分区的数据，会被合并到同一个分区目录中\n\n- checksums.txt：校验文件\n\n  - 按二进制格式存储，保存了剩余数据文件的大小及其哈希值，用于快速校验数据文件的完整性和准确性\n\n- columns.txt：列信息文件\n\n  - 使用明文存储，用于保存该分区目录下的列字段信息。例如：\n\n  ``` bash\n  [root@xxxx test]# cat partitioned_by_week/19991227_1_1_0/columns.txt \n  columns format version: 1\n  2 columns:\n  `d` Date\n  `x` UInt8\n  ```\n\n- count.txt：计数文件\n\n  - 使用明文存储，记录保存了当前数据分区目录下的数据行数。例如：\n\n  ``` bash\n  [root@xxxx test]# cat partitioned_by_week/19991227_1_1_0/count.txt \n  2\n  ```\n\n- primary.idx：一级索引文件\n\n  - 使用二进制格式存储。用于存放稀疏索引，一张MergeTree通过ORDER BY或PRIMARY KEY只能声明一个一级索引\n\n- [column].bin：数据文件\n\n  - 默认使用LZ4压缩格式存储。用来存放该数据分区的某列的数据。MergeTree采用了列式存储，故每列字段都有独立的bin数据文件，以列名命名。\n  \n- [column].mrk或[column].mrk2：列字段标记文件\n\n  - 使用二进制格式存储。保存了[column].bin文件的偏移量信息，MergeTree通过该文件建立了primary.idx稀疏索引与[column].bin文件之间的映射关系。它会先通过primary.idx找到对应数据的偏移量信息column.mrk，再通过偏移量直接从[column].bin文件中读取数据。该文件与[column].bin文件一一对应，也是每列字段都有独立的mrk文件，如果使用了自适应大小的索引间隔，会以.mrk2命名\n\n- partition.dat和minmax_d.idx：分区索引文件\n\n  - 当使用了分区键，例如`PARTITION BY toMonday(d)`，便会生成partition.dat和minmax_d.idx索引文件，均适用二进制格式存储。\n  - partition.dat用于保存当前分区下，分区表达式最终生成的值\n  - minmax_d.idx用于记录当前分区下，分区字段对应原始数据的最小和最大值\n\n","tags":["clickhouse","engine","MergeTree"],"categories":["clickhouse"]},{"title":"ClickHouse存储引擎之MySQL引擎","url":"/2020/06/09/clickhouse/存储引擎/ClickHouse存储引擎之MySQL引擎/","content":"\n## 一、介绍\n\n​\tClickHouse提供了MySQL库引擎可以将MySQL中的表映射到ClickHouse中，并允许用户通过clickhouse对数据进行insert和update操作。实际的操作其实都在**MySQL服务器上完成**，MySQL引擎会将查询转换为MySQL语法并发送到MySQL服务器上面并实现数据交互，但无法通过clickhouse对MySQL数据执行rename、create table、alter等操作。\n\n## 二、使用\n\n### 1、ClickHouse建库语法\n\n``` sql\nCREATE DATABASE [IF NOT EXISTS] db_name [ON CLUSTER cluster]\nENGINE = MySQL('host:port', 'database', 'user', 'password')\n```\n\n**MySQL引擎参数：**\n\n1. `host:port`:MySQL地址\n2. `database`:MySQL数据库名，不指定则表示全部映射\n3. `user`:使用的用户名\n4. `password`:用户密码\n\n### 2、使用示例\n\n#### 2.1 环境准备\n\n``` sql\n-- 创建映射库，本次使用的clickhouse是由docker启动的，故使用以下命令进入clickhouse客户端\n[root@xxxx docker_compose]# docker exec -it 817eeb4e2569 clickhouse-client\n-- 用户需有对应操作的权限\nclickhouse-server_1 :) create database test_4098 \\\n:-] ENGINE = MySQL('x.x.x.x:4098', 'dbzz_dbreport', \\\n:-] 'dba', 'xxxxxx')\n\nCREATE DATABASE test_4098\nENGINE = MySQL('x.x.x.x:4098', 'dbzz_dbreport', 'dba', 'xxxxxx')\n\nOk.\n\n0 rows in set. Elapsed: 0.030 sec. \n\nclickhouse-server_1 :) show databases;\n\nSHOW DATABASES\n\n┌─name──────┐\n│ datasets  │\n│ default   │\n│ system    │\n│ test      │\n│ test_4098 │\n└───────────┘\n\n5 rows in set. Elapsed: 0.002 sec. \n-- 创建成功之后在MySQL数据库中执行 show processlist; 可以看到成功创建的连接\n\n-- 在对应MySQL库上面创建一个测试表，并插入一条数据\n(dba:4098)@[dbzz_dbreport]>create table clickhouse_test_table (\n    -> `int_id` INT NOT NULL AUTO_INCREMENT,\n    -> `float` FLOAT NOT NULL,\n    -> PRIMARY KEY (`int_id`));\nQuery OK, 0 rows affected (0.09 sec)\n(dba:4098)@[dbzz_dbreport]>insert into clickhouse_test_table values(1, 2); \nQuery OK, 1 row affected (0.04 sec)\n```\n\n<img src=\"ClickHouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8BMySQL%E5%BC%95%E6%93%8E/MySQL_engine1.png\" style=\"zoom:33%;\" />\n\n​\t上图所在的metadata目录是clickhouse的元数据目录，里面记录了所有建库、建表的语句，可以看出本次测试的test_4098库仅有建库语句，表并不是通过clickhouse创建的；上一级的data目录记录了所有库具体的数据文件信息，可看出并没有test_4098和test_4098_ro库相关数据信息。\n\n#### 2.2 clickhouse测试\n\n- 在clickhouse上执行show tables\n\n```bash\n# clickhouse对应日志如下，可以看到将show tables语句转换为了SELECT name FROM system.tables WHERE database = 'test_4098'语句\n2020.06.10 16:10:12.871697 [ 81 ] {3c0db0d4-5f48-4896-8418-6d1e0211a3c8} <Debug> executeQuery: (from 127.0.0.1:55258) SHOW TABLES\n2020.06.10 16:10:12.871899 [ 81 ] {3c0db0d4-5f48-4896-8418-6d1e0211a3c8} <Debug> executeQuery: (internal) SELECT name FROM system.tables WHERE database = 'test_4098'\n2020.06.10 16:10:12.872213 [ 81 ] {3c0db0d4-5f48-4896-8418-6d1e0211a3c8} <Trace> AccessRightsContext (default): Access granted: SELECT(database, name) ON system.tables\n2020.06.10 16:10:12.872344 [ 81 ] {3c0db0d4-5f48-4896-8418-6d1e0211a3c8} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\n2020.06.10 16:10:12.872580 [ 99 ] {3c0db0d4-5f48-4896-8418-6d1e0211a3c8} <Trace> AccessRightsContext (default): Access granted: SHOW ON *.*\n2020.06.10 16:10:12.876803 [ 81 ] {3c0db0d4-5f48-4896-8418-6d1e0211a3c8} <Information> executeQuery: Read 27 rows, 1.36 KiB in 0.005 sec., 5360 rows/sec., 269.67 KiB/sec.\n2020.06.10 16:10:12.876840 [ 81 ] {3c0db0d4-5f48-4896-8418-6d1e0211a3c8} <Debug> MemoryTracker: Peak memory usage (for query): 0.00 B.\n2020.06.10 16:10:12.876934 [ 81 ] {} <Debug> MemoryTracker: Peak memory usage (total): 0.00 B.\n2020.06.10 16:10:12.876956 [ 81 ] {} <Information> TCPHandler: Processed in 0.005 sec.\n```\n\n- clickhouse上查询表中信息\n\n``` sql\n-- 执行对应表查询\nclickhouse-server_1 :) select * from clickhouse_test_table;\n\nSELECT *\nFROM clickhouse_test_table\n\n┌─int_id─┬─float─┐\n│      1 │     2 │\n└────────┴───────┘\n\n1 rows in set. Elapsed: 0.034 sec. \n\n-- clickhouse日志显示，可以看到会先和对应的MySQL实例建立连接\n-- 查询语句被转换为了 SELECT(int_id, float) ON test_4098.clickhouse_test_table \n2020.06.10 16:13:14.851866 [ 81 ] {54864811-5b01-4f41-9abf-b4280e7c277b} <Debug> executeQuery: (from 127.0.0.1:55258) SELECT * FROM clickhouse_test_table\n2020.06.10 16:13:14.864183 [ 81 ] {54864811-5b01-4f41-9abf-b4280e7c277b} <Trace> AccessRightsContext (default): Access granted: SELECT(int_id, float) ON test_4098.clickhouse_test_table\n2020.06.10 16:13:14.868456 [ 81 ] {54864811-5b01-4f41-9abf-b4280e7c277b} <Information> Application: MYSQL: Connecting to dbzz_dbreport@10.148.16.25:4098 as user dba\n2020.06.10 16:13:14.880487 [ 81 ] {54864811-5b01-4f41-9abf-b4280e7c277b} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\n2020.06.10 16:13:14.882556 [ 81 ] {54864811-5b01-4f41-9abf-b4280e7c277b} <Information> executeQuery: Read 1 rows, 8.00 B in 0.031 sec., 32 rows/sec., 261.44 B/sec.\n2020.06.10 16:13:14.882602 [ 81 ] {54864811-5b01-4f41-9abf-b4280e7c277b} <Debug> MemoryTracker: Peak memory usage (for query): 0.00 B.\n2020.06.10 16:13:14.884205 [ 81 ] {} <Debug> MemoryTracker: Peak memory usage (total): 0.00 B.\n2020.06.10 16:13:14.884845 [ 81 ] {} <Information> TCPHandler: Processed in 0.033 sec.\n\n-- 打开MySQL全日志后，看到所有操作均在MySQL上执行\n2020-06-10T08:54:11.541873Z 74904749 Query  SELECT TABLE_NAME AS table_name,  CREATE_TIME AS modification_time  FROM INFORMATION_SCHEMA.TABLES  WHERE TABLE_SCHEMA = 'dbzz_dbreport'\n2020-06-10T08:54:11.545698Z 74904749 Query  SELECT TABLE_NAME AS table_name,  CREATE_TIME AS modification_time  FROM INFORMATION_SCHEMA.TABLES  WHERE TABLE_SCHEMA = 'dbzz_dbreport'\n2020-06-10T08:54:11.549140Z 74904749 Query  SELECT TABLE_NAME AS table_name,  CREATE_TIME AS modification_time  FROM INFORMATION_SCHEMA.TABLES  WHERE TABLE_SCHEMA = 'dbzz_dbreport'\n2020-06-10T08:54:11.552753Z 74904749 Query  SELECT TABLE_NAME AS table_name,  CREATE_TIME AS modification_time  FROM INFORMATION_SCHEMA.TABLES  WHERE TABLE_SCHEMA = 'dbzz_dbreport'\n2020-06-10T08:54:11.556415Z 75644195 Query  SELECT `int_id`, `float` FROM `dbzz_dbreport`.`clickhouse_test_table`\n```\n\n- 在clickhouse上插入数据\n\n``` sql\n-- 执行对应插入数据操作\nclickhouse-server_1 :) insert into clickhouse_test_table values(3,4)\n\nINSERT INTO clickhouse_test_table VALUES\n\nOk.\n\n1 rows in set. Elapsed: 0.042 sec.\n\n-- clickhouse日志显示：在连接已经存在的情况下，可以看到进行权限检查后执行了insert操作\n2020.06.10 16:18:51.172346 [ 81 ] {2a1b1d66-dfed-460e-89fe-e7cc9ae3cfa6} <Debug> executeQuery: (from 127.0.0.1:55258) insert into clickhouse_test_table values\n2020.06.10 16:18:51.177580 [ 81 ] {2a1b1d66-dfed-460e-89fe-e7cc9ae3cfa6} <Trace> AccessRightsContext (default): Access granted: INSERT(int_id, float) ON test_4098.clickhouse_test_table\n2020.06.10 16:18:51.209389 [ 81 ] {2a1b1d66-dfed-460e-89fe-e7cc9ae3cfa6} <Debug> MemoryTracker: Peak memory usage (for query): 0.00 B.\n2020.06.10 16:18:51.209481 [ 81 ] {} <Debug> MemoryTracker: Peak memory usage (total): 0.00 B.\n2020.06.10 16:18:51.209545 [ 81 ] {} <Information> TCPHandler: Processed in 0.037 sec.\n\n-- 解析MySQL二进制日志，可看出写入操作在MySQL上进行\nBEGIN\n/*!*/;\n# at 340\n#200610 16:18:51 server id 210894098  end_log_pos 415 CRC32 0x46a5ba76  Table_map: `dbzz_dbreport`.`clickhouse_test_table` mapped to number 2067\n# at 415\n#200610 16:18:51 server id 210894098  end_log_pos 459 CRC32 0xd8f0a3ac  Write_rows: table id 2067 flags: STMT_END_F\n### INSERT INTO `dbzz_dbreport`.`clickhouse_test_table`\n### SET\n###   @1=3\n###   @2=4                   \n# at 459\n#200610 16:18:51 server id 210894098  end_log_pos 490 CRC32 0xcb88aafc  Xid = 36747174953\nCOMMIT/*!*/;\n```\n\n\n\n","tags":["clickhouse","engine"],"categories":["clickhouse"]},{"title":"ClickHouse存储引擎概述","url":"/2020/05/23/clickhouse/存储引擎/clickhouse存储引擎概述/","content":"\n本篇内容参考：[clickhouse官方文档](https://clickhouse.tech/docs/zh/engines/table-engines/)\n\n## 一、ClickHouse引擎的作用\n\n​\tClickHouse引擎可分为库引擎和表引擎。ClickHouse引擎的作用基本如下：\n\n- 数据的存储方式和位置：例如log系列引擎将数据写入在磁盘上，而Special系列的引擎将数据写入在内存上，但Distributed引擎并不存储书籍，仅作为中间件转发\n- 支持的哪些查询方式：例如log系列引擎不支持update和delete操作\n- 是否支持并发访问数据，是否可以执行多线程的请求：例如TinyLog引擎不支持并发读取，而Log引擎支持并发读取\n- 是否可以使用索引：例如log系列引擎并不支持使用索引\n- 数据如何进行复制：不同的存储引擎进行数据复制的参数完全不同\n\n## 二、ClickHouse库引擎分类\n\nClickHouse目前支持5种库引擎：\n\n- Ordinary：默认引擎。在该引擎下可以使用任何类型的表引擎\n- Dictionary：字典引擎。这种引擎的数据库会自动为所有的数据字典创建它们的数据表\n- Memory：内存引擎。用于存放临时数据，这种引擎的数据库下的表只会停留在内存中，不涉及任何磁盘操作，服务重启后数据会被清除\n- Lazy：日志引擎。该类数据库只能只用Log系列的表引擎\n- MySQL引擎。该类数据库会自动拉取远端MySQL中的数据，并创建MySQL表引擎的数据表。\n\n## 三、ClickHouse表引擎分类\n\n​\tClickHouse提供了大概27种适用于不同情况的表引擎，其中整体大概分为4类，分类大致如下图所示：\n\n<img src=\"clickhouse%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E6%A6%82%E8%BF%B0/%E8%A1%A8%E5%BC%95%E6%93%8E.jpeg\" style=\"zoom:30%;\" />\n\n​\tClickHouse主要将表引擎分为了四类：\n\n- MergeTree系列是主要适用的存储引擎，几乎可以支持clickhouse的所有功能使用\n- Log系列主要适用于快速小表写入，全部读出的场景，但之间仍存在查询性能的区别\n- Integration系列主要用于将外部数据导入到clickhosue中，或直接在clickhouse中处理其他的数据。例如之前使用过MySQL表引擎在clickhouse中连接到MySQL数据库，直接针对其数据进行查询\n- Special系列大多数是为了一些特殊的场景来进行的处理：例如Distributed本身不存储数据，一般作为中间件执行数据聚合等操作返回给用户；Memory将数据写入到内存中，服务重启数据丢失，一般用来做临时表；Null直接将写入数据丢弃，读取时为空，但适合用来作为视图使用等。\n\n\n\n​\t具体每类表引擎中各个引擎的区别及使用方法会在后续文档中分别进行描述，重点会在于MergeTree和log系列。其余引擎会简单描述其适用场景。\n\n","tags":["clickhouse","engine"],"categories":["clickhouse"]},{"title":"行存与列存的简单对比","url":"/2020/04/25/DB/行存与列存的简单对比/","content":"\n## 一、行式存储\n\n​\t\t一般的事务型数据库(OLTP)基本会增删改查同一行数据，故大多使用了行式存储，所有数据按列名排成一行，可通过主键快速找到对应的那行数据，基本数据存储情况如下表。\n\n| 编号 | 姓名 | 年龄 | 居住地 | 学位 |\n| ---- | ---- | ---- | ------ | ---- |\n| 1    | 张三 | 20   | 北京   | 本科 |\n| 2    | 李四 | 21   | 上海   | 硕士 |\n| 3    | 王五 | 22   | 广州   | 博士 |\n\n​\t\t物理存储格式基本如下：\n\n<img src=\"行存与列存的简单对比/1.png\" style=\"zoom:50%;\" />\n\n## 二、列式存储\n\n​\t\t一般OLAP系统需要查询大量的数据，但仅需要关注其中几个列的数据，基于使用情况，一般会使用列式存储。同样的数据按列存储，基本数据存储情况为：\n\n| 1    | 2    | 3    |\n| ---- | ---- | ---- |\n| 张三 | 李四 | 王五 |\n| 20   | 21   | 22   |\n| 北京 | 上海 | 广州 |\n| 本科 | 硕士 | 博士 |\n\n​\t\t物理存储格式基本如下：\n\n<img src=\"行存与列存的简单对比/2.png\" style=\"zoom:50%;\" />\n\n## 三、读写对比\n\n### 1、数据写入\n\n1. 按照上述示例结构，行存储写入一条数据仅需一次便可直接完成，并且可以保证数据完整性\n2. 列存储上述示例数据写入一条数据，需要拆成五列进行保存，写入次数比行存储翻了五倍，实际写入时间会更长\n\n### 2、数据修改\n\n1. 若需要修改一条数据，行存储到指定位置写入一次即可，列存储需要定位到多个位置进行写入，按上述示例数据，列存储所需次数仍是行存储的5倍\n\n### 3、数据读取\n\n1. 读取某行数据时，行存储会将该条记录的所有数据读出，若仅需要其中某列的数据，则存在了数据冗余，通常会消耗内存来消除这些冗余列数据\n2. 列存储读取的均为所需要的某一段数据，不存在冗余列的数据\n3. 由于行存储读取的数据包含了多种类型，可能存在数据类型之间的转换从而对数据进行解析，列存储读出的每一段数据的类型均相同，不需要对数据进行类型转换，可以使用不同方法对不同类型进行数据压缩，列存储更有利于对大数据进行分析\n\n## 四、适用场景\n\n​\t简单来讲，行存储更适合于OLAP场景，列存储更适合于OLTP场景。\n\n​\t当经常需要对某些行进行增删改，无法进行批处理操作，经常关注整张表的结构和数据而不只是某几列的数据，对获取到的数据也并没有很大二次计算处理的需求，此时更适合使用行存储。\n\n​\t若写数据的操作可以进行批量处理，并且经常需要对读取的数据进行聚合运算分析场景时，更适合使用列存储，这是由于列式存储可以对字段数据进行向量化处理，可以将一个列的一整个字段连续读入CPU cache中，可以利用CPU的向量化处理并进行一些常用的计算等操作。\n\n## 五、ClickHouse查询写入测试\n\n### 1、测试数据导入 \n\n​\t\t本次ClickHouse使用官方提供的Yandex.Metrica Data测试数据来进行测试，其中包含两张表visit_v1(访问数据)和hits_v1(Yandex.Metrica提供的查询匹配数据)，安装流程可参考[ClickHouse测试数据导入](https://clickhouse.tech/docs/en/getting_started/example_datasets/metrica/)，由于官方提供的导入方式前提为直接安装了clickhouse服务，而之前一直使用docker方式来进行安装，所以这里简单描述docker环境下如何导入测试数据。\n\n``` bash\n# 使用了docker-compose打包了clickhouse镜像\n## 1. 下载并解压测试数据\n[root@xxxx clickhouse]# curl https://clickhouse-datasets.s3.yandex.net/hits/tsv/hits_v1.tsv.xz | unxz --threads=`nproc` > hits_v1.tsv\n[root@xxxx clickhouse]# curl https://clickhouse-datasets.s3.yandex.net/visits/tsv/visits_v1.tsv.xz | unxz --threads=`nproc` > visits_v1.tsv\n## 2. 在docker-compose配置文件中volume中添加一个地址和镜像中的对应\n[root@xxxx docker_compose]# ll\ntotal 28\n-rw-r--r--  1 root root 14907 Apr 30 15:49 config.xml\ndrwxr-xr-x 10  101  101   204 Apr 26 18:56 data\n-rw-r--r--  1 root root   733 Apr 26 18:46 docker-compose.yml\ndrwxr-xr-x  2 root root    80 Apr 30 15:53 log\ndrwxr-xr-x  2  101  101    58 Apr 30 15:41 tmp\n-rw-r--r--  1 root root  4532 Mar 30 17:43 users.xml\n[root@xxxx docker_compose]# vim docker-compose.yml\n    volumes:\n      ... \n      - ./tmp:/var/lib/clickhouse/tmp\n# 这里使用tmp目录存放下载的测试数据，映射到镜像中的/var/lib/clickhouse/tmp目录\n[root@xxxx docker_compose]# ll tmp/\ntotal 10197044\n-rw-r--r-- 1  101  101 7784351125 Apr 26 18:32 hits_v1.tsv\n-rw-r--r-- 1 root root 2657415178 Apr 30 15:41 visits_v1.tsv\n# docker clickhouse已经启动，进入docker环境导入数据即可\n[root(host/tjtx148-16-25.58os.org)@tjtx162-17-78 docker_compose]# docker ps\nCONTAINER ID        IMAGE                                                     COMMAND                  CREATED             STATUS                 PORTS                                                                              NAMES\n968b926da80b        clickhouse-server-demo:1.0                                \"/entrypoint.sh\"         3 days ago          Up 3 days              0.0.0.0:8123->8123/tcp, 0.0.0.0:9000->9000/tcp, 0.0.0.0:9004->9004/tcp, 9009/tcp   clickhouse-server_1\n## 3. 导入测试数据\n[root@xxxx docker_compose]# docker exec -it clickhouse-server_1 /bin/bash\nroot@clickhouse-server_1:/# ll /var/lib/clickhouse/tmp/\ntotal 10197044\ndrwxr-xr-x  2 clickhouse clickhouse         58 Apr 30 07:41 ./\ndrwxr-xr-x 10 clickhouse clickhouse        204 Apr 26 10:56 ../\n-rw-r--r--  1 clickhouse clickhouse 7784351125 Apr 26 10:32 hits_v1.tsv\n-rw-r--r--  1 root       root       2657415178 Apr 30 07:41 visits_v1.tsv\nroot@clickhouse-server_1:/# clickhouse-client --query \"CREATE DATABASE IF NOT EXISTS datasets\"\n... # 建表语句参考官方文档即可\n## 将visiit_v1.tsv测试数据导入，另外一张表hists_v1采用同样方法导入\nroot@clickhouse-server_1:/# cat visits_v1.tsv | clickhouse-client --query \"INSERT INTO datasets.visits_v1 FORMAT TSV\" --max_insert_block_size=100000\n\n## 4. 检验测试数据量\nroot@clickhouse-server_1:/# clickhouse-client \nClickHouse client version 20.3.4.10 (official build).\nConnecting to localhost:9000 as user default.\nConnected to ClickHouse server version 20.3.4 revision 54433.\n\nclickhouse-server_1 :) use datasets\n\nUSE datasets\n\nOk.\n\n0 rows in set. Elapsed: 0.002 sec. \n\nclickhouse-server_1 :) select count() from hits_v1;\n\nSELECT count()\nFROM hits_v1\n\n┌─count()─┐\n│ 8873898 │\n└─────────┘\n\n1 rows in set. Elapsed: 0.008 sec. \n\nclickhouse-server_1 :) select count() from visits_v1;\n\nSELECT count()\nFROM visits_v1\n\n┌─count()─┐\n│ 1676861 │\n└─────────┘\n\n1 rows in set. Elapsed: 0.002 sec.\n```\n\n### 2、查询语句测试\n\n​\t\t由于clickhouse本身并没有提供查看执行计划的命令，所以只能通过查看日志变相看到SQL语句的执行过程，下面将基于hits_v1表以及官方提供的SQL测试语句结合记录的日志来进行查询语句的测试，并且之后针对clickhouse会基于这两张表持续测试。\n\n#### 1. hits_v1表结构简单介绍\n\n```SQL\n## 这里为了后面的测试，简单介绍hits_v1的表结构，具体关于clickhouse的SQL描述在后面的文章中写出\nCREATE TABLE datasets.hits_v1 (`WatchID` UInt64, ...`RequestNum` UInt32, `RequestTry` UInt8) ENGINE = MergeTree() PARTITION BY toYYYYMM(EventDate) ORDER BY (CounterID, EventDate, intHash32(UserID)) SAMPLE BY intHash32(UserID) SETTINGS index_granularity = 8192\n```\n\nclickhouse中create table的基础语法为：\n\n``` sql\nCREATE TABLE [IF NOT EXISTS] [db.]table_name ON CLUSTER cluster\n(\n    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],\n    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],\n    ...\n    INDEX index_name1 expr1 TYPE type1(...) GRANULARITY value1,\n    INDEX index_name2 expr2 TYPE type2(...) GRANULARITY value2\n) ENGINE = engine_name()\n[PARTITION BY expr]\n[ORDER BY expr]\n[PRIMARY KEY expr]\n[SAMPLE BY expr]\n[SETTINGS name=value, ...];\n\n# 选项描述\n- db:指定数据库名称，若未指定，默认使用当前数据库\n- cluster: clickhouse中包含集群的概念，可对每个集群进行数据分片，创建分布式表，ON CLUSTER表示将在每个分片上都创建这个本地表，默认为default\n- type: 该列类型，例如UInt32，clickhouse大小写敏感，类型必须遵守严格的大小写格式\n- MATERIALIZED: 表示该列不能被修改，是通过其他列计算出来的数据并保存在表中，查询时并不需要即时计算，所以insert时不需要插入该列数据，select *查询时该列数据也不会显示\n- ALIAS: 类似于MATERIALIZED参数，但该列数据并不会保存在表中，每次需要时才会进行计算，同样的insert不能修改该列数据，select *时该列数据也不会显示\n\n# 由于hits_v1测试表使用的是MergeTree引擎，这里剩余参数针对MergeTree进行简单描述，其余引擎未必全部支持，关于各个引擎的描述及适用场景会在之后的文档中分开进行详细描述\n- PARTITION BY: 指定分区键，该测试表使用日期进行分区(EventDate)\n- ORDER BY: 指定排序键\n- PRIMARY KEY: 指定主键，默认与ORDER BY相同\n- SAMPLE BY: 抽样表达式\n- SETTING: 其他一些参数\n```\n\n#### 2. 分组排序查询\n\n```bash\n# SQL：\nclickhouse-server_1 :) select CounterID, count() AS c from hits_v1 group by CounterID order by c desc limit 10\n\nSELECT \n    CounterID, \n    count() AS c\nFROM hits_v1\nGROUP BY CounterID\nORDER BY c DESC\nLIMIT 10\n\n┌─CounterID─┬──────c─┐\n│   1704509 │ 523264 │\n│    732797 │ 475698 │\n│    598875 │ 337212 │\n│    792887 │ 252197 │\n│   3807842 │ 196036 │\n│  25703952 │ 147211 │\n│    716829 │  90109 │\n│     59183 │  85379 │\n│  33010362 │  77807 │\n│    800784 │  77492 │\n└───────────┴────────┘\n\n10 rows in set. Elapsed: 0.026 sec. Processed 8.87 million rows, 35.50 MB (339.77 million rows/s., 1.36 GB/s.) \n\n# log\n## 1. 查询语句\n2020.05.03 22:31:49.042192 [ 81 ] {d06708d7-2f0c-489f-96fe-e42012f641f0} <Debug> executeQuery: (from 127.0.0.1:59736) SELECT CounterID, count() AS c FROM hits_v1 GROUP BY CounterID ORDER BY c DESC LIMIT 10\n## 2. 用户权限验证\n2020.05.03 22:31:49.042790 [ 81 ] {d06708d7-2f0c-489f-96fe-e42012f641f0} <Trace> AccessRightsContext (default): Access granted: SELECT(CounterID) ON datasets.hits_v1\n## 3. 该SQL查询未使用主键索引\n2020.05.03 22:31:49.042971 [ 81 ] {d06708d7-2f0c-489f-96fe-e42012f641f0} <Debug> datasets.hits_v1 (SelectExecutor): Key condition: unknown\n## 4. 该SQL查询未使用分区索引\n2020.05.03 22:31:49.042986 [ 81 ] {d06708d7-2f0c-489f-96fe-e42012f641f0} <Debug> datasets.hits_v1 (SelectExecutor): MinMax index condition: unknown\n## 5. 该查询扫描了1个分区目录，共1092个MarkRange（分区目录和MarkRange在MergeTree中的意义还在理解中，后续在MergeTree引擎中详细描述）\n2020.05.03 22:31:49.043021 [ 81 ] {d06708d7-2f0c-489f-96fe-e42012f641f0} <Debug> datasets.hits_v1 (SelectExecutor): Selected 1 parts by date, 1 parts by key, 1092 marks to read from 1 ranges\n## 6. 全表扫描，共8873898条数据，共使用20个stream来进行查询处理数据\n2020.05.03 22:31:49.043381 [ 81 ] {d06708d7-2f0c-489f-96fe-e42012f641f0} <Trace> datasets.hits_v1 (SelectExecutor): Reading approx. 8873898 rows with 20 streams\n2020.05.03 22:31:49.044209 [ 81 ] {d06708d7-2f0c-489f-96fe-e42012f641f0} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\n2020.05.03 22:31:49.045627 [ 100 ] {d06708d7-2f0c-489f-96fe-e42012f641f0} <Trace> AggregatingTransform: Aggregating\n...\n...\n## 7. 每个stream查询的行数，使用时间等信息\n2020.05.03 22:31:49.050780 [ 100 ] {d06708d7-2f0c-489f-96fe-e42012f641f0} <Trace> AggregatingTransform: Aggregated. 572078 to 5872 rows (from 2.182 MiB) in 0.006 sec. (88841051.020 rows/sec., 338.902 MiB/sec.)\n2020.05.03 22:31:49.050814 [ 193 ] {d06708d7-2f0c-489f-96fe-e42012f641f0} <Trace> AggregatingTransform: Aggregated. 516096 to 7617 rows (from 1.969 MiB) in 0.006 sec. (80547357.953 rows/sec., 307.264 MiB/sec.)\n2020.05.03 22:31:49.051022 [ 191 ] {d06708d7-2f0c-489f-96fe-e42012f641f0} <Trace> AggregatingTransform: Aggregated. 450560 to 8195 rows (from 1.719 MiB) in 0.007 sec. (68053391.462 rows/sec., 259.603 MiB/sec.)\n## 8. 某一个stream进行数据merge操作\n2020.05.03 22:31:49.051046 [ 191 ] {d06708d7-2f0c-489f-96fe-e42012f641f0} <Trace> Aggregator: Merging aggregated data\n## 9. 共读取了8873898条数据，共33.85M\n2020.05.03 22:31:49.066350 [ 81 ] {d06708d7-2f0c-489f-96fe-e42012f641f0} <Information> executeQuery: Read 8873898 rows, 33.85 MiB in 0.024 sec., 368641453 rows/sec., 1.37 GiB/sec.\n2020.05.03 22:31:49.066415 [ 81 ] {d06708d7-2f0c-489f-96fe-e42012f641f0} <Debug> MemoryTracker: Peak memory usage (for query): 0.00 B.\n## 10. 查询共消耗了0.00B内存\n2020.05.03 22:31:49.066786 [ 81 ] {} <Debug> MemoryTracker: Peak memory usage (total): 0.00 B.\n## 11. 查询共使用了0.025s\n2020.05.03 22:31:49.066814 [ 81 ] {} <Information> TCPHandler: Processed in 0.025 sec.\n```\n\n#### 3. 使用主键索引\n\n``` bash\n# SQL:\nclickhouse-server_1 :) SELECT WatchID FROM hits_v1 WHERE CounterID = 67141\n\nSELECT WatchID\nFROM hits_v1\nWHERE CounterID = 67141\n\n┌─────────────WatchID─┐\n│ 9092821867385297764 │\n│ 6698385316098085730 │\n│ 8281386980251669809 │\n│ 7804373457861079090 │\n│ 5352419935083292124 │\n│ 7522442961486322437 │\n│ 4926733399374529578 │\n│ 8651569660825010330 │\n│ 7777215115402859170 │\n│ 5488491440763342147 │\n│ 7016898938173798841 │\n│ 7512073271455311672 │\n│ 7675183452718991621 │\n│ 7698094942612287474 │\n│ 7229580476946423672 │\n│ 8265472689024610766 │\n│ 7397061429050334296 │\n│ 5642502882079177996 │\n│ 5521967617262710331 │\n│ 6045376808846148744 │\n│ 5223813301270698276 │\n│ 5891294304736742075 │\n│ 7473702977877450342 │\n│ 7131227524298036078 │\n│ 6397036526472438783 │\n│ 5452801867475832050 │\n│ 8203620973862900075 │\n│ 8228211160680219393 │\n│ 5669672267661574263 │\n│ 6447542723619820343 │\n│ 5609776647750491151 │\n│ 5937976217944527938 │\n│ 8559139126342788142 │\n│ 6731577587255153490 │\n│ 7541590813574755789 │\n│ 6736741087826610411 │\n│ 5750208933466385975 │\n│ 6501641543222310031 │\n│ 6817897199087131799 │\n│ 8775895600472212626 │\n│ 7276707177012917444 │\n│ 7841417239216625313 │\n│ 6708893161493789316 │\n│ 5161987475887808662 │\n│ 5167052428932424884 │\n│ 8512404755681004329 │\n│ 5407707620324494582 │\n│ 7664508369041326595 │\n│ 6437220034025745400 │\n│ 5074053444698312956 │\n│ 5698931552063656743 │\n│ 8826145146896127905 │\n└─────────────────────┘\n\n52 rows in set. Elapsed: 0.003 sec. Processed 8.19 thousand rows, 98.30 KB (2.77 million rows/s., 33.19 MB/s.) \n\n# log\n2020.05.03 22:58:53.011895 [ 82 ] {55122f0e-83a7-454f-abed-870934d0f0a4} <Debug> executeQuery: (from 127.0.0.1:50236) SELECT WatchID FROM hits_v1 WHERE CounterID = 67141\n2020.05.03 22:58:53.012824 [ 82 ] {55122f0e-83a7-454f-abed-870934d0f0a4} <Trace> AccessRightsContext (default): Access granted: SELECT(WatchID, CounterID) ON datasets.hits_v1\n## 可以看到该条查询使用了主键索引\n2020.05.03 22:58:53.012985 [ 82 ] {55122f0e-83a7-454f-abed-870934d0f0a4} <Debug> datasets.hits_v1 (SelectExecutor): Key condition: (column 0 in [67141, 67141])\n2020.05.03 22:58:53.013000 [ 82 ] {55122f0e-83a7-454f-abed-870934d0f0a4} <Debug> datasets.hits_v1 (SelectExecutor): MinMax index condition: unknown\n2020.05.03 22:58:53.013032 [ 82 ] {55122f0e-83a7-454f-abed-870934d0f0a4} <Debug> datasets.hits_v1 (SelectExecutor): Selected 1 parts by date, 1 parts by key, 1 marks to read from 1 ranges\n2020.05.03 22:58:53.013210 [ 82 ] {55122f0e-83a7-454f-abed-870934d0f0a4} <Trace> datasets.hits_v1 (SelectExecutor): Reading approx. 8192 rows with 1 streams\n2020.05.03 22:58:53.013291 [ 82 ] {55122f0e-83a7-454f-abed-870934d0f0a4} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\n## 一共查询了8192行，共96KB\n2020.05.03 22:58:53.013902 [ 82 ] {55122f0e-83a7-454f-abed-870934d0f0a4} <Information> executeQuery: Read 8192 rows, 96.00 KiB in 0.002 sec., 4226200 rows/sec., 48.37 MiB/sec.\n2020.05.03 22:58:53.013964 [ 82 ] {55122f0e-83a7-454f-abed-870934d0f0a4} <Debug> MemoryTracker: Peak memory usage (for query): 0.00 B.\n2020.05.03 22:58:53.014059 [ 82 ] {} <Debug> MemoryTracker: Peak memory usage (total): 0.00 B.\n## 查询一共花费了0.002s\n2020.05.03 22:58:53.014082 [ 82 ] {} <Information> TCPHandler: Processed in 0.002 sec.\n```\n\n### 3、写入语句测试\n\n​\t\t这里建立一张临时表，并插入一部分数据，结合log查看列数据库的写入逻辑，clickhouse官方目前未提供SQL查询及写入逻辑流程，并且基于不同的引擎，其写入逻辑有所不同，之后会在不同引擎的测试中对写入逻辑及日志进行详细描述。\n\n``` bash\n# 建立临时表：\n## SQL:\nclickhouse-server_1 :) CREATE TABLE mixed_granularity_table (`WatchID` UInt64, `JavaEnable` UInt8, `Title` String, `GoodEvent` Int16, `EventTime` DateTime, `EventDate` Date, `CounterID` UInt32, `ClientIP` UInt32, `ClientIP6` FixedString(16), `RegionID` UInt32, `UserID` UInt64, `CounterClass` Int8, `OS` UInt8, `UserAgent` UInt8, `URL` String, `Referer` String, `URLDomain` String, `RefererDomain` String, `Refresh` UInt8, `IsRobot` UInt8, `RefererCategories` Array(UInt16), `URLCategories` Array(UInt16), `URLRegions` Array(UInt32), `RefererRegions` Array(UInt32), `ResolutionWidth` UInt16, `ResolutionHeight` UInt16, `ResolutionDepth` UInt8, `FlashMajor` UInt8, `FlashMinor` UInt8, `FlashMinor2` String, `NetMajor` UInt8, `NetMinor` UInt8, `UserAgentMajor` UInt16, `UserAgentMinor` FixedString(2), `CookieEnable` UInt8, `JavascriptEnable` UInt8, `IsMobile` UInt8, `MobilePhone` UInt8, `MobilePhoneModel` String, `Params` String, `IPNetworkID` UInt32, `TraficSourceID` Int8, `SearchEngineID` UInt16, `SearchPhrase` String, `AdvEngineID` UInt8, `IsArtifical` UInt8, `WindowClientWidth` UInt16, `WindowClientHeight` UInt16, `ClientTimeZone` Int16, `ClientEventTime` DateTime, `SilverlightVersion1` UInt8, `SilverlightVersion2` UInt8, `SilverlightVersion3` UInt32, `SilverlightVersion4` UInt16, `PageCharset` String, `CodeVersion` UInt32, `IsLink` UInt8, `IsDownload` UInt8, `IsNotBounce` UInt8, `FUniqID` UInt64, `HID` UInt32, `IsOldCounter` UInt8, `IsEvent` UInt8, `IsParameter` UInt8, `DontCountHits` UInt8, `WithHash` UInt8, `HitColor` FixedString(1), `UTCEventTime` DateTime, `Age` UInt8, `Sex` UInt8, `Income` UInt8, `Interests` UInt16, `Robotness` UInt8, `GeneralInterests` Array(UInt16), `RemoteIP` UInt32, `RemoteIP6` FixedString(16), `WindowName` Int32, `OpenerName` Int32, `HistoryLength` Int16, `BrowserLanguage` FixedString(2), `BrowserCountry` FixedString(2), `SocialNetwork` String, `SocialAction` String, `HTTPError` UInt16, `SendTiming` Int32, `DNSTiming` Int32, `ConnectTiming` Int32, `ResponseStartTiming` Int32, `ResponseEndTiming` Int32, `FetchTiming` Int32, `RedirectTiming` Int32, `DOMInteractiveTiming` Int32, `DOMContentLoadedTiming` Int32, `DOMCompleteTiming` Int32, `LoadEventStartTiming` Int32, `LoadEventEndTiming` Int32, `NSToDOMContentLoadedTiming` Int32, `FirstPaintTiming` Int32, `RedirectCount` Int8, `SocialSourceNetworkID` UInt8, `SocialSourcePage` String, `ParamPrice` Int64, `ParamOrderID` String, `ParamCurrency` FixedString(3), `ParamCurrencyID` UInt16, `GoalsReached` Array(UInt32), `OpenstatServiceName` String, `OpenstatCampaignID` String, `OpenstatAdID` String, `OpenstatSourceID` String, `UTMSource` String, `UTMMedium` String, `UTMCampaign` String, `UTMContent` String, `UTMTerm` String, `FromTag` String, `HasGCLID` UInt8, `RefererHash` UInt64, `URLHash` UInt64, `CLID` UInt32, `YCLID` UInt64, `ShareService` String, `ShareURL` String, `ShareTitle` String, `ParsedParams.Key1` Array(String), `ParsedParams.Key2` Array(String), `ParsedParams.Key3` Array(String), `ParsedParams.Key4` Array(String), `ParsedParams.Key5` Array(String), `ParsedParams.ValueDouble` Array(Float64), `IslandID` FixedString(16), `RequestNum` UInt32, `RequestTry` UInt8) ENGINE = MergeTree() PARTITION BY toYYYYMM(EventDate) ORDER BY (CounterID, EventDate, intHash32(UserID)) SAMPLE BY intHash32(UserID) SETTINGS index_granularity=8192, enable_mixed_granularity_parts=1; -- same with hits, but enabled mixed granularity\n\n...\n\nOk.\n\n0 rows in set. Elapsed: 0.008 sec. \n## log\n### 1. 检查建表语句\n2020.05.03 23:06:08.921921 [ 82 ] {0db543f9-58b2-4765-af63-a5f881246d41} <Debug> executeQuery: (from 127.0.0.1:50236) CREATE TABLE mixed_granularity_table (`WatchID` UInt64, `JavaEnable` UInt8, `Title` String, `GoodEvent` Int16, `EventTime` DateTime, `EventDate` Date, `CounterID` UInt32, `ClientIP` UInt32, `ClientIP6` FixedString(16), `RegionID` UInt32, `UserID` UInt64, `CounterClass` Int8, `OS` UInt8, `UserAgent` UInt8, `URL` String, `Referer` String, `URLDomain` String, `RefererDomain` String, `Refresh` UInt8, `IsRobot` UInt8, `RefererCategories` Array(UInt16), `URLCategories` Array(UInt16), `URLRegions` Array(UInt32), `RefererRegions` Array(UInt32), `ResolutionWidth` UInt16, `ResolutionHeight` UInt16, `ResolutionDepth` UInt8, `FlashMajor` UInt8, `FlashMinor` UInt8, `FlashMinor2` String, `NetMajor` UInt8, `NetMinor` UInt8, `UserAgentMajor` UInt16, `UserAgentMinor` FixedString(2), `CookieEnable` UInt8, `JavascriptEnable` UInt8, `IsMobile` UInt8, `MobilePhone` UInt8, `MobilePhoneModel` String, `Params` String, `IPNetworkID` UInt32, `TraficSourceID` Int8, `SearchEngineID` UInt16, `SearchPhrase` String, `AdvEngineID` UInt8, `IsArtifical` UInt8, `WindowClientWidth` UInt16, `WindowClientHeight` UInt16, `ClientTimeZone` Int16, `ClientEventTime` DateTime, `SilverlightVersion1` UInt8, `SilverlightVersion2` UInt8, `SilverlightVersion3` UInt32, `SilverlightVersion4` UInt16, `PageCharset` String, `CodeVersion` UInt32, `IsLink` UInt8, `IsDownload` UInt8, `IsNotBounce` UInt8, `FUniqID` UInt64, `HID` UInt32, `IsOldCounter` UInt8, `IsEvent` UInt8, `IsParameter` UInt8, `DontCountHits` UInt8, `WithHash` UInt8, `HitColor` FixedString(1), `UTCEventTime` DateTime, `Age` UInt8, `Sex` UInt8, `Income` UInt8, `Interests` UInt16, `Robotness` UInt8, `GeneralInterests` Array(UInt16), `RemoteIP` UInt32, `RemoteIP6` FixedString(16), `WindowName` Int32, `OpenerName` Int32, `HistoryLength` Int16, `BrowserLanguage` FixedString(2), `BrowserCountry` FixedString(2), `SocialNetwork` String, `SocialAction` String, `HTTPError` UInt16, `SendTiming` Int32, `DNSTiming` Int32, `ConnectTiming` Int32, `ResponseStartTiming` Int32, `ResponseEndTiming` Int32, `FetchTiming` Int32, `RedirectTiming` Int32, `DOMInteractiveTiming` Int32, `DOMContentLoadedTiming` Int32, `DOMCompleteTiming` Int32, `LoadEventStartTiming` Int32, `LoadEventEndTiming` Int32, `NSToDOMContentLoadedTiming` Int32, `FirstPaintTiming` Int32, `RedirectCount` Int8, `SocialSourceNetworkID` UInt8, `SocialSourcePage` String, `ParamPrice` Int64, `ParamOrderID` String, `ParamCurrency` FixedString(3), `ParamCurrencyID` UInt16, `GoalsReached` Array(UInt32), `OpenstatServiceName` String, `OpenstatCampaignID` String, `OpenstatAdID` String, `OpenstatSourceID` String, `UTMSource` String, `UTMMedium` String, `UTMCampaign` String, `UTMContent` String, `UTMTerm` String, `FromTag` String, `HasGCLID` UInt8, `RefererHash` UInt64, `URLHash` UInt64, `CLID` UInt32, `YCLID` UInt64, `ShareService` String, `ShareURL` String, `ShareTitle` String, `ParsedParams.Key1` Array(String), `ParsedParams.Key2` Array(String), `ParsedParams.Key3` Array(String), `ParsedParams.Key4` Array(String), `ParsedParams.Key5` Array(String), `ParsedParams.ValueDouble` Array(Float64), `IslandID` FixedString(16), `RequestNum` UInt32, `RequestTry` UInt8) ENGINE = MergeTree() PARTITION BY toYYYYMM(EventDate) ORDER BY (CounterID, EventDate, intHash32(UserID)) SAMPLE BY intHash32(UserID) SETTINGS index_granularity = 8192, enable_mixed_granularity_parts = 1\n### 2. 权限检查\n2020.05.03 23:06:08.922323 [ 82 ] {0db543f9-58b2-4765-af63-a5f881246d41} <Trace> AccessRightsContext (default): Access granted: CREATE TABLE ON datasets.mixed_granularity_table\n2020.05.03 23:06:08.925036 [ 82 ] {0db543f9-58b2-4765-af63-a5f881246d41} <Debug> datasets.mixed_granularity_table: Loading data parts\n2020.05.03 23:06:08.925135 [ 82 ] {0db543f9-58b2-4765-af63-a5f881246d41} <Debug> datasets.mixed_granularity_table: Loaded data parts (0 items)\n2020.05.03 23:06:08.925992 [ 82 ] {0db543f9-58b2-4765-af63-a5f881246d41} <Debug> MemoryTracker: Peak memory usage (for query): 0.00 B.\n2020.05.03 23:06:08.926057 [ 82 ] {} <Debug> MemoryTracker: Peak memory usage (total): 0.00 B.\n2020.05.03 23:06:08.926089 [ 82 ] {} <Information> TCPHandler: Processed in 0.006 sec.\n\n# 插入数据：\n## SQL:\nclickhouse-server_1 :) INSERT INTO mixed_granularity_table SELECT * FROM hits_v1 LIMIT 10;\n\nINSERT INTO mixed_granularity_table SELECT *\nFROM hits_v1\nLIMIT 10\n\n↖ Progress: 10.00 rows, 10.85 KB (23.92 rows/s., 25.95 KB/s.)  0%Ok.\n\n0 rows in set. Elapsed: 0.418 sec. \n## log:\n2020.05.03 23:09:53.387837 [ 82 ] {321f3cb7-467a-4744-8371-29d536f78908} <Debug> executeQuery: (from 127.0.0.1:50236) INSERT INTO mixed_granularity_table SELECT * FROM hits_v1 LIMIT 10\n### 需要进行两次权限检查，对新表mixed_granularity_table的insert权限以及对hits_v1的select权限\n2020.05.03 23:09:53.388113 [ 82 ] {321f3cb7-467a-4744-8371-29d536f78908} <Trace> AccessRightsContext (default): Access granted: INSERT(WatchID, JavaEnable, ..., RequestTry) ON datasets.mixed_granularity_table\n2020.05.03 23:09:53.389910 [ 82 ] {321f3cb7-467a-4744-8371-29d536f78908} <Trace> AccessRightsContext (default): Access granted: SELECT(WatchID, JavaEnable, ..., RequestTry) ON datasets.hits_v1\n2020.05.03 23:09:53.390381 [ 82 ] {321f3cb7-467a-4744-8371-29d536f78908} <Debug> datasets.hits_v1 (SelectExecutor): Key condition: unknown\n2020.05.03 23:09:53.390396 [ 82 ] {321f3cb7-467a-4744-8371-29d536f78908} <Debug> datasets.hits_v1 (SelectExecutor): MinMax index condition: unknown\n2020.05.03 23:09:53.390421 [ 82 ] {321f3cb7-467a-4744-8371-29d536f78908} <Debug> datasets.hits_v1 (SelectExecutor): Selected 1 parts by date, 1 parts by key, 1092 marks to read from 1 ranges\n2020.05.03 23:09:53.390615 [ 82 ] {321f3cb7-467a-4744-8371-29d536f78908} <Trace> MergeTreeSelectProcessor: Reading 1 ranges from part 201403_1_32_2, approx. 8873898 rows starting from 0\n2020.05.03 23:09:53.390711 [ 82 ] {321f3cb7-467a-4744-8371-29d536f78908} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\n2020.05.03 23:09:53.391523 [ 82 ] {321f3cb7-467a-4744-8371-29d536f78908} <Debug> executeQuery: Query pipeline:\nNullAndDoCopy\n Converting\n  Limit\n   Expression\n    Expression\n     TreeExecutor\n\n2020.05.03 23:09:53.791641 [ 102 ] {321f3cb7-467a-4744-8371-29d536f78908} <Debug> DiskLocal: Reserving 1.00 MiB on disk `default`, having unreserved 3.44 TiB.\n2020.05.03 23:09:53.804394 [ 102 ] {321f3cb7-467a-4744-8371-29d536f78908} <Trace> datasets.mixed_granularity_table: Renaming temporary part tmp_insert_201403_1_1_0 to 201403_1_1_0.\n2020.05.03 23:09:53.804871 [ 82 ] {321f3cb7-467a-4744-8371-29d536f78908} <Information> executeQuery: Read 10 rows, 10.59 KiB in 0.417 sec., 23 rows/sec., 25.40 KiB/sec.\n2020.05.03 23:09:53.804923 [ 82 ] {321f3cb7-467a-4744-8371-29d536f78908} <Debug> MemoryTracker: Peak memory usage (for query): 263.95 MiB.\n2020.05.03 23:09:53.806135 [ 82 ] {} <Debug> MemoryTracker: Peak memory usage (total): 263.95 MiB.\n2020.05.03 23:09:53.806169 [ 82 ] {} <Information> TCPHandler: Processed in 0.419 sec.\n```\n\n\n\n\n\n","tags":["data"]},{"title":"harbor配置https","url":"/2020/04/20/harbor/harbor配置https/","content":"\n- 参考网页：[harbor配置https官方文档](https://goharbor.io/docs/1.10/install-config/configure-https/)\n\n​\t\t在前面[harbor搭建docker私有镜像仓库](https://schnappi618.github.io/2020/03/28/harbor搭建docker私有镜像仓库/)中使用了默认的http端口，但生产环境中并不提倡使用不安全的http服务，建议使用https保证安全性，这里根据官方推荐的openssl方法来自签证书，但浏览器并不认可自签证书的安全性，所以浏览器需要添加颁发的证书到浏览器中。同时，也可使用官方推荐的ACME获取免费的SSL证书。\n\n## 一、自签证书\n\n### 1、生成CA证书\n\n``` bash\nmkdir /Users/bulubulu/docker/cert\t\t\t# 创建一个放置证书相关的目录，并使用cd进入该目录\n## 1. 生成CA证书私钥\nopenssl genrsa -out ca.key 4096\n## 2. 生成CA证书，可调整 -subj 选项来表明域名名称等信息\nopenssl req -x509 -new -nodes -sha512 -days 3650 \\\n -subj \"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=harbor.test.com\" \\\n -key ca.key \\\n -out ca.crt\n```\n\n### 2、生成服务器证书\n\n​\t\t认证证书通常包含证书请求`.csr`文件、签名证书`.crt`文件及私钥`.key`文件，我这里harbor配置的hostname是harbor.test.com，所以最终需要生成`harbor.test.com.crt、harbor.test.com.csr、harbor.test.com.key`三个文件。\n\n- key：证书私钥，一般利用rsa等算法生成\n- csr：证书请求文件，利用证书私钥生成证书请求文件，该文件包含了服务器和地址等信息，申请人将该文件提交给CA机构，CA机构会根据该文件所携带的私钥信息来进行签名生成证书\n- crt：证书文件\n\n``` bash\n## 1. 生成私钥\nopenssl genrsa -out harbor.test.com.key 4096\n## 2. 生成csr文件\nopenssl req -sha512 -new \\\n    -subj \"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=harbor.test.com\" \\\n    -key harbor.test.com.key \\\n    -out harbor.test.com.csr\n## 3. 生成ssl匹配多域名文，例如既想使用域名又需要通过127.0.0.1本地地址登陆测试，可使用subjectAltName参数来进行配置\ncat > v3.ext <<-EOF\nauthorityKeyIdentifier=keyid,issuer\nbasicConstraints=CA:FALSE\nkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment\nextendedKeyUsage = serverAuth\nsubjectAltName = @alt_names\n\n[alt_names]\nDNS.1=harbor.test.com\nDNS.2=127.0.0.1\nEOF\n## 4. 根据v3.ext及csr文件请求生成crt证书文件\nopenssl x509 -req -sha512 -days 3650 \\\n    -extfile v3.ext \\\n    -CA ca.crt -CAkey ca.key -CAcreateserial \\\n    -in harbor.test.com.csr \\\n    -out harbor.test.com.crt\n```\n\n### 3、harbor配置修改\n\n``` yml\nvim harbor.yml\nhostname: harbor.test.com\n# https related config\nhttps:\n  # https port for harbor, default is 443\n  port: 443\n  # The path of cert and key files for nginx\n  certificate: /Users/bulubulu/docker/cert/harbor.test.com.crt\n  private_key: /Users/bulubulu/docker/cert/harbor.test.com.key\n```\n\n### 4、harbor重新导入配置并启动\n\n``` bash\n## 在harbor安装目录下执行以下命令重新启动\ndocker-compose down -v\n./prepare\ndocker-compose up -d\n```\n\n### 5、浏览器访问测试\n\n​\t\t在浏览器通过所设置域名及ip分别进行测试\n\n![访问harbor.test.com](3.png)\n\n![访问127.0.0.1](2.png)\n\n\n\n\n\n","tags":["harbor"],"categories":["harbor"]},{"title":"harbor配置nginx代理","url":"/2020/04/09/harbor/harbor配置nginx代理/","content":"\n​\t\t从前面的文章[harbor搭建docker私有镜像仓库](https://schnappi618.github.io/2020/03/28/harbor%E6%90%AD%E5%BB%BAdocker%E7%A7%81%E6%9C%89%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/)可以看出harbor默认只能使用`harbor.yml`中hostname指定的ip或主机名作为web访问地址，但在实际使用过程中，一般不允许ip地址或者主机名直接暴露在外访问，故需要配置nginx代理，通过代理后指定的地址进行访问。\n\n****\n\n### 一、设置原理\n\n- 通过nginx为harbor后端暴露的地址及端口设置proxy地址，来源于harbor配置文件中的hostname及port\n- 修改harbor配置文件再次使用nginx设置的proxy地址\n\n****\n\n### 二、Nginx代理\n\n​\t\t通过修改nginx的配置文件中server模块设置代理地址以及端口等信息，若harbor与nginx不在同一个服务器上或harbor不止一个服务器，还需要通过nginx的upstream模块来实现请求后端realserver及负载均衡，nginx配置文件修改处示例如下：\n\n``` bash\n## 设置upstream\nupstream harbor{\n    server x.x.x.x:xx;\t\t\t# 后端harbor地址\n}\n## 设置代理后地址及监听端口等\nserver {\n    listen 80;\t\t# 代理后端口\n    server_name xx.xx.com;\t\t# 代理后访问地址\n\n    location /harbor {\n        proxy_pass http://harbor;\t\t\t# 这里对应的是上面upstream后指定的名称\n     }\n}\n```\n\n****\n\n### 三、Harbor设置\n\n​\t\t通过nginx配置了代理之后，还需要修改harbor的配置文件设置proxy地址：\n\n``` yaml\n[root@xxxx harbor]# vim harbor.yml\n# Uncomment external_url if you want to enable external proxy\n# And when it enabled the hostname will no longer used\n## 打开该项配置，这里对应着nginx所设置的代理后访问地址\nexternal_url: http://xx.xx.com\n```\n\n****\n\n### 四、Web验证\n\n​\t\t通过浏览器访问`http://xx.xx.com:port`访问代理后地址，这里因为nginx代理后使用了80端口，所以不需要写明端口。\n\n​\t\t\t\t\t\t\t\t\t\t\t<img src=\"harbor配置nginx代理/1.jpg\" style=\"zoom:70%;\" />\n\n​\t\t至此，harbor配置nginx代理设置成功！","tags":["harbor"],"categories":["harbor"]},{"title":"harbor配置外部数据库","url":"/2020/04/08/harbor/harbor配置外部数据库/","content":"\n​\t\tharbor默认安装会使用官方打包的PostgreSQL docker镜像goharbor/harbor-db，harbor启动之后的数据均存放在改数据库上，后续管理可能存在不便，故使用harbor配置外部数据库。\n\n## 一、搭建PostgreSQL数据库\n\n​\t\tharbor从1.6版本之后仅支持PostgreSQL数据库作为外部数据库，故需要搭建PostgreSQL数据库使用。这里目前作为测试，故仅安装了单节点，未配置主从，搭建步骤如下：\n\n### 1. 安装\n\n``` bash\n- 系统版本：CentOS7\n\n## 1. 安装依赖包\nyum install -y cmake gcc gcc-c++ perl readline readline-devel openssl openssl-devel zlib zlib-devel ncurses-devel readline readline-devel zlib zlib-devel\n\n## 2. 源码安装PostgreSQL\n[postgres@xxxx dba]$ wget https://ftp.postgresql.org/pub/source/v12.2/postgresql-12.2.tar.gz\n[postgres@xxxx dba]$ tar zxf postgresql-12.2.tar.gz \n[postgres@xxxx dba]$ cd postgresql-12.2\n[postgres@xxxx postgresql-12.2]$ ./configure --prefix=/usr/local/postgresql\n[postgres@xxxx postgresql-12.2]$ make && make install\n### 这里configure的时候制定了安装目录，故需要将该目录下的bin目录写入到环境变量中去，以方便后面直接使用，也可不指定，安装到默认路径下\n```\n\n### 2. 配置\n\n``` bash\n# 1. 创建数据目录\n[postgres@xxxx data]$ mkdir -p /work/harbor-db/data\n# 2. 创建日志目录\n[postgres@xxxx data]$ mkdir -p /work/harbor-db/log\n# 3. 创建socket目录\n[postgres@xxxx data]$ mkdir -p /work/harbor-db/tmp\n# 4. 授权\n[postgres@xxxx data]$ chown -R postgres.postgres /work/harbor-db/\n# 5. 初始化pg实例\n[postgres@xxxx data]$ initdb --username=postgres -D /work/harbor-db/data/\n \n## 这里PostgreSQL数据库与harbor并未在同一台主机上，故除了修改配置文件postgresql.conf外还需要修改客户端认证配置pg_hba.conf文件，若在同一台主机上没有网络以及认证需求的话，可以不修改\n# 6. 根据需要修改初始化的配置文件，修改位置如下：\n[postgres@xxxx data]$ vim /work/harbor-db/data/postgresql.conf\n # 数据目录指定\ndata_directory = '/work/harbor-db/data'\n # 客户端可连接ip，默认为localhost，若不需要可不修改，*为所有\nlisten_addresses = '*'\n # 端口设置\nport = 7002\n # 允许最大连接数\nmax_connections = 100\n # socket目录及权限设置\nunix_socket_directories = '/work/harbor-db/tmp'\nunix_socket_group = ''\nunix_socket_permissions = 0777\n # 内存大小\nshared_buffers = 128MB\n # 时区修改\ntimezone = 'Asia/Shanghai'\n \n # 日志：\n ## 是否开启日志\nlogging_collector = on\n ## 日志存放目录\nlog_directory = '/work/harbor-db/log'\n ## 每个日志最大size\nlog_rotation_size = 1GB\n ## 日志时区\nlog_timezone = 'Asia/Shanghai'\n ## 记录执行时间大于100ms的sql及执行时间，相当于慢SQL日志\nlog_min_duration_statement = 100\n\n## 由于这里需要远程可以连接，所以需要添加认证配置pg_hba.conf，根据自己需求配置，若不需要的话可不配置该文件\n[postgres@xxxx data]$ vim pg_hba.conf \n# 在文件末尾添加，以下配置表示，允许ADDRESS对应的主机，通过harbor用户访问该库的所有数据库\n# TYPE  DATABASE        USER            ADDRESS                 METHOD\nhost    all             harbor             x.x.x.x/x           trust\n```\n\n### 3. 启动\n\n```bash\n[postgres@xxxx data]$ su - postgres\n## 启动方式使用以下1种即可\n[postgres@xxxx data]$ pg_ctl -D /work/harbor-db/data/ -l /work/harbor-db/log/start.log start\n\n或使用 postgres -D /work/harbor-db/data > /work/harbor-db/log/start.log 2>&1 & 命令启动\n```\n\n### 4. 登陆测试\n\n``` bash\n## 1. 本地测试\n# 安装完成后会有postgres用户，相当于MySQL的root用户，默认没有密码\n[postgres@xxxx data]$ psql -h 127.0.0.1 -p 7002 -U postgres\npsql (12.2)\nType \"help\" for help.\n### 修改postgres用户的密码\npostgres=# \\password postgres\nEnter new password: \nEnter it again: \n### 创建harbor用户，并创建harbor所涉及数据库及进行授权\npostgres=# create user harbor with password 'harbor123';\nCREATE ROLE\npostgres=# CREATE DATABASE harbor;\nCREATE DATABASE\npostgres=# create database harbor_clair;\nCREATE DATABASE\npostgres=# create database harbor_notary_server;\nCREATE DATABASE\npostgres=# create database harbor_notary_signer; \nCREATE DATABASE\npostgres=# GRANT ALL PRIVILEGES ON DATABASE harbor to harbor;           \nGRANT\npostgres=# GRANT ALL PRIVILEGES ON DATABASE harbor_clair to harbor;           \nGRANT\npostgres=# GRANT ALL PRIVILEGES ON DATABASE harbor_notary_server to harbor;            \nGRANT\npostgres=# GRANT ALL PRIVILEGES ON DATABASE harbor_notary_signer to harbor;                    \nGRANT\n\n## 2. 远程主机harbor用户测试\n[root@remote harbor]# psql -h x.x.x.x -p 7002 -U harbor -W \nPassword: \npsql (12.2)\nType \"help\" for help.\n\nharbor=> \n```\n\n​\t\t至此，PostgreSQL数据库及基础配置设置完毕。\n\n## 二、Harbor配置\n\n### 1. 配置文件修改\n\n``` yaml\n[root@remote harbor]# vim harbor.yml\n# Uncomment external_database if using external database.\nexternal_database:\n  harbor:\n    host: x.x.x.x\n    port: 7002\n    db_name: harbor\n    username: harbor\n    password: xxxxxxxx\n    ssl_mode: disable\n    max_idle_conns: 50\n    max_open_conns: 100\n  clair:\n    host: x.x.x.x\n    port: 7002\n    db_name: harbor_clair\n    username: harbor\n    password: xxxxxxxx\n    ssl_mode: disable\n  notary_signer:\n    host: x.x.x.x\n    port: 7002\n    db_name: harbor_notary_signer\n    username: harbor\n    password: xxxxxxxx\n    ssl_mode: disable\n  notary_server:\n    host: x.x.x.x\n    port: 7002\n    db_name: harbor_notary_server\n    username: harbor\n    password: xxxxxxxx\n```\n\n### 2. docker-compose文件修改\n\n​\t\t设置了外部数据库之后，便不再需要harbor本身的harbor-db镜像来支持，由安装重启文件`install.sh`可看出最终的安装等操作都由`docker-compose.yml`文件来完成，故需要在docker-compose文件中删除或注释掉harbor-db相关，修改完成后执行`sh install.sh`文件重启harbor服务即可。\n\n## 三、测试验证\n\n### 1. 数据库验证\n\n​\t\t当harbor服务重启完成后，进入外部数据库中会发现刚才配置的库里面有了harbor的一些相关表。\n\n``` bash\n[root@remote harbor]# psql -h x.x.x.x -p 7002 -U harbor -W \nPassword: \npsql (12.2)\nType \"help\" for help.\n# 查看有哪些库\nharbor=> \\l\n                                       List of databases\n         Name         |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges   \n----------------------+----------+----------+-------------+-------------+-----------------------\n harbor               | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/postgres         +\n                      |          |          |             |             | postgres=CTc/postgres+\n                      |          |          |             |             | harbor=CTc/postgres\n harbor_clair         | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/postgres         +\n                      |          |          |             |             | postgres=CTc/postgres+\n                      |          |          |             |             | harbor=CTc/postgres\n harbor_notary_server | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/postgres         +\n                      |          |          |             |             | postgres=CTc/postgres+\n                      |          |          |             |             | harbor=CTc/postgres\n harbor_notary_signer | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/postgres         +\n                      |          |          |             |             | postgres=CTc/postgres+\n                      |          |          |             |             | harbor=CTc/postgres\n postgres             | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | \n template0            | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +\n                      |          |          |             |             | postgres=CTc/postgres\n template1            | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +\n                      |          |          |             |             | postgres=CTc/postgres\n(7 rows)\n# 进入harbor库中\nharbor=> \\c harbor\nPassword for user harbor: \nYou are now connected to database \"harbor\" as user \"harbor\".\n# 查看该库有哪些表\nharbor=> \\dt\n                 List of relations\n Schema |           Name           | Type  | Owner  \n--------+--------------------------+-------+--------\n public | access                   | table | harbor\n public | access_log               | table | harbor\n public | admin_job                | table | harbor\n public | alembic_version          | table | harbor\n public | artifact                 | table | harbor\n public | artifact_blob            | table | harbor\n public | blob                     | table | harbor\n public | cve_whitelist            | table | harbor\n public | harbor_label             | table | harbor\n public | harbor_resource_label    | table | harbor\n public | harbor_user              | table | harbor\n public | immutable_tag_rule       | table | harbor\n public | job_log                  | table | harbor\n public | notification_job         | table | harbor\n public | notification_policy      | table | harbor\n public | oidc_user                | table | harbor\n public | project                  | table | harbor\n public | project_blob             | table | harbor\n public | project_member           | table | harbor\n public | project_metadata         | table | harbor\n public | properties               | table | harbor\n public | quota                    | table | harbor\n public | quota_usage              | table | harbor\n public | registry                 | table | harbor\n public | replication_execution    | table | harbor\n public | replication_policy       | table | harbor\n public | replication_schedule_job | table | harbor\n public | replication_task         | table | harbor\n public | repository               | table | harbor\n public | retention_execution      | table | harbor\n public | retention_policy         | table | harbor\n public | retention_task           | table | harbor\n public | robot                    | table | harbor\n public | role                     | table | harbor\n public | scan_report              | table | harbor\n public | scanner_registration     | table | harbor\n public | schedule                 | table | harbor\n public | schema_migrations        | table | harbor\n public | user_group               | table | harbor\n(39 rows)\n\n## 由于并没有开启其他三个组件的功能，所以其他三个库里面没有表，当harbor库中有表存在后，则外部数据库配置成功\n```\n\n### 2. Web页面测试\n\n​\t\t根据之前的[harbor搭建]([https://schnappi618.github.io/2020/03/28/harbor%E6%90%AD%E5%BB%BAdocker%E7%A7%81%E6%9C%89%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/](https://schnappi618.github.io/2020/03/28/harbor搭建docker私有镜像仓库/))中最后的web页面创建镜像仓库的演示，可新创建一个镜像仓库，并上传一个镜像，完成后，在数据库中可看到记录\n\n``` bash\nharbor_notary_signer=> \\c harbor\nPassword for user harbor: \nYou are now connected to database \"harbor\" as user \"harbor\".\n# 查看操作日志，创建了一个pingcap仓库，并上传了一个tikv:v3.0.12的镜像到pingcap仓库中，所有的操作均为admin用户执行\nharbor=> select * from access_log;\n log_id | username | project_id |  repo_name   | repo_tag | guid | operation |          op_time           \n--------+----------+------------+--------------+----------+------+-----------+----------------------------\n      1 | admin    |          2 | pingcap/     | N/A      |      | create    | 2020-04-08 18:02:50.369493\n      2 | admin    |          2 | pingcap/tikv | v3.0.12  |      | push      | 2020-04-08 18:03:48.824079\n(2 rows)\n# 查看目前有哪些仓库，即project\nharbor=> select * from project;   \n project_id | owner_id |  name   |       creation_time        |        update_time         | deleted \n------------+----------+---------+----------------------------+----------------------------+---------\n          1 |        1 | library | 2020-04-08 17:48:10.024358 | 2020-04-08 17:48:10.024358 | f\n          2 |        1 | pingcap | 2020-04-08 18:02:50        | 2020-04-08 18:02:50        | f\n(2 rows)\n# 查看目前有哪些镜像\nharbor=> select * from repository;\n repository_id |     name     | project_id | description | pull_count | star_count |       creation_time        |        update_t\nime         \n---------------+--------------+------------+-------------+------------+------------+----------------------------+----------------\n------------\n             1 | pingcap/tikv |          2 |             |          0 |          0 | 2020-04-08 18:03:48.824717 | 2020-04-08 18:0\n3:48.824717\n(1 row)\n```\n\n​\t\t可以看到，所有的结果均符合预期，harbor配置外部数据库及测试完成。^_^\n\n","tags":["harbor","PostgreSQL"],"categories":["harbor"]},{"title":"clickhouse用户配置详解","url":"/2020/03/28/clickhouse/clickhouse用户配置详解/","content":"\n**参考网页：**\n\n- [clickhouse官方文档](https://clickhouse.tech/docs/zh/)\n- [clickhouse配置文件参数](https://clickhouse.tech/docs/zh/operations/settings/settings/)\n\n​\t\tClickHouse的用户及访问权限控制均可由配置文件直接进行标准化配置，一般由`users.xml`文件设置，该文件名在/etc/clickhouse-server/config.xml中修改，详情可参考[clickhouse-server配置文件详解]([https://schnappi618.github.io/2020/03/28/clickhouse-server%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/](https://schnappi618.github.io/2020/03/28/clickhouse-server配置文件详解/))，若需要对某一个用户单独设置例如dba用户，可放入`/etc/clickhouse-server/users.d/dba.xml`，下面会描述该文件的配置示例。\n\n## 一、users.xml文件示例\n\n​\t\t以下是一个标准默认的`users.xml`用户配置示例，可直接测试使用，对用户的权限管理将会单独使用一篇文章来进行说明，后面将会对该文件分开描述。\n\n​\t\t有文件中可以看出users.xml主要由以下三部分设置组成：\n\n- profile：类似于用户角色，可以实现最大内存、负载方式等配置的服用\n- users：设置包括用户名、密码、权限等\n- quotas：限制一段时间内的资源使用等\n\n``` xml\n<?xml version=\"1.0\"?>\n<yandex>\n    <profiles>\n        <default>\n            <max_memory_usage>10000000000</max_memory_usage>\n            <load_balancing>random</load_balancing>\n            <constraints><!-- 配置约束-->\n                <max_memory_usage>\n                    <min>5000000000</min>\n                    <max>20000000000</max>\n                </max_memory_usage>\n                <load_balancing>\n                    <readonly/>\n                </load_balancing>\n            </constraints>\n        </default>\n        </default>\n\n        <readonly>\n            <readonly>1</readonly>\n        </readonly>\n    </profiles>\n\n    <users>\n        <default>\n            <password></password>\n            <networks incl=\"networks\" replace=\"replace\">\n                <ip>::1</ip>\n        \t\t\t\t<ip>127.0.0.1</ip>\n            </networks>\n\n            <profile>default</profile>\n\n            <quota>default</quota>\n        </default>\n      <!--下面两个用户为测试用户，可以不配置-->\n        <seluser>\n            <password>meiyoumima</password>\n            <networks incl=\"networks\" replace=\"replace\">\n                <ip>::/0</ip>\n            </networks>\n            <profile>readonly</profile>\n            <quota>default</quota>\n        </seluser>\n        <inuser>\n            <password>meiyoumima</password>\n            <networks incl=\"networks\" replace=\"replace\">\n                <ip>::/0</ip>\n            </networks>\n            <profile>default</profile>\n            <quota>default</quota>\n        </inuser>\n      \n    </users>\n\n    <!-- Quotas. -->\n    <quotas>\n        <default>\n            <interval>\n                <duration>3600</duration>\n                <queries>0</queries>\n                <errors>0</errors>\n                <result_rows>0</result_rows>\n                <read_rows>0</read_rows>\n                <execution_time>0</execution_time>\n            </interval>\n        </default>\n    </quotas>\n</yandex>\n```\n\n## 二、profile设置详解\n\n​\t\t`users.xml`用户配置文件中`profiles`部分定义了一些可复用的配置，他的作用类似于用户角色，可定义多个profile，并为不同的profile定义不同的配置，其中每个参数的含义可参考前面的参考网页二，并在后续使用中不断完善，以下面配置为例：\n\n### 1、profile配置详情\n\n``` xml\n<yandex>\n    <!--定义profiles-->\n    <profiles>    \n        <!--可自定义名称，default是默认存在的角色名称-->\n        <default>\n            <max_memory_usage>10000000000</max_memory_usage>\n            <load_balancing>random</load_balancing>\n          \n            <constraints><!-- 配置约束-->\n                <max_memory_usage>\n                    <min>5000000000</min>\n                    <max>20000000000</max>\n                </max_memory_usage>\n                <load_balancing>\n                    <readonly/>\n                </load_balancing>\n            </constraints>\n        </default>\n      \n\t\t\t\t<!--自定义readonly角色-->\n        <readonly>\n            <readonly>1</readonly>\n        </readonly>\n    </profiles>\n```\n\n### 2、profile配置约束\n\nprofile中有约束条件，从而限制其中的参数值被任意修改，约束条件有三种规则：\n\n1. Min：最小值约束，对应参数取值不能小于该值\n\n2. Max：最大值约束，对应参数取值不能大雨该值\n\n3. Readonly：只读约束，对应参数禁止修改\n\n   \n\n   **profile中default的constraints配置约束会作为全局约束，自动被其他profile继承。**\n\n****\n\n​\t\t以上述配置示例，将default用户角色中的`max_memory_usage`设置了默认值以及最大最小阈值，`load_balancing`设置为了只读，对其配置进行测试\n\n``` bash\n[root@xxxx docker_compose]# docker exec -it 92b25e101be0 /bin/bash\n# 所有的profile设置中，default是默认配置，必须存在，利用docker-compose配置后容器会无法启动\nroot@clickhouse-server_1:/# clickhouse-client\nClickHouse client version 20.3.4.10 (official build).\nConnecting to localhost:9000 as user default.\nConnected to ClickHouse server version 20.3.4 revision 54433.\n\n# 设置max_memory_usage为50，他的最小值约束起了作用，禁止修改为该值\nclickhouse-server_1 :) set max_memory_usage = 50\n\nSET max_memory_usage = 50\n\nReceived exception from server (version 20.3.4):\nCode: 452. DB::Exception: Received from localhost:9000. DB::Exception: Setting max_memory_usage shouldn't be less than 5000000000. \n\n0 rows in set. Elapsed: 0.058 sec.\n\n## 修改load_balancing，禁止修改该值\nclickhouse-server_1 :) set load_balancing = 'nearest_hostname'\n\nSET load_balancing = 'nearest_hostname'\n\nReceived exception from server (version 20.3.4):\nCode: 452. DB::Exception: Received from localhost:9000. DB::Exception: Setting load_balancing should not be changed. \n\n0 rows in set. Elapsed: 0.001 sec. \n```\n\n### 3、profile切换和继承\n\n1、profile切换\n\n``` bash\n# 根据上面的配置文件，可以看到这次profile中包含default和readonly，clickhouse默认登陆用户为default，profile为default，可切换到readonly，切换后会获得相应的配置\nclickhouse-server_1 :) set profile = 'readonly'\n\nSET profile = 'readonly'\n\nOk.\n\n0 rows in set. Elapsed: 0.001 sec.\n# 从上面配置可以看到，设置的max_memory_usage符合约束条件，但由于目前是readonly的profile，所有参数都不能修改\nclickhouse-server_1 :) set max_memory_usage = 10000000001\n\nSET max_memory_usage = 10000000001\n\nReceived exception from server (version 20.3.4):\nCode: 164. DB::Exception: Received from localhost:9000. DB::Exception: Cannot modify 'max_memory_usage' setting in readonly mode. \n\n0 rows in set. Elapsed: 0.001 sec.\n```\n\n2、profile继承\n\n​\t\tprofile配置支持继承，实现继承的方式是在profile配置中先引入其他的profile名称，但若有冲突，后面的配置会覆盖之前继承的配置，示例如下：\n\n``` xml\n\t<profiles>\n    <test1>\n    \t<allow_experimental_live_view>1</allow_experimental_live_view>\n      <distributed_product_mode>allow</distributed_product_mode>\n    </test1>\n    <!--normal_inherit profile会继承test1里面的两个参数配置，但它自身也设置了distributed_product_mode和test1的冲突，后面自己设置的deny会覆盖掉test1的allow设置-->\n\t\t<normal_inherit> \n    \t<profile>test1</profile>\n\t\t\t<distributed_product_mode>deny</distributed_product_mode>\n\t\t</normal_inherit>\n\t</profiles>\n```\n\n## 三、users配置详解\n\n​\t\t`users.xml`用户配置文件中users模块可以自定义配置用户属性，例如用户名、密码、权限等，用官网默认配置会发现`users.xml`文件中会默认创建default用户，使用`clickhouse-client`无参数登陆会通过该用户登陆，将以下面的示例进行说明：\n\n### 1、users配置详情\n\n``` xml\n    <users>\n      <!--default用户会默认存在-->\n        <default>\n            <password></password>\n            <networks incl=\"networks\" replace=\"replace\">\n                <ip>::1</ip>\n        \t\t\t\t<ip>127.0.0.1</ip>\n            </networks>\n\n            <profile>default</profile>\n\n            <quota>default</quota>\n        </default>\n      <!--下面两个用户为测试用户，可以不配置-->\n        <seluser>\n            <password>meiyoumima</password>\n            <networks incl=\"networks\" replace=\"replace\">\n                <ip>::/0</ip>\n            </networks>\n            <profile>readonly</profile>\n            <quota>default</quota>\n        </seluser>\n        <inuser>\n            <password>meiyoumima</password>\n            <networks incl=\"networks\" replace=\"replace\">\n                <ip>::/0</ip>\n            </networks>\n            <profile>default</profile>\n            <quota>default</quota>\n        </inuser>\n      \n    </users>\n```\n\n### 2、users属性详解\n\n​\t\t一个完整的用户设置，需要包含下面的属性\n\n- username：用户名\n- password：密码设置\n- networks：网络设置，一般用来限制可登陆的客户端地址\n- profile：该用户所使用的profile\n- quota\n\n****\n\n**1. username**\n\n```xml\n    <users>\n      \t<!--用户的第一行设置为其username-->\n        <default>\n            <password></password>\n            <networks incl=\"networks\" replace=\"replace\">\n                <ip>::1</ip>\n        \t\t\t\t<ip>127.0.0.1</ip>\n            </networks>\n\n            <profile>default</profile>\n\n            <quota>default</quota>\n        </default>\n```\n\n****\n\n**2. password**\n\n​\t\t登陆密码，clickhouse支持**明文、SHA256加密、double_sha1**三种设置方式，但SHA256和sha1都是散列算法，明文和密文一一对应，也可通过密文很容易进行解密...\n\n- 明文登陆\n\n``` xml\n<!--直接在用户中通过password标签定义，中间字符即为登陆密码-->\n<password>meiyoumima</password>\n<!--类似上述default用户，中间为空即代表没有密码-->\n<password></password>\n```\n\n- SHA256加密登陆\n\n``` bash\n## 官方推荐生成密码方式，RSZ4QZMc为随机的明文密码，21d076f...为最终密文\n[root@xxxx docker_compose]#   PASSWORD=$(base64 < /dev/urandom | head -c8); echo \"$PASSWORD\"; echo -n \"$PASSWORD\" | sha256sum | tr -d '-'\nRSZ4QZMc\n21d076f8340b5d836769a35c4d658d7b3091e7e1ccb18d66e9e1a7b6eef823df \n### 也可通过openssl生成密文，明文为123，输出为密文\n[root@xxxx docker_compose]# echo -n 123 | openssl dgst -sha256\n(stdin)= a665a45920422f9d417e4867efdc4fb8a04a1f3fff1fa07e998e86f7f7a27ae3\n```\n\n``` xml\n<!--设置方式-->\n<password_sha256_hex>21d076f8340b5d836769a35c4d658d7b3091e7e1ccb18d66e9e1a7b6eef823df</password_sha256_hex>\n```\n\n- double_sha1加密登陆\n\n``` bash\n# 官方推荐生成密码方式，+0agrMRX为urandom生成的明文，407732...为最终密文\n[root@xxxx docker_compose]#   PASSWORD=$(base64 < /dev/urandom | head -c8); echo \"$PASSWORD\"; echo -n \"$PASSWORD\" | sha1sum | tr -d '-' | xxd -r -p | sha1sum | tr -d '-'\n+0agrMRX\n407732ce14cdea57dc0a2ff9c64773472f8cd666\n### 通过openssl生成密文，明文为123，输出为密文\n[root@xxxx docker_compose]# echo -n 123 | openssl dgst -sha1 -binary | openssl dgst -sha1\n(stdin)= 23ae809ddacaf96af0fd78ed04b6a265e05aa257\n```\n\n``` xml\n<!--设置方式-->\n<password_double_sha1_hex>407732ce14cdea57dc0a2ff9c64773472f8cd666</password_double_sha1_hex>\n```\n\n****\n\n**3. networks**\n\n​\t\tnetworks表示允许被登陆clickhouse服务器的客户端列表，支持通过ip、host、host_regexp方式设置\n\n- ip设置\n\n``` xml\n<!--通过ip直接设置-->\n<ip>1.1.1.1</ip>\n<ip>10.0.0.1/8</ip>\n\n<!--为所有客户端打开权限-->\n<ip>::/0</ip>\n<!--仅允许本地登陆-->\n<ip>::1</ip>\n<ip>127.0.0.1</ip>\n```\n\n- host设置\n\n``` xml\n<host>example1.host.com</host>\n```\n\n- host_regexp设置\n\n```xml\n<!--通过主机名的正则表达式设置-->\n<host_regexp>^example\\d\\d-\\d\\d-\\d\\.host\\.ru$</host_regexp>\n```\n\n****\n\n**4. profile设置**\n\n​\t\t该用户所使用的profile设置，直接写入即可\n\n``` xml\n<default>\n\t<profile>default</profile>\n</default>\n```\n\n****\n\n**5. quota设置**\n\n​\t\t该用户单位时间内的资源限制，直接使用quotas设置的名称即可\n\n``` xml\n<quota>default</quota>\n```\n\n****\n\n**6. database设置**\n\n​\t\t该设置可以限制当前用户select时返回的行，以完成简单的行数据安全，示例如下：\n\n``` xml\n<!--以下配置强制用户user1只能看到database_name.table1表中id为1000的行，其中filter支持UInt8类型的值，并支持比较和逻辑运算符-->\n<user1>\n    <databases>\n        <database_name>\n            <table1>\n                <filter>id = 1000</filter>\n            </table1>\n        </database_name>\n    </databases>\n</user1>\n```\n\n## 四、quotas配置详解\n\n### 1、quotas配置详情\n\n​\t\t`users.xml`配置文件中的quotas标签是限制了单位时间内的系统资源使用量，而不是限制单个查询的系统资源使用量**(server的配置可以设置限制单个查询的系统资源的使用量)**，值为0表示不限制，如下面示例所示，表示**仅跟踪每小时的资源消耗，而不限制使用情况**，当设置阈值之后，对应资源达到阈值，正在进行的操作也会中断。\n\n``` xml\n    <quotas>\n        <default>\t\t<!--自定义名称-->\n            <interval>\n                <duration>3600</duration>\n                <queries>0</queries>\n                <errors>0</errors>\n                <result_rows>0</result_rows>\n                <read_rows>0</read_rows>\n                <execution_time>0</execution_time>\n            </interval>\n        </default>\n    </quotas>\n```\n\n### 2、quotas属性详解\n\n**1. duration设置**\n\n​\t\tduration表示累计的时间周期，单位为秒，达到该时间周期后，清除所有收集的值，接下来的周期，将重新开始计算，当服务重启时，也会清除所有的值，重新开始新的周期。\n\n``` xml\n<duration>3600</duration>\n```\n\n****\n\n**2. queris设置**\n\n​\t\tqueris表示在该周期内，允许执行的查询次数，0为不限制。\n\n``` xml\n<!--在duration设置周期时间内只允许查询1000次-->\n<queries>1000</queries>\n```\n\n****\n\n**3. errors设置**\n\n​\t\terrors表示在该周期内，允许引发异常的查询次数，0为不限制。\n\n``` xml\n<errors>0</errors>\n```\n\n****\n\n**4. result_rows设置**\n\n​\t\tresult_rows表示在周期内，允许查询返回的结果行数，0为不限制。\n\n``` xml\n<result_rows>0</result_rows>\n```\n\n****\n\n**5. read_rows设置**\n\n​\t\tread_rows表示在周期内，允许远程节点读取的数据行数，0为不限制。\n\n``` xml\n<read_rows>0</read_rows>\n```\n\n****\n\n**6. execution_time设置**\n\n​\t\texecution_time表示允许查询的总执行时间(又叫wall time)，单位为秒，0为不限制。\n\n``` xml\n<execution_time>0</execution_time>\n```\n\n","tags":["clickhouse"],"categories":["clickhouse"]},{"title":"clickhouse-server配置文件详解","url":"/2020/03/28/clickhouse/clickhouse-server配置文件详解/"},{"title":"harbor搭建docker私有镜像仓库","url":"/2020/03/28/harbor/harbor搭建docker私有镜像仓库/","content":"\n参考文档：\n\n- [Harbor官方文档](https://goharbor.io/docs/1.10/)\n\n## 一、Harbor简介\n\n​\t\tHarbor是VMWare开源的企业级容器镜像仓库，在Docker Registry基础上增加了Web UI、基于角色的访问控制、日志审计、扫描镜像漏洞等功能从而使其应用更加广泛。\n\n​\t\t其中大致包括以下组件，对其组件的功能及修改在之后使用过程中了解：\n\n- harbor-jobservice\n- nginx\n- harbor-ui\n- harbor-db\n- registry\n- harbor-adminserver\n- harbor-log\n\n## 二、Harbor私有镜像仓库搭建\n\n## 1、环境准备\n\n``` bash\ndocker 版本17.06.0+\ndocker-compose  版本高于1.6.0\n```\n\n​\t\t本次环境配置如下：\n\n<img src=\"harbor搭建docker私有镜像仓库/1.png\" style=\"zoom:50%;\" />\n\n- [docker安装参考](https://schnappi618.github.io/2020/03/07/利用docker安装启动ClickHouse/)\n- [docker-compose安装参考](https://schnappi618.github.io/2020/03/28/docker-compose定制clickhouse配置启动/)\n\n## 2、搭建过程\n\n​\t\t目前Harbor最新版本为1.10.1，[可点击此处下载该版本安装包](https://github.com/goharbor/harbor/releases/download/v1.10.1/harbor-offline-installer-v1.10.1.tgz)\n\n#### 1、下载解压\n\n``` bash\n[root@xxxx harbor]# ll -h\ntotal 643M\n-rw-r--r-- 1 root root 643M Mar 26 00:24 harbor-offline-installer-v1.10.1.tgz\n# 解压该安装包\n[root@xxxx harbor]# tar zxvf harbor-offline-installer-v1.10.1.tgz \nharbor/harbor.v1.10.1.tar.gz\nharbor/prepare\t\t\t\t# 执行一些创建目录等准备工作的脚本\nharbor/LICENSE\nharbor/install.sh\t\t\t# harbor安装脚本，配置文件修改完成后直接执行该脚本，若无报错，即可安装完成\nharbor/common.sh\t\t\t# 安装前检查docker、docker-compose等基础环境是否符合安装要求脚本,install.sh脚本中将该脚本先执行\nharbor/harbor.yml\t\t\t# harbor的配置文件\n```\n\n#### 2、harbor配置\n\n``` yml\n# 若不需要进行变动，则修改hostname即可\n# Configuration file of Harbor\n\n# The IP address or hostname to access admin UI and registry service.\n# DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients.\nhostname: x.x.x.x\t\t\t\t# 修改为自己搭建主机的ip即可\n```\n\n#### 3、harbor.yml相关配置解释\n\n``` yml\n[root@xxxx harbor]# vim harbor.yml\n# hostname: 指定主机名，不能指定为127.0.0.1或localhost或0.0.0.0\nhostname: reg.mydomain.com\n\n# http配置：但为了安全，业务生产环境中官方不建议使用http协议，会容易遭到中间人攻击\nhttp:\n  # 配置http端口，默认为80\n  port: 80\n  \n# https配置，后面会描述如何开启harbor的https配置\nhttps:\n  # https端口配置，默认为443，可用于访问harbor以及其中的docker push等命令\n  port: 443\n  # ssl证书的路径\n  certificate: /your/certificate/path\n  # ssl密钥路径\n  private_key: /your/private/key/path\n\n# 是否开启外部代理，启用后，将不使用前面配置的hostname访问，默认未开启\nexternal_url: https://reg.mydomain.com:8433\n\n# harbor默认管理员密码，可用于web页面登录，默认用户名为admin，密码为Harbor12345\nharbor_admin_password: Harbor12345\n\n# Harbor DB配置，harbor中默认提供了数据库组件，也可以去掉默认数据库组件，使用外部数据库，但官方文档描述说仅支持PostgreSQL数据库，使用外部数据库需要启动external_database参数并进行配置，也可启用外部redis服务\ndatabase:\n  # 数据库密码\n  password: root123\n  # 空闲连接池最大连接数，该值小于等于0时，空闲连接池将不会保留任何连接\n  max_idle_conns: 50\n  # 与数据库的最大打开的连接数，该值小于等于0时，表示无限制\n  max_open_conns: 100\n# external_database:\n#   harbor:\n#     host: harbor_db_host\n#     port: harbor_db_port\n#     db_name: harbor_db_name\n#     username: harbor_db_username\n#     password: harbor_db_password\n#     ssl_mode: disable\n#     max_idle_conns: 2\n#     max_open_conns: 0\n#   clair:\n#     host: clair_db_host\n#     port: clair_db_port\n#     db_name: clair_db_name\n#     username: clair_db_username\n#     password: clair_db_password\n#     ssl_mode: disable\n#   notary_signer:\n#     host: notary_signer_db_host\n#     port: notary_signer_db_port\n#     db_name: notary_signer_db_name\n#     username: notary_signer_db_username\n#     password: notary_signer_db_password\n#     ssl_mode: disable\n#   notary_server:\n#     host: notary_server_db_host\n#     port: notary_server_db_port\n#     db_name: notary_server_db_name\n#     username: notary_server_db_username\n#     password: notary_server_db_password\n#     ssl_mode: disable\n\n# external_redis:\n#   host: redis\n#   port: 6379\n#   password:\n#   # db_index 0 is for core, it's unchangeable\n#   registry_db_index: 1\n#   jobservice_db_index: 2\n#   chartmuseum_db_index: 3\n#   clair_db_index: 4\n\n# 主机上存储harbor数据的位置\ndata_volume: /data\n\n# harbor默认将图像和图表数据存储在本地上，storage_service配置其可以使用其他的存储后端存储，其中可以配置CA证书路径、filesystem等配置\n# storage_service:\n#   ca_bundle:\n#   filesystem:\n#     maxthreads: 100\n#   # set disable to true when you want to disable registry redirect\n#   redirect:\n#     disabled: false\n\n# Clair镜像扫描配置，检查容器基础框架的安全性，其原理还未研究，之后补充。harbor默认检查时间间隔为12h，设置为0表示禁止扫描\nclair:\n  # The interval of clair updaters, the unit is hour, set to 0 to disable the updaters.\n  updaters_interval: 12\n\n# jobservice是harbor的其中一个组件，主要负责镜像复制，具体原理后续补充\njobservice:\n  # Maximum number of job workers in job service\n  max_job_workers: 10\n\nnotification:\n  # Maximum retry count for webhook job\n  webhook_job_max_retry: 10\n  \nchart:\n  # Change the value of absolute_url to enabled can enable absolute url in chart\n  absolute_url: disabled\n  \n# 日志配置，harbor默认使用rsyslog来收集日志\nlog:\n  # 设置日志级别，options are debug, info, warning, error, fatal\n  level: info\n  # configs for logs in local storage\n  local:\n    # Log files are rotated log_rotate_count times before being removed. If count is 0, old versions are removed rather than rotated.\n    rotate_count: 50\n    # 日志大小，可使用k，M，G作为单位\n    rotate_size: 200M\n    # 日志存储路径\n    location: /var/log/harbor\n\n  # 启用该选项可将日志转发到rsyslog服务器\n  # external_endpoint:\n  #   # protocol used to transmit log to external endpoint, options is tcp or udp\n  #   protocol: tcp\n  #   # The host of external endpoint\n  #   host: localhost\n  #   # Port of external endpoint\n  #   port: 5140\n\n# 代理配置\nproxy:\n  http_proxy:\n  https_proxy:\n  # no_proxy endpoints will appended to 127.0.0.1,localhost,.local,.internal,log,db,redis,nginx,core,portal,postgresql,jobservice,registry,registryctl,clair,chartmuseum,notary-server\n  no_proxy:\n  components:\n    - core\n    - jobservice\n    - clair\n```\n\n#### 4、配置启动\n\n​\t\t这里仅先作为测试使用，所以仅修改了hostname、data、log目录，并关闭了https服务，使用默认的http服务以便于测试查看，修改记录如下：\n\n``` yaml\n[root@xxx harbor]# vim harbor/harbor.yml\nhostname: 10.162.17.78\ndata_volume: /work/docker/harbor/data\nlog:\n  level: info\n  rotate_count: 50\n  rotate_size: 200M\n  location: /work/docker/harbor/log\n```\n\n​\t\t配置文件修改完成后，执行install.sh文件进行安装\n\n``` bash\n# 执行安装脚本，以下哪一步报错对应解决即可\n[root@xxxx harbor]# ./install.sh \n## 1. 检查docker是否安装及docker版本\n[Step 0]: checking if docker is installed ...\n\nNote: docker version: 18.03.1\n## 2. 检查docker-compose是否安装及对应版本\n[Step 1]: checking docker-compose is installed ...\n\nNote: docker-compose version: 1.25.4\n## 3. 加载harbor相关镜像\n[Step 2]: loading Harbor images ...\n47a4bb1cfbc7: Loading layer [==================================================>]  34.26MB/34.26MB\nc2d9cf7a4eaf: Loading layer [==================================================>]  9.056MB/9.056MB\n...\n54b809bfb5ec: Loading layer [==================================================>]  10.24kB/10.24kB\nLoaded image: goharbor/harbor-db:v1.10.1\n\n## 4. 准备环境,查看config.yml其中的hostname是否配置正确\n[Step 3]: preparing environment ...\n## 5. 准备配置文件\n[Step 4]: preparing harbor configs ...\nprepare base dir is set to /work/docker/harbor/harbor\nWARNING:root:WARNING: HTTP protocol is insecure. Harbor will deprecate http protocol in the future. Please make sure to upgrade to https\nGenerated configuration file: /config/log/logrotate.conf\nGenerated configuration file: /config/log/rsyslog_docker.conf\nGenerated configuration file: /config/nginx/nginx.conf\nGenerated configuration file: /config/core/env\nGenerated configuration file: /config/core/app.conf\nGenerated configuration file: /config/registry/config.yml\nGenerated configuration file: /config/registryctl/env\nGenerated configuration file: /config/db/env\nGenerated configuration file: /config/jobservice/env\nGenerated configuration file: /config/jobservice/config.yml\nGenerated and saved secret to file: /secret/keys/secretkey\nGenerated certificate, key file: /secret/core/private_key.pem, cert file: /secret/registry/root.crt\nGenerated configuration file: /compose_location/docker-compose.yml\nClean up the input dir\n\n\n## 6. 启动harbor\n[Step 5]: starting Harbor ...\nCreating network \"harbor_harbor\" with the default driver\nCreating harbor-log ... done\nCreating harbor-db     ... done\nCreating registryctl   ... done\nCreating harbor-portal ... done\nCreating registry      ... done\nCreating redis         ... done\nCreating harbor-core   ... done\nCreating nginx             ... done\nCreating harbor-jobservice ... done\n✔ ----Harbor has been installed and started successfully.----\n\n# 可看出，最终harbor启动了nginx、redis、registry、db、log等模块\n[root@xxx harbor]# docker ps\nCONTAINER ID        IMAGE                                                     COMMAND                  CREATED             STATUS                   PORTS                       NAMES\nb2a00d220528        goharbor/harbor-jobservice:v1.10.1                        \"/harbor/harbor_jobs…\"   4 minutes ago       Up 4 minutes (healthy)                               harbor-jobservice\n3bbf43ca6e63        goharbor/nginx-photon:v1.10.1                             \"nginx -g 'daemon of…\"   4 minutes ago       Up 4 minutes (healthy)   0.0.0.0:80->8080/tcp        nginx\nf3024394558d        goharbor/harbor-core:v1.10.1                              \"/harbor/harbor_core\"    4 minutes ago       Up 4 minutes (healthy)                               harbor-core\na2a1f9f07e4e        goharbor/redis-photon:v1.10.1                             \"redis-server /etc/r…\"   4 minutes ago       Up 4 minutes (healthy)   6379/tcp                    redis\n042965f58cf7        goharbor/registry-photon:v2.7.1-patch-2819-2553-v1.10.1   \"/home/harbor/entryp…\"   4 minutes ago       Up 4 minutes (healthy)   5000/tcp                    registry\ncbd4a760d1ee        goharbor/harbor-portal:v1.10.1                            \"nginx -g 'daemon of…\"   4 minutes ago       Up 4 minutes (healthy)   8080/tcp                    harbor-portal\na2e008d5258d        goharbor/harbor-registryctl:v1.10.1                       \"/home/harbor/start.…\"   4 minutes ago       Up 4 minutes (healthy)                               registryctl\nf8a3567b9172        goharbor/harbor-db:v1.10.1                                \"/docker-entrypoint.…\"   4 minutes ago       Up 4 minutes (healthy)   5432/tcp                    harbor-db\n84343b0a3fb5        goharbor/harbor-log:v1.10.1                               \"/bin/sh -c /usr/loc…\"   4 minutes ago       Up 4 minutes (healthy)   127.0.0.1:1514->10514/tcp   harbor-log\n\n## 配置文件中设置的数据及日志目录都分别有各个模块的数据\n[root@xxx harbor]# ls data/\nca_download  database  job_logs  psc  redis  registry  secret\n[root@xxx harbor]# ls log/\ncore.log  jobservice.log  portal.log  postgresql.log  proxy.log  redis.log  registryctl.log  registry.log\n```\n\n### 三、镜像上传及拉取测试\n\n​\t\t目前，Harbor服务已经启动，可通过web登录进入并搭建私有镜像仓库\n\n#### 1、登陆\n\n​\t\t\t<img src=\"harbor搭建docker私有镜像仓库/2.png\" style=\"zoom:25%;\" />\t\n\n#### 2、新建私有镜像仓库\n\n​\t\t\t\t\t\t\t\t\t<img src=\"harbor搭建docker私有镜像仓库/3.png\" style=\"zoom:25%;\" />\n\n​\t\t\t\t\t<img src=\"harbor搭建docker私有镜像仓库/4.png\" style=\"zoom:25%;\" />\n\n#### 3、客户端免https登陆\n\n``` bash\n# 此时直接使用docker login登陆到harbor中，会报错，下面hostname和port是harbor的配置文件中设置的名称及端口\n[root@xxxx harbor]# docker login [hostname]:[port]\nUsername: admin\nPassword: \nError response from daemon: Get https://[hostname:port]/v2/: http: server gave HTTP response to HTTPS client\n# 这是由于虽然harbor配置的是http端口启动，但客户端默认使用的是https协议，所以需要对docker做以下修改,在文件末尾添加insecure-registries\n[root@xxxx harbor]# vim /etc/docker/daemon.json\n{\n    \"graph\": \"/work/docker/data\",\n    \"insecure-registries\": [ \"hostname:port\" ]\n}\n# 修改后，重启docker使其生效\n[root@xxxx harbor]# systemctl restart docker.service\n# 利用docker info查看是否添加上\n[root@xxxx harbor]# docker info\nContainers: 10\n Running: 1\n Paused: 0\n Stopped: 9\nImages: 37\n...\nExperimental: false\nInsecure Registries:\n hostname:port\n 127.0.0.0/8\nLive Restore Enabled: false\n```\n\n​\t\t上面类似CentOs、ubuntu的设置客户端免https登陆的方法，但mac等安装了docker desktop主机上并没有这个文件，需要在desktop中修改，完成后重启docker\n\n​\t\t\t<img src=\"harbor搭建docker私有镜像仓库/5.png\" alt=\"image-20200329180536770\" style=\"zoom:33%;\" />\n\n#### 4、上传镜像\n\n``` bash\n[root@xxxx harbor]# docker login hostname:port\nUsername: admin\nPassword: \nLogin Succeeded\n[root@xxxx harbor]# docker tag clickhouse-server-demo:1.0 hostname:port/clickhouse/clickhouse-server-demo:1.0\n[root@xxxx harbor]# docker push hostname:port/clickhouse/clickhouse-server-demo:1.0\nThe push refers to repository [hostname:port/clickhouse/clickhouse-server-demo]\n4e418dcae3b7: Pushed \ne6fad812466e: Pushed \nb05b15db2cd1: Pushed \n1c79e943c270: Pushed \n0dbb638d17fd: Pushed \na5c6f2a2f0f4: Pushed \ne0367eb23283: Pushed \n16542a8fc3be: Pushed \n6597da2e2e52: Pushed \n977183d4e999: Pushed \nc8be1b8f4d60: Pushed \n1.0: digest: sha256:6247b85f528c16e534a6f8c3be2b7baa70054d0be0a4ffa42b256259034c3268 size: 2617\n```\n\n​\t<img src=\"harbor搭建docker私有镜像仓库/6.png\" style=\"zoom:33%;\" />\n\n#### 5、下载镜像\n\n``` bash\n# 用另外一个机器当测试机，拉取镜像，从harbor web页面也可发现下载数变为了1\n[root@xx ~]# docker pull hostname:port/clickhouse/clickhouse-server-demo:1.0\n```\n\n<img src=\"harbor搭建docker私有镜像仓库/7.png\" style=\"zoom:25%;\" />\n\n<img src=\"harbor搭建docker私有镜像仓库/8.png\" style=\"zoom:25%;\" />\n","tags":["docker","harbor"],"categories":["harbor"]},{"title":"docker-compose定制clickhouse配置启动","url":"/2020/03/28/clickhouse/docker-compose定制clickhouse配置启动/","content":"\n​\t\t上一篇介绍[clickhouse的docker架构](https://schnappi618.github.io/2020/03/21/clickhouse%E7%9A%84docker%E6%9E%B6%E6%9E%84/)中通过剥离ClickHouse提供的官方docker代码中server的必需代码打包了一个完整的clickhouse的镜像，但启动之后的配置文件都是默认的，http、MySQL访问接口以及用户权限等都未进行设置，其clickhouse服务在环境中相当于裸奔状态，本文将通过docker-compose设置clickhouse的配置文件、用户设置等来完成其定制化启动。\n\n**参考文档：**\n\n- [docker-compose官方文档](https://docs.docker.com/compose/)\n- [clickhouse-server设置文档](https://clickhouse.tech/docs/zh/operations/server_settings/settings/)\n\n## 一、docker-compose简介\n\n### 1、什么是docker-compose\n\n​\t\tdocker-compose是一个用户定义并运行多个容器的Docker工具，可以通过YAML文件配置服务，并通过命令按照文件配置启动该服务。\n\n​\t\t**docker-compose一般使用的步骤：**\n\n- 使用Dockerfile或打包好的docker镜像作为应用程序的基础环境\n\n- docker-compose.yml文件定义构成应用程序的服务，例如：网络环境，端口等情况\n- 执行`docker-compose up`命令启动并运行应用程序\n\n### 2、docker-compose安装\n\n​\t\t若为windows或mac安装了docker desktop版本，均已经自带了docker-compose命令，直接使用即可，若为其他CentOS或ubuntu等的linux版本，安装docker以后还需要另外安装docker-compose命令(目前最新的稳定版本为1.25.4，所以下面的安装方法为1.25.4版本，后续若需要最新的版本，可到[docker-compose的github网站上](https://github.com/docker/compose/releases)安装即可)，安装方法为：\n\n``` bash\ncurl -L https://github.com/docker/compose/releases/download/1.25.4/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose\n```\n\n\n\n## 二、docker-compose定制clickhouse配置\n\n### 1、文件结构\n\n​\t\t新建一个目录用来放置docker-compose启动clickhouse的配置文件等信息，具体文件结构如下：\n\n``` bash\n┌─[bulubulu@localhost] - [~/clickhouse/docker_compose] - [2020-03-28 10:01:47]\n└─[0] <> tree .\n.\n├── config.xml\n├── data\n├── docker-compose.yml\n├── log\n│   ├── clickhouse-server.err.log\n│   └── clickhouse-server.log\n└── users.xml\n## config.xml：clickhouse-server的配置文件\n## data：利用docker启动clickhouse后的数据目录\n## docker-compose.yml：docker-compose的配置文件\n## log：日志目录\n## user.xml：clickhouse-server的用户配置文件\n```\n\n### 2、docker-compose.yml文件内容\n\n​\t\tdocker-compose.yml为compose的核心，该文件的大部分指令均与`docker run`相关参数含义类似。\n\n``` yaml\nversion: '3'\nservices:\n\t# 服务名称为：clickhouse-server\n  clickhouse-server:\n  \t# image：指定镜像，可以为镜像名称或镜像id，如果本地没有该镜像，compose会尝试pull该镜像\n    image: clickhouse-server-demo:1.0\n    # container_name：指定容器名称，默认为 项目名称_服务名称_序号 的格式\n    container_name: clickhouse-server_1\n    # hostname：指定容器主机名\n    hostname: clickhouse-server_1\n    # networks配置该容器连接的网络，指定到文件末尾定义的networks\n    networks:\n      - test-bridge\n    # ports：暴露端口信息，格式为 宿主机端口:容器端口；仅指定容器端口时，宿主机会随机选择端口，类似于docker run -p\n    ports:\n      - \"8123:8123\"\n      - \"9000:9000\"\n      - \"9004:9004\"\n    # expose：暴露端口，但不映射到宿主机，所以外部无法访问该端口，仅能容器内部访问使用\n    expose:\n      - 9009\n    # volumes：数据卷挂载路径设置，类似于docker run --volumn=hostdir:containerDir，也可指定文件权限\n    volumes:\n    # 例如：将当前目录下的config.xml文件映射到容器中的/etc/clickhouse-server/config.xml文件\n      - ./config.xml:/etc/clickhouse-server/config.xml\n      - ./users.xml:/etc/clickhouse-server/users.xml\n      - ./data:/var/lib/clickhouse\n      - ./log/clickhouse-server.log:/var/log/clickhouse-server/clickhouse-server.log\n      - ./log/clickhouse-server.err.log:/var/log/clickhouse-server/clickhouse-server.err.log\n\nnetworks:\n# networks名称为test-bridge，和上面services中networks下的名称对应\n  test-bridge:\n  # external表示compose启动时会找到名为docker-compose-default的已存在的网络，若未找到该网络，则docker-compose up启动时会报错，同时通过 docker network ls 查看本地目前有哪些网络\n    external:\n      name: docker_compose_default\n```\n\n### 3、config.xml文件内容\n\n​\t\t从docker-compose.yml文件中可以看出，该文件其实为clickhose-server的配置文件，本次基本使用了一些默认的配置，对clickhouse-server配置文件的解释可参考[clickhouse-server配置文件详解]([https://schnappi618.github.io/2020/03/28/clickhouse-server%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/](https://schnappi618.github.io/2020/03/28/clickhouse-server配置文件详解/))，该文件内容如下：\n\n``` xml\n<?xml version=\"1.0\"?>\n<yandex>\n    <logger>\n        <level>trace</level>\n        <log>/var/log/clickhouse-server/clickhouse-server.log</log>\n        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>\n        <size>1000M</size>\n        <count>10</count>\n    </logger>\n\n    <http_port>8123</http_port>   <!-- 通过url访问clickhouse的端口号 -->\n    <tcp_port>9000</tcp_port>     <!-- 通过tcp访问clickhouse的端口号 -->\n    <mysql_port>9004</mysql_port>  <!-- 通过mysql访问clickhouse的端口号 -->\n\n    <!-- For HTTPS and SSL over native protocol. -->\n    <!--\n    <https_port>8443</https_port>\n    <tcp_ssl_port>9440</tcp_ssl_port>\n    -->\n\n    <!-- Used with https_port and tcp_ssl_port. Full ssl options list: https://github.com/yandex/ClickHouse/blob/master/contrib/libpoco/NetSSL_OpenSSL/include/Poco/Net/SSLManager.h#L71 -->\n    <openSSL>\n        <server> <!-- Used for https server AND secure tcp port -->\n            <!-- openssl req -subj \"/CN=localhost\" -new -newkey rsa:2048 -days 365 -nodes -x509 -keyout /etc/clickhouse-server/server.key -out /etc/clickhouse-server/server.crt -->\n            <certificateFile>/etc/clickhouse-server/server.crt</certificateFile>\n            <privateKeyFile>/etc/clickhouse-server/server.key</privateKeyFile>\n            <!-- openssl dhparam -out /etc/clickhouse-server/dhparam.pem 4096 -->\n            <dhParamsFile>/etc/clickhouse-server/dhparam.pem</dhParamsFile>\n            <verificationMode>none</verificationMode>\n            <loadDefaultCAFile>true</loadDefaultCAFile>\n            <cacheSessions>true</cacheSessions>\n            <disableProtocols>sslv2,sslv3</disableProtocols>\n            <preferServerCiphers>true</preferServerCiphers>\n        </server>\n\n        <client> <!-- Used for connecting to https dictionary source -->\n            <loadDefaultCAFile>true</loadDefaultCAFile>\n            <cacheSessions>true</cacheSessions>\n            <disableProtocols>sslv2,sslv3</disableProtocols>\n            <preferServerCiphers>true</preferServerCiphers>\n            <!-- Use for self-signed: <verificationMode>none</verificationMode> -->\n            <invalidCertificateHandler>\n                <!-- Use for self-signed: <name>AcceptCertificateHandler</name> -->\n                <name>RejectCertificateHandler</name>\n            </invalidCertificateHandler>\n        </client>\n    </openSSL>\n\n    <!-- Default root page on http[s] server. For example load UI from https://tabix.io/ when opening http://localhost:8123 -->\n    <!--\n    <http_server_default_response><![CDATA[<html ng-app=\"SMI2\"><head><base href=\"http://ui.tabix.io/\"></head><body><div ui-view=\"\" class=\"content-ui\"></div><script src=\"http://loader.tabix.io/master.js\"></script></body></html>]]></http_server_default_response>\n    -->\n\n    <!-- Port for communication between replicas. Used for data exchange. -->\n    <interserver_http_port>9009</interserver_http_port>\n\n    <!-- Hostname that is used by other replicas to request this server.\n         If not specified, than it is determined analoguous to 'hostname -f' command.\n         This setting could be used to switch replication to another network interface.\n      -->\n    <!--\n    <interserver_http_host>example.yandex.ru</interserver_http_host>\n    -->\n\n    <!-- Listen specified host. use :: (wildcard IPv6 address), if you want to accept connections both with IPv4 and IPv6 from everywhere. -->\n    <!-- <listen_host>::</listen_host> -->\n    <!-- Same for hosts with disabled ipv6: -->\n    <!-- <listen_host>0.0.0.0</listen_host> -->\n\n    <!-- Default values - try listen localhost on ipv4 and ipv6: -->\n    <!--\n    <listen_host>::1</listen_host>\n    <listen_host>127.0.0.1</listen_host>\n    -->\n\n    <max_connections>4096</max_connections>\n    <keep_alive_timeout>3</keep_alive_timeout>\n\n    <!-- Maximum number of concurrent queries. -->\n    <max_concurrent_queries>100</max_concurrent_queries>\n\n    <!-- Set limit on number of open files (default: maximum). This setting makes sense on Mac OS X because getrlimit() fails to retrieve\n         correct maximum value. -->\n    <!-- <max_open_files>262144</max_open_files> -->\n\n    <!-- Size of cache of uncompressed blocks of data, used in tables of MergeTree family.\n         In bytes. Cache is single for server. Memory is allocated only on demand.\n         Cache is used when 'use_uncompressed_cache' user setting turned on (off by default).\n         Uncompressed cache is advantageous only for very short queries and in rare cases.\n      -->\n    <uncompressed_cache_size>8589934592</uncompressed_cache_size>\n\n    <!-- Approximate size of mark cache, used in tables of MergeTree family.\n         In bytes. Cache is single for server. Memory is allocated only on demand.\n         You should not lower this value.\n      -->\n    <mark_cache_size>5368709120</mark_cache_size>\n\n\n    <!-- Path to data directory, with trailing slash. -->\n    <path>/var/lib/clickhouse/</path>\n\n    <!-- Path to temporary data for processing hard queries. -->\n    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>\n\n    <!-- Path to configuration file with users, access rights, profiles of settings, quotas. -->\n    <users_config>users.xml</users_config>\n    <!-- <users>\n    <default>\n            <password_sha256_hex>8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92</password_sha256_hex>\n            <networks incl=\"networks\" replace=\"replace\">\n                <ip>127.0.0.1/0</ip>\n            </networks>\n            <profile>default</profile>\n            <quota>default</quota>\n        </default>\n        <ck>\n            <password_sha256_hex>8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92</password_sha256_hex>\n            <networks incl=\"networks\" replace=\"replace\">\n                <ip>::/0</ip>\n            </networks>\n            <profile>readonly</profile>\n            <quota>default</quota>\n        </ck>\n    </users> -->\n    <!-- Default profile of settings.. -->\n    <default_profile>default</default_profile>\n\n    <!-- Default database. -->\n    <default_database>default</default_database>\n\n    <!-- Server time zone could be set here.\n\n         Time zone is used when converting between String and DateTime types,\n          when printing DateTime in text formats and parsing DateTime from text,\n          it is used in date and time related functions, if specific time zone was not passed as an argument.\n\n         Time zone is specified as identifier from IANA time zone database, like UTC or Africa/Abidjan.\n         If not specified, system time zone at server startup is used.\n\n         Please note, that server could display time zone alias instead of specified name.\n         Example: W-SU is an alias for Europe/Moscow and Zulu is an alias for UTC.\n    -->\n    <timezone>Asia/Shanghai</timezone>\n\n    <!-- You can specify umask here (see \"man umask\"). Server will apply it on startup.\n         Number is always parsed as octal. Default umask is 027 (other users cannot read logs, data files, etc; group can only read).\n    -->\n    <!-- <umask>022</umask> -->\n\n    <!-- Configuration of clusters that could be used in Distributed tables.\n         https://clickhouse.yandex/reference_en.html#Distributed\n      -->\n    <remote_servers incl=\"clickhouse_remote_servers\" >\n        <!-- Test only shard config for testing distributed storage -->\n        <test_shard_localhost>\n            <shard>\n                <replica>\n                    <host>localhost</host>\n                    <port>9000</port>\n                </replica>\n            </shard>\n        </test_shard_localhost>\n    </remote_servers>\n\n\n    <!-- If element has 'incl' attribute, then for it's value will be used corresponding substitution from another file.\n         By default, path to file with substitutions is /etc/metrika.xml. It could be changed in config in 'include_from' element.\n         Values for substitutions are specified in /yandex/name_of_substitution elements in that file.\n      -->\n\n    <!-- ZooKeeper is used to store metadata about replicas, when using Replicated tables.\n         Optional. If you don't use replicated tables, you could omit that.\n\n         See https://clickhouse.yandex/reference_en.html#Data%20replication\n      -->\n    <zookeeper incl=\"zookeeper-servers\" optional=\"true\" />\n\n    <!-- Substitutions for parameters of replicated tables.\n          Optional. If you don't use replicated tables, you could omit that.\n\n         See https://clickhouse.yandex/reference_en.html#Creating%20replicated%20tables\n      -->\n    <macros incl=\"macros\" optional=\"true\" />\n\n\n    <!-- Reloading interval for embedded dictionaries, in seconds. Default: 3600. -->\n    <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>\n\n\n    <!-- Maximum session timeout, in seconds. Default: 3600. -->\n    <max_session_timeout>3600</max_session_timeout>\n\n    <!-- Default session timeout, in seconds. Default: 60. -->\n    <default_session_timeout>60</default_session_timeout>\n\n    <!-- Sending data to Graphite for monitoring. Several sections can be defined. -->\n    <!--\n        interval - send every X second\n        root_path - prefix for keys\n        hostname_in_path - append hostname to root_path (default = true)\n        metrics - send data from table system.metrics\n        events - send data from table system.events\n        asynchronous_metrics - send data from table system.asynchronous_metrics\n    -->\n    <!--\n    <graphite>\n        <host>localhost</host>\n        <port>42000</port>\n        <timeout>0.1</timeout>\n        <interval>60</interval>\n        <root_path>one_min</root_path>\n        <hostname_in_path>true<hostname_in_path>\n\n        <metrics>true</metrics>\n        <events>true</events>\n        <asynchronous_metrics>true</asynchronous_metrics>\n    </graphite>\n    <graphite>\n        <host>localhost</host>\n        <port>42000</port>\n        <timeout>0.1</timeout>\n        <interval>1</interval>\n        <root_path>one_sec</root_path>\n\n        <metrics>true</metrics>\n        <events>true</events>\n        <asynchronous_metrics>false</asynchronous_metrics>\n    </graphite>\n    -->\n\n\n    <!-- Query log. Used only for queries with setting log_queries = 1. -->\n    <query_log>\n        <!-- What table to insert data. If table is not exist, it will be created.\n             When query log structure is changed after system update,\n              then old table will be renamed and new table will be created automatically.\n        -->\n        <database>system</database>\n        <table>query_log</table>\n\n        <!-- Interval of flushing data. -->\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </query_log>\n\n\n    <!-- Uncomment if use part_log\n    <part_log>\n        <database>system</database>\n        <table>part_log</table>\n\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </part_log>\n    -->\n\n\n    <!-- Parameters for embedded dictionaries, used in Yandex.Metrica.\n         See https://clickhouse.yandex/reference_en.html#Internal%20dictionaries\n    -->\n\n    <!-- Path to file with region hierarchy. -->\n    <!-- <path_to_regions_hierarchy_file>/opt/geo/regions_hierarchy.txt</path_to_regions_hierarchy_file> -->\n\n    <!-- Path to directory with files containing names of regions -->\n    <!-- <path_to_regions_names_files>/opt/geo/</path_to_regions_names_files> -->\n\n\n    <!-- Configuration of external dictionaries. See:\n         https://clickhouse.yandex/reference_en.html#External%20Dictionaries\n    -->\n    <dictionaries_config>*_dictionary.xml</dictionaries_config>\n\n    <!-- Uncomment if you want data to be compressed 30-100% better.\n         Don't do that if you just started using ClickHouse.\n      -->\n    <compression incl=\"clickhouse_compression\">\n    <!--\n        <!- - Set of variants. Checked in order. Last matching case wins. If nothing matches, lz4 will be used. - ->\n        <case>\n\n            <!- - Conditions. All must be satisfied. Some conditions may be omitted. - ->\n            <min_part_size>10000000000</min_part_size>        <!- - Min part size in bytes. - ->\n            <min_part_size_ratio>0.01</min_part_size_ratio>   <!- - Min size of part relative to whole table size. - ->\n\n            <!- - What compression method to use. - ->\n            <method>zstd</method>\n        </case>\n    -->\n    </compression>\n\n    <!-- Allow to execute distributed DDL queries (CREATE, DROP, ALTER, RENAME) on cluster.\n         Works only if ZooKeeper is enabled. Comment it if such functionality isn't required. -->\n    <distributed_ddl>\n        <!-- Path in ZooKeeper to queue with DDL queries -->\n        <path>/clickhouse/task_queue/ddl</path>\n    </distributed_ddl>\n\n    <!-- Settings to fine tune MergeTree tables. See documentation in source code, in MergeTreeSettings.h -->\n    <!--\n    <merge_tree>\n        <max_suspicious_broken_parts>5</max_suspicious_broken_parts>\n    </merge_tree>\n    -->\n\n    <!-- Protection from accidental DROP.\n         If size of a MergeTree table is greater than max_table_size_to_drop (in bytes) than table could not be dropped with any DROP query.\n         If you want do delete one table and don't want to restart clickhouse-server, you could create special file <clickhouse-path>/flags/force_drop_table and make DROP once.\n         By default max_table_size_to_drop is 50GB, max_table_size_to_drop=0 allows to DROP any tables.\n         Uncomment to disable protection.\n    -->\n    <!-- <max_table_size_to_drop>0</max_table_size_to_drop> -->\n\n    <!-- Example of parameters for GraphiteMergeTree table engine -->\n    <graphite_rollup_example>\n        <pattern>\n            <regexp>click_cost</regexp>\n            <function>any</function>\n            <retention>\n                <age>0</age>\n                <precision>3600</precision>\n            </retention>\n            <retention>\n                <age>86400</age>\n                <precision>60</precision>\n            </retention>\n        </pattern>\n        <default>\n            <function>max</function>\n            <retention>\n                <age>0</age>\n                <precision>60</precision>\n            </retention>\n            <retention>\n                <age>3600</age>\n                <precision>300</precision>\n            </retention>\n            <retention>\n                <age>86400</age>\n                <precision>3600</precision>\n            </retention>\n        </default>\n    </graphite_rollup_example>\n\n    <!-- Directory in <clickhouse-path> containing schema files for various input formats.\n         The directory will be created if it doesn't exist.\n      -->\n    <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>\n</yandex>\n```\n\n### 3、users.xml文件内容\n\n​\t\tclickhouse-server中users.xml文件表示了对其服务的用户及权限的设置，本次文件也在默认配置下进行了修改，具体每个配置代表的意义可以参考[clickhouse用户配置详解]([https://schnappi618.github.io/2020/03/28/clickhouse%E7%94%A8%E6%88%B7%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/](https://schnappi618.github.io/2020/03/28/clickhouse用户配置详解/))，内容如下：\n\n``` xml\n<?xml version=\"1.0\"?>\n<yandex>\n    <!-- Profiles of settings. -->\n    <profiles>\n        <!-- Default settings. -->\n        <default>\n            <!-- Maximum memory usage for processing single query, in bytes. -->\n            <max_memory_usage>10000000000</max_memory_usage>\n\n            <!-- Use cache of uncompressed blocks of data. Meaningful only for processing many of very short queries. -->\n            <use_uncompressed_cache>0</use_uncompressed_cache>\n\n            <!-- How to choose between replicas during distributed query processing.\n                 random - choose random replica from set of replicas with minimum number of errors\n                 nearest_hostname - from set of replicas with minimum number of errors, choose replica\n                  with minumum number of different symbols between replica's hostname and local hostname\n                  (Hamming distance).\n                 in_order - first live replica is choosen in specified order.\n            -->\n            <load_balancing>random</load_balancing>\n        </default>\n\n        <!-- Profile that allows only read queries. -->\n        <readonly>\n            <readonly>1</readonly>\n        </readonly>\n    </profiles>\n\n    <!-- Users and ACL. -->\n    <users>\n        <!-- If user name was not specified, 'default' user is used. -->\n        <default>\n            <!-- Password could be specified in plaintext or in SHA256 (in hex format).\n\n                 If you want to specify password in plaintext (not recommended), place it in 'password' element.\n                 Example: <password>qwerty</password>.\n                 Password could be empty.\n\n                 If you want to specify SHA256, place it in 'password_sha256_hex' element.\n                 Example: <password_sha256_hex>65e84be33532fb784c48129675f9eff3a682b27168c0ea744b2cf58ee02337c5</password_sha256_hex>\n\n                 How to generate decent password:\n                 Execute: PASSWORD=$(base64 < /dev/urandom | head -c8); echo \"$PASSWORD\"; echo -n \"$PASSWORD\" | sha256sum | tr -d '-'\n                 In first line will be password and in second - corresponding SHA256.\n            -->\n            <password></password>\n\n            <!-- List of networks with open access.\n\n                 To open access from everywhere, specify:\n                    <ip>::/0</ip>\n\n                 To open access only from localhost, specify:\n                    <ip>::1</ip>\n                    <ip>127.0.0.1</ip>\n\n                 Each element of list has one of the following forms:\n                 <ip> IP-address or network mask. Examples: 213.180.204.3 or 10.0.0.1/8 or 2a02:6b8::3 or 2a02:6b8::3/64.\n                 <host> Hostname. Example: server01.yandex.ru.\n                     To check access, DNS query is performed, and all received addresses compared to peer address.\n                 <host_regexp> Regular expression for host names. Example, ^server\\d\\d-\\d\\d-\\d\\.yandex\\.ru$\n                     To check access, DNS PTR query is performed for peer address and then regexp is applied.\n                     Then, for result of PTR query, another DNS query is performed and all received addresses compared to peer address.\n                     Strongly recommended that regexp is ends with $\n                 All results of DNS requests are cached till server restart.\n            -->\n            <networks incl=\"networks\" replace=\"replace\">\n                <ip>::1</ip>\n        <ip>127.0.0.1</ip>\n            </networks>\n\n            <!-- Settings profile for user. -->\n            <profile>default</profile>\n\n            <!-- Quota for user. -->\n            <quota>default</quota>\n        </default>\n\n        <!-- Example of user with readonly access. 说明：下面有两个用户seluser（readonly表示只读权限）和inuser（default表示默认权限）密码如下 -->\n        <seluser>\n            <password>meiyoumima</password>\n            <networks incl=\"networks\" replace=\"replace\">\n                <ip>::/0</ip>\n            </networks>\n            <profile>readonly</profile>\n            <quota>default</quota>\n        </seluser>\n        <inuser>\n            <password>meiyoumima</password>\n            <networks incl=\"networks\" replace=\"replace\">\n                <ip>::/0</ip>\n            </networks>\n            <profile>default</profile>\n            <quota>default</quota>\n        </inuser>\n    </users>\n\n    <!-- Quotas. -->\n    <quotas>\n        <!-- Name of quota. -->\n        <default>\n            <!-- Limits for time interval. You could specify many intervals with different limits. -->\n            <interval>\n                <!-- Length of interval. -->\n                <duration>3600</duration>\n\n                <!-- No limits. Just calculate resource usage for time interval. -->\n                <queries>0</queries>\n                <errors>0</errors>\n                <result_rows>0</result_rows>\n                <read_rows>0</read_rows>\n                <execution_time>0</execution_time>\n            </interval>\n        </default>\n    </quotas>\n</yandex>\n```\n\n## 三、启动并测试服务\n\n### 1、启动服务\n\n``` bash\n# 启动该服务，docker-compose表示创建并启动该容器，-d表示放入后台\n[rootxxxx docker_compose]# docker-compose up -d\nCreating clickhouse-server_1 ... done\n# 查看启动状态\n[rootxxxx docker_compose]# docker ps\nCONTAINER ID        IMAGE                        COMMAND             CREATED             STATUS              PORTS                                                                              NAMES\n92b25e101be0        clickhouse-server-demo:1.0   \"/entrypoint.sh\"    3 seconds ago       Up 2 seconds        0.0.0.0:8123->8123/tcp, 0.0.0.0:9000->9000/tcp, 0.0.0.0:9004->9004/tcp, 9009/tcp   clickhouse-server_1\n```\n\n### 2、测试用户配置\n\n​\t\t从users.xml文件中可以看到创建了一个用户名为seluser，密码为meiyoumima的只读用户，这里通过该用户是否可以登陆服务，并且权限是否正确进行简单的测试\n\n``` bash\n# 通过对外暴露的tcp端口9000使用clickhouse-client登陆测试\n## 1. seluser只读用户登陆\n[rootxxxx docker_compose]# docker run -it --rm --link clickhouse-server_1:docker_compose --net docker_compose_default clickhouse-server-demo:1.0 usr/bin/clickhouse-client --host docker_compose --user seluser --password meiyoumima\nClickHouse client version 20.3.4.10 (official build).\nConnecting to docker_compose:9000 as user seluser.\nConnected to ClickHouse server version 20.3.4 revision 54433.\n\nclickhouse-server_1 :) show databases\n\nSHOW DATABASES\n\n┌─name────┐\n│ default │\n│ system  │\n└─────────┘\n\n2 rows in set. Elapsed: 0.002 sec. \n\nclickhouse-server_1 :) create database test\t\t# 可以看到由于seluser是个readonly的用户，所以无法创建数据库\n\nCREATE DATABASE test\n\nReceived exception from server (version 20.3.4):\nCode: 164. DB::Exception: Received from docker_compose:9000. DB::Exception: seluser: Cannot execute query in readonly mode. \n\n0 rows in set. Elapsed: 0.071 sec. \n\nclickhouse-server_1 :) \n\n## 2. inuser读写用户登陆\n[rootxxxx docker_compose]# docker run -it --rm --link clickhouse-server_1:docker_compose --net docker_compose_default clickhouse-server-demo:1.0 usr/bin/clickhouse-client --host docker_compose --user inuser --password meiyoumima \nClickHouse client version 20.3.4.10 (official build).\nConnecting to docker_compose:9000 as user inuser.\nConnected to ClickHouse server version 20.3.4 revision 54433.\n\nclickhouse-server_1 :) create database test\t\t\t# inuser读写用户创建test库成功\n\nCREATE DATABASE test\n\nOk.\n\n0 rows in set. Elapsed: 0.001 sec. \n\nclickhouse-server_1 :) show databases\n\nSHOW DATABASES\n\n┌─name────┐\n│ default │\n│ system  │\n│ test    │\n└─────────┘\n\n3 rows in set. Elapsed: 0.002 sec.\n\n# 3、从上面的config.xml中可以看到开启了其他远程主机通过mysql登陆的方法，端口为9004\n[rootxxxx ~]\n$ mysql -h xx.xx.xx.xx -P9004 -u seluser -p\nEnter password: \nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 3\nServer version: 20.3.4.10-ClickHouse \n\nCopyright (c) 2009-2017 Percona LLC and/or its affiliates\nCopyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nmysql> show databases;\n+---------+\n| name    |\n+---------+\n| default |\n| system  |\n| test    |\n+---------+\n3 rows in set (0.00 sec)\n\nmysql> create database zztest;\nERROR 164 (00000): seluser: Cannot execute query in readonly mode\n```\n\n","tags":["clickhouse","docker"],"categories":["clickhouse"]},{"title":"clickhouse的docker架构","url":"/2020/03/21/clickhouse/clickhouse的docker架构/","content":"\n​\t\t由于最终选用了docker方法安装了clickhouse，便从github下载了[clickhouse源码](https://github.com/ClickHouse/ClickHouse/)，对clickhouse提供的docker目录结构进行了解，并且积累有关docker的知识(本文仅会通过clickhouse本身的Dockerfile文件简单描述其中使用到的各个命令的作用及在当前使用的情况，详细关于Dockerfile中指令的作用示例等会在之后的docker部分中进行学习描述^_^)，从而方便之后修改打包出需要的镜像。\n\n## 一、ClickHouse的docker文件架构\n\n​\t\tclickhouse关于docker的文件目录分为builder、client、packager、server、test以及外层的docker-compose.yml文件，docker目录的树状结构如下：\n\n<details>\n  <summary><font>docker文件目录</font></summary>\n  <pre><code>  \ndocker\n├── README.md\n├── builder\t\t\t\t\t\t\t# gcc-9/ninja/cmake... 等基础环境的安装\n│   ├── Dockerfile\n│   ├── Makefile\n│   ├── README.md\n│   └── build.sh\n├── client\t\t\t\t\t\t\t# 安装clickhouse client\n│   ├── Dockerfile\n│   └── README.md\n├── images.json\n├── packager\n│   ├── README.md\n│   ├── binary\n│   │   ├── Dockerfile\n│   │   └── build.sh\n│   ├── deb\n│   │   ├── Dockerfile\n│   │   └── build.sh\n│   ├── freebsd\n│   │   └── Vagrantfile\n│   └── packager\n├── server\t\t\t\t\t\t# 安装配置clickhouse server\n│   ├── Dockerfile\n│   ├── README.md\n│   ├── docker_related_config.xml\n│   ├── entrypoint.sh\n│   └── local.Dockerfile\n└── test\t\t\t\t\t\t\t# 用于测试使用\n    ├── Dockerfile\n    ├── README.md\n    ├── codebrowser\n    │   └── Dockerfile\n    ├── compatibility\n    │   ├── centos\n    │   │   └── Dockerfile\n    │   └── ubuntu\n    │       └── Dockerfile\n    ├── coverage\n    │   └── Dockerfile\n    ├── integration\n    │   └── Dockerfile\n    ├── performance\n    │   ├── Dockerfile\n    │   ├── run.sh\n    │   └── s3downloader\n    ├── performance-comparison\n    │   ├── Dockerfile\n    │   ├── compare.sh\n    │   ├── config\n    │   │   ├── config.d\n    │   │   │   └── perf-comparison-tweaks-config.xml\n    │   │   └── users.d\n    │   │       └── perf-comparison-tweaks-users.xml\n    │   ├── download.sh\n    │   ├── entrypoint.sh\n    │   ├── eqmed.sql\n    │   ├── perf.py\n    │   ├── performance_comparison.md\n    │   └── report.py\n    ├── pvs\n    │   └── Dockerfile\n    ├── split_build_smoke_test\n    │   ├── Dockerfile\n    │   └── run.sh\n    ├── stateful\n    │   ├── Dockerfile\n    │   └── s3downloader\n    ├── stateful_with_coverage\n    │   ├── Dockerfile\n    │   ├── run.sh\n    │   └── s3downloader\n    ├── stateless\n    │   ├── Dockerfile\n    │   └── clickhouse-statelest-test-runner.Dockerfile\n    ├── stateless_with_coverage\n    │   ├── Dockerfile\n    │   └── run.sh\n    ├── stress\n    │   ├── Dockerfile\n    │   ├── README.md\n    │   └── stress\n    ├── test_runner.sh\n    ├── test_runner_docker_compose.yaml\n    └── unit\n        └── Dockerfile\n  </code></pre>\n</details>\n\n## 二、server内容详解\n\n​\t\tClickHouse docker的server目录包含了：Dockerfile、README.md、docker_related_config.xml、entrypoint.sh、local.Dockerfile这些文件，其中README.md简单介绍了如何通过docker启动clickhouse服务等基本应用，将从Dockerfile文件内容入手从而解释其他文件的作用。\n\n### 2.1、Dockerfile文件内容\n\n```dockerfile\nFROM ubuntu:18.04\n\n## ARG 构建参数： repository、version、gosu_ver\nARG repository=\"deb http://repo.yandex.ru/clickhouse/deb/stable/ main/\"\n\n## 官方目前还没有clickhouse-common-statis/client/server的20.4.1.*这个版本，改为version=20.3.4.*即可docker build打包镜像\nARG version=20.4.1.*\nARG gosu_ver=1.10\n\n## RUN 执行命令：安装基础命令及clickhouse-client/clickhouse-server/clickhouse-common-static...\nRUN apt-get update \\\n    && apt-get install --yes --no-install-recommends \\\n        apt-transport-https \\\n        dirmngr \\\n        gnupg \\\n    && mkdir -p /etc/apt/sources.list.d \\\n    && apt-key adv --keyserver keyserver.ubuntu.com --recv E0C56BD4 \\\n    && echo $repository > /etc/apt/sources.list.d/clickhouse.list \\\n    && apt-get update \\\n    && env DEBIAN_aFRONTEND=noninteractive \\\n        apt-get install --allow-unauthenticated --yes --no-install-recommends \\\n            clickhouse-common-static=$version \\\n            clickhouse-client=$version \\\n            clickhouse-server=$version \\\n            locales \\\n            tzdata \\\n            wget \\\n    && rm -rf \\\n        /var/lib/apt/lists/* \\\n        /var/cache/debconf \\\n        /tmp/* \\\n    && apt-get clean\n\n## ADD: 将github上的gosu-amd64下载为/bin/gosu文件, gosu类似于linux中的sudo命令\nADD https://github.com/tianon/gosu/releases/download/$gosu_ver/gosu-amd64 /bin/gosu\n\n# 语言环境修改\n## 生成需要的locale文件\nRUN locale-gen en_US.UTF-8\n## ENV：设置环境变量\nENV LANG en_US.UTF-8\nENV LANGUAGE en_US:en\nENV LC_ALL en_US.UTF-8\nENV TZ UTC\n\nRUN mkdir /docker-entrypoint-initdb.d\n\n## COPY：复制文件，eg：将docker_related_config.xml文件复制到/etc/clickhouse-server/config.d/目录下，不需要提前创建目标目录，若不存在，COPY会自动创建\nCOPY docker_related_config.xml /etc/clickhouse-server/config.d/\nCOPY entrypoint.sh /entrypoint.sh\n\nRUN chmod +x \\\n    /entrypoint.sh \\\n    /bin/gosu\n\n## EXPOSE：暴露端口，仅声明容器运行时应该打开哪些服务端口，方便启动docker run -p时配置映射关系\nEXPOSE 9000 8123 9009\n\n## VOLUME: 数据持久化，会将启动后容器/var/lib/clickhouse目录下的数据写入到宿主机上，如果docker run时指定了--volume=/work/docker/clickhouse_test_db:/var/lib/clickhouse，便会同步至宿主机的/work/docker/clickhouse_test_db目录，若未指定会写入宿主机docker info的Docker Root Dir目录下\nVOLUME /var/lib/clickhouse\n\n## 设置CLICKHOUSE_CONFIG环境变量\nENV CLICKHOUSE_CONFIG /etc/clickhouse-server/config.xml\n\n## ENTRYPOINT [\"shell脚本\"]：执行容器运行前的一些准备工作\nENTRYPOINT [\"/entrypoint.sh\"]\n```\n\n### 2.2 docker_related_config.xml文件内容\n\n​\t\t从Dockerfile中可以看到，docker_related_config.xml文件会被放置在clickhouse-server的配置目录`/etc/clickhouse-server/config.d/`下，用来配置clickhouse-server容器的监听地址，默认配置允许接受来自其他容器和主机网络的连接。\n\n``` xml\n<yandex>\n     <!-- Listen wildcard address to allow accepting connections from other containers and host network. -->\n    <listen_host>::</listen_host>\n    <listen_host>0.0.0.0</listen_host>\n    <listen_try>1</listen_try>\n\n    <!--\n    <logger>\n        <console>1</console>\n    </logger>\n    -->\n</yandex>\n```\n\n### 2.3、entrypoint.sh文件内容\n\n``` shell\n#!/bin/bash\nDO_CHOWN=1\nif [ \"$CLICKHOUSE_DO_NOT_CHOWN\" = 1 ]; then\n    DO_CHOWN=0\nfi\n\nCLICKHOUSE_UID=\"${CLICKHOUSE_UID:-\"$(id -u clickhouse)\"}\"\nCLICKHOUSE_GID=\"${CLICKHOUSE_GID:-\"$(id -g clickhouse)\"}\"\n\n# support --user\n## 设置USER/GROUP为clickhouse\nif [ x\"$UID\" == x0 ]; then\n    USER=$CLICKHOUSE_UID\n    GROUP=$CLICKHOUSE_GID\n    gosu=\"gosu $USER:$GROUP\"\nelse\n    USER=\"$(id -u)\"\n    GROUP=\"$(id -g)\"\n    gosu=\"\"\n    DO_CHOWN=0\nfi\n\n# set some vars\n## 配置文件 /etc/clickhouse-server/config.xml\nCLICKHOUSE_CONFIG=\"${CLICKHOUSE_CONFIG:-/etc/clickhouse-server/config.xml}\"\n\n# port is needed to check if clickhouse-server is ready for connections\nHTTP_PORT=\"$(clickhouse extract-from-config --config-file $CLICKHOUSE_CONFIG --key=http_port)\"\n\n# get CH directories locations\nDATA_DIR=\"$(clickhouse extract-from-config --config-file $CLICKHOUSE_CONFIG --key=path || true)\"\nTMP_DIR=\"$(clickhouse extract-from-config --config-file $CLICKHOUSE_CONFIG --key=tmp_path || true)\"\nUSER_PATH=\"$(clickhouse extract-from-config --config-file $CLICKHOUSE_CONFIG --key=user_files_path || true)\"\nLOG_PATH=\"$(clickhouse extract-from-config --config-file $CLICKHOUSE_CONFIG --key=logger.log || true)\"\nLOG_DIR=\"$(dirname $LOG_PATH || true)\"\nERROR_LOG_PATH=\"$(clickhouse extract-from-config --config-file $CLICKHOUSE_CONFIG --key=logger.errorlog || true)\"\nERROR_LOG_DIR=\"$(dirname $ERROR_LOG_PATH || true)\"\nFORMAT_SCHEMA_PATH=\"$(clickhouse extract-from-config --config-file $CLICKHOUSE_CONFIG --key=format_schema_path || true)\"\nCLICKHOUSE_USER=\"${CLICKHOUSE_USER:-default}\"\n\nfor dir in \"$DATA_DIR\" \\\n  \"$ERROR_LOG_DIR\" \\\n  \"$LOG_DIR\" \\\n  \"$TMP_DIR\" \\\n  \"$USER_PATH\" \\\n  \"$FORMAT_SCHEMA_PATH\"\ndo\n    # check if variable not empty\n    [ -z \"$dir\" ] && continue\n    # ensure directories exist\n    if ! mkdir -p \"$dir\"; then\n        echo \"Couldn't create necessary directory: $dir\"\n        exit 1\n    fi\n\n    if [ \"$DO_CHOWN\" = \"1\" ]; then\n        # ensure proper directories permissions\n        chown -R \"$USER:$GROUP\" \"$dir\"\n    elif [ \"$(stat -c %u \"$dir\")\" != \"$USER\" ]; then\n        echo \"Necessary directory '$dir' isn't owned by user with id '$USER'\"\n        exit 1\n    fi\ndone\n\n\n\nif [ -n \"$(ls /docker-entrypoint-initdb.d/)\" ]; then\n    $gosu /usr/bin/clickhouse-server --config-file=$CLICKHOUSE_CONFIG &\n    pid=\"$!\"\n\n    # check if clickhouse is ready to accept connections\n    # will try to send ping clickhouse via http_port (max 12 retries, with 1 sec delay)\n    if ! wget --spider --quiet --tries=12 --waitretry=1 --retry-connrefused \"http://localhost:$HTTP_PORT/ping\" ; then\n        echo >&2 'ClickHouse init process failed.'\n        exit 1\n    fi\n\n    if [ ! -z \"$CLICKHOUSE_PASSWORD\" ]; then\n        printf -v WITH_PASSWORD '%s %q' \"--password\" \"$CLICKHOUSE_PASSWORD\"\n    fi\n\n    clickhouseclient=( clickhouse-client --multiquery -u $CLICKHOUSE_USER $WITH_PASSWORD )\n\n    echo\n    for f in /docker-entrypoint-initdb.d/*; do\n        case \"$f\" in\n            *.sh)\n                if [ -x \"$f\" ]; then\n                    echo \"$0: running $f\"\n                    \"$f\"\n                else\n                    echo \"$0: sourcing $f\"\n                    . \"$f\"\n                fi\n                ;;\n            *.sql)    echo \"$0: running $f\"; cat \"$f\" | \"${clickhouseclient[@]}\" ; echo ;;\n            *.sql.gz) echo \"$0: running $f\"; gunzip -c \"$f\" | \"${clickhouseclient[@]}\"; echo ;;\n            *)        echo \"$0: ignoring $f\" ;;\n        esac\n        echo\n    done\n\n    if ! kill -s TERM \"$pid\" || ! wait \"$pid\"; then\n        echo >&2 'Finishing of ClickHouse init process failed.'\n        exit 1\n    fi\nfi\n\n# if no args passed to `docker run` or first argument start with `--`, then the user is passing clickhouse-server arguments\nif [[ $# -lt 1 ]] || [[ \"$1\" == \"--\"* ]]; then\n    exec $gosu /usr/bin/clickhouse-server --config-file=$CLICKHOUSE_CONFIG \"$@\"\nfi\n\n# Otherwise, we assume the user want to run his own process, for example a `bash` shell to explore this image\nexec \"$@\"\n```\n\n### 2.4、local.Dockerfile文件\n\n​\t\t暂时保留，未发现使用该文件的地方\n\n### 2.5 server镜像打包\n\n​\t\t根据clickhouse-server的docker源代码发现Dockerfile、entrypoint.sh、docker_related_config.xml三个文件为docker必需文件，新建一个目录，只写入这三个文件后，对原生server镜像进行打包。\n\n​\t\t\t\t\t\t\t\t\t<img src=\"clickhouse的docker架构/1.png\" alt=\"镜像打包目录架构\" style=\"zoom:50%;\" />\n\n​\t\t上图为镜像打包准备目录的架构，确保docker服务启动后使用`docker build -t clickhouse-server-demo:1.0 .`打包镜像名为clickhouse-server-demo，tag为1.0的docker镜像。\n\n``` shell\n## 打包镜像\n[root... test-clickhouse]# docker build -t clickhouse-server-demo:1.0 .\nSending build context to Docker daemon 8.704 kB\nStep 1/19 : FROM ubuntu:18.04\n...\n\nSuccessfully built 16acf3ee797d\t\t\t\t\t\t\t## 当最终出现打包镜像成功表示docker build完成\n## 若打包失败处理方法(本次打包过程中从github下载源代码版本较新，官方deb包还未更新，出现过打包失败的情况)：\n[root... test-clickhouse]# docker build -t clickhouse-server-demo:1.0 .\n...\nE: Version '20.4.1.*' for 'clickhouse-common-static' was not found\nE: Version '20.4.1.*' for 'clickhouse-client' was not found\nE: Version '20.4.1.*' for 'clickhouse-server' was not found\nThe command '/bin/sh -c apt-get update     && apt-get install --yes --no-install-recommends         apt-transport-https         dirmngr         gnupg     && mkdir -p /etc/apt/sources.list.d     && apt-key adv --keyserver keyserver.ubuntu.com --recv E0C56BD4     && echo $repository > /etc/apt/sources.list.d/clickhouse.list     && apt-get update     && env DEBIAN_FRONTEND=noninteractive         apt-get install --allow-unauthenticated --yes --no-install-recommends             clickhouse-common-static=$version             clickhouse-client=$version             clickhouse-server=$version             locales             tzdata             wget     && rm -rf         /var/lib/apt/lists/*  \n\n### 以上报错表示clickhouse-server/client..未找到20.4.1.*的包，在执行Dockerfile中的/bin/sh -c apt-get update...命令执行失败\n#### 1. 通过`docker image ls`的命令看到并未打包镜像成功，其中image id为289a...\n[root... test-clickhouse]# docker image ls\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n<none>              <none>              9feb83a76f47        8 minutes ago       64.2 MB\nubuntu              18.04               4e5021d210f6        37 hours ago        64.2 MB\nhello-world         latest              fce289e99eb9        14 months ago       1.84 kB\n#### 2. 通过`docker run -it 9feb83a76f47 /bin/bash`进入目前已打包的镜像中，执行失败的命令，查看报错原因\n[root... test-clickhouse]# docker run -it 9feb83a76f47 /bin/bash\n## 进入后可通过执行命令查看打包失败原因\nroot@8974a71311f5:/# apt-get update     && apt-get install --yes --no-install-recommends         apt-transport-https         dirmngr         gnupg     && mkdir -p /etc/apt/sources.list.d     && apt-key adv --keyserver keyserver.ubuntu.com --recv E0C56BD4     && echo $repository > /etc/apt/sources.list.d/clickhouse.list     && apt-get update     && env DEBIAN_FRONTEND=noninteractive         apt-get install --allow-unauthenticated --yes --no-install-recommends             clickhouse-common-static=$version             clickhouse-client=$version             clickhouse-server=$version             locales             tzdata             wget     && rm -rf         /var/lib/apt/lists/*         /var/cache/debconf         /tmp/*     && apt-get clean\n...\nE: Unable to locate package clickhouse-common-static\nE: Unable to locate package clickhouse-client\nE: Unable to locate package clickhouse-server\n## 由执行结果看到是由于没有找到clickhouse-server/client/common-static这三个包，通过查看命令可以看到，安装这三个包时指定了版本为Dockerfile初始化的version值，可能是由于version版本过高导致\n### 可以通过不指定版本安装查看是否是由于版本过高导致，通过结果可以看到，会得到的版本是20.3.4.10\nroot@8974a71311f5:/# apt-get install --allow-unauthenticated --yes --no-install-recommends clickhouse-common-static\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  tzdata\nSuggested packages:\n  clickhouse-common-static-dbg\nThe following NEW packages will be installed:\n  clickhouse-common-static tzdata\n0 upgraded, 2 newly installed, 0 to remove and 0 not upgraded.\nNeed to get 117 MB of archives.\nAfter this operation, 397 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 tzdata all 2019c-0ubuntu0.18.04 [190 kB]\nGet:2 http://repo.yandex.ru/clickhouse/deb/stable main/ clickhouse-common-static 20.3.4.10 [116 MB]\n### 也可通过获取路径看到最新版的clickhouse-client等包为20.3.4.10，所以将Dockerfile中的version值改为20.3.4.*即可，或者在命令中不指定版本安装，默认打包最新的安装包即可。\n\n## 其他docker build过程中的报错也可通过该方法解决，启动镜像找到报错原因去解决问题即可。\n\n## 问题解决后，将已有镜像删除，重新进行打包\n### 由于当时只启动了关于该镜像的容器，所以可以直接全部stop掉，如果有其他启动的容器，则不能这样关闭\n[root... test-clickhouse]# docker stop $(docker ps -a -q)\n8974a71311f5\nfae466f31ccf\n[root... test-clickhouse]# docker rm fae466f31ccf\nfae466f31ccf\n[root... test-clickhouse]# docker rm 8974a71311f5\n8974a71311f5\n### 删除镜像\n[root... test-clickhouse]# docker rmi 9feb83a76f47\nDeleted: sha256:9feb83a76f4778aba0523c9e4bd492aa6804d1fa759558b8f93d8aa61ae6ac57\nDeleted: sha256:b99e0912ee05a0f2a581f061828a89b1b08d6485b5481bc3585e44a7c8f53857\nDeleted: sha256:227768fbfa5b173b32260e0cb38ef33d9495693593699c95b837f7b71a286064\n[root... test-clickhouse]# docker image ls        \nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nubuntu              18.04               4e5021d210f6        38 hours ago        64.2 MB\nhello-world         latest              fce289e99eb9        14 months ago       1.84 kB\n## 重新打包\n[root... test-clickhouse]# docker build -t clickhouse-server-demo:1.0 .\n```\n\n<img src=\"clickhouse的docker架构/2.png\" style=\"zoom:50%;\" />\t\t\n\n``` shell\n## 查看镜像\n[root... test-clickhouse]# docker image ls        \nREPOSITORY               TAG                 IMAGE ID            CREATED             SIZE\nclickhouse-server-demo   1.0                 16acf3ee797d        21 minutes ago      492 MB\nubuntu                   18.04               4e5021d210f6        3 days ago          64.2 MB\nhello-world              latest              fce289e99eb9        14 months ago       1.84 kB\n## 启动容器\n[root... test-clickhouse]# docker run -d --name clickhouse-test-server --ulimit nofile=262144:262144  --volume=/work/clickhouse/clickhouse-test-server:/var/lib/clickhouse  clickhouse-server-demo:1.0\n958ed2deaab03542f2880f41e66346165252f953f91efa60b7d95ad6a1a88330\n[root... test-clickhouse]# docker ps\nCONTAINER ID        IMAGE                        COMMAND             CREATED             STATUS              PORTS                          NAMES\n958ed2deaab0        clickhouse-server-demo:1.0   \"/entrypoint.sh\"    3 seconds ago       Up 3 seconds        8123/tcp, 9000/tcp, 9009/tcp   clickhouse-test-server\n## 进入容器\n[root... work]# docker exec -it 958e /bin/bash\n### 进入当前clickhouse\nroot@958ed2deaab0:/# clickhouse-client \nClickHouse client version 20.3.4.10 (official build).\nConnecting to localhost:9000 as user default.\nConnected to ClickHouse server version 20.3.4 revision 54433.\n\n958ed2deaab0 :) show databases;\n\nSHOW DATABASES\n\n┌─name────┐\n│ default │\n│ system  │\n└─────────┘\n\n2 rows in set. Elapsed: 0.002 sec. \n```\n\n## 三、client内容详解\n\n​\t\tclient目录下仅有Dockerfile以及README.md文件\n\n### 3.1、Dockerfile文件内容\n\n``` dockerfile\nFROM ubuntu:18.04\n\nARG repository=\"deb http://repo.yandex.ru/clickhouse/deb/stable/ main/\"\nARG version=20.4.1.*\n\nRUN apt-get update \\\n    && apt-get install --yes --no-install-recommends \\\n        apt-transport-https \\\n        dirmngr \\\n        gnupg \\\n    && mkdir -p /etc/apt/sources.list.d \\\n    && apt-key adv --keyserver keyserver.ubuntu.com --recv E0C56BD4 \\\n    && echo $repository > /etc/apt/sources.list.d/clickhouse.list \\\n    && apt-get update \\\n    && env DEBIAN_FRONTEND=noninteractive \\\n        apt-get install --allow-unauthenticated --yes --no-install-recommends \\\n            clickhouse-client=$version \\\n            clickhouse-common-static=$version \\\n            locales \\\n            tzdata \\\n    && rm -rf /var/lib/apt/lists/* /var/cache/debconf \\\n    && apt-get clean\n\nRUN locale-gen en_US.UTF-8\nENV LANG en_US.UTF-8\nENV LANGUAGE en_US:en\nENV LC_ALL en_US.UTF-8\n\nENTRYPOINT [\"/usr/bin/clickhouse-client\"]\n```\n\n","tags":["clickhouse","docker"],"categories":["clickhouse"]},{"title":"multiprocessing进程池与回调函数","url":"/2020/03/12/code/multiprocessing进程池与回调函数/","content":"\n## 一、研究背景\n\n​\t\t在利用python库multiprocessing进行多进程开发时，利用了进程池及apply_async异步非阻塞进行函数调用时，为了代码逻辑清晰以及代码块功能最小化，下一步的调用使用到了第一次apply_async的结果，将两个异步调用执行变成了同步执行，导致异步1min可以执行完成的程序变成了10min才执行完成，将优点变成了缺点。\n\n​\t\t这里将对源代码进行分析，并进行修改。\n\n**原本代码类似如下：**\n\n``` python\nfrom multiprocessing import Pool\n\ndef getA(info):\n    info['test1'] = 'test1'\n    info['test2'] = 'test2'\n    return info\n\ndef getB(info):\n    a = {}\n    a['test'] = info['test1'] + '_' + info['test2']\n    print(a)\n    return a\n\nif __name__ == '__main__':\n    try:\n        msg = 'success'\n        pool = Pool(4)\n        infoList = [{'a': 'a1', 'b': 'b1'}, {'a': 'a2', 'b': 'b2'}]\n        for info in infoList:\n            basicinfo = pool.apply_async(getA, (info, ))\n            baseinfo = basicinfo.get()\n            pool.apply_async(getB, (baseinfo, ))\n        pool.close()\n        pool.join()\n        print(msg)\n    except Exception as err:\n        print(err)\n```\n\n**执行结果：**\n\n``` python\n{'test': 'test1_test2'}\n{'test': 'test1_test2'}\nsuccess\n```\n\n\n\n## 二、原因分析\n\n​\t\tapply_async属于异步非阻塞模式，原本的代码使用了两次pool.apply_async()，并且第二次的apply_async需要利用第一次apply_async的结果，这就表示本来应该是两次异步同一时间执行两个函数，现在第二个函数需要等待第一个函数执行完之后再执行，产生了等待时间，从而将程序执行时长扩大。以下通过上述getA和getB示例详细描述原因：\n\n​\t\t\t\t\t\t\t\t<img src=\"multiprocessing进程池与回调函数/2.png\" style=\"zoom:50%;\" />\n\n​\t\t上图为apply_async方法适合用的场景，该场景两个调用函数并不关心对方的结果，getA与getB函数可以同时执行，到了t2时刻执行时间最长的getA函数执行结束，则该程序执行结束。\n\n​\t\t\t\t\t\t\t<img src=\"multiprocessing进程池与回调函数/3.png\" style=\"zoom:50%;\" />\n\n​\t\t而本次的需求实际为上图所示，虽然都使用了apply_async的异步模式，但getB函数需接收getA执行完成的结果，导致getB函数并没有和getA同时开始执行，getB从t1时刻就开始等待getA的执行结果，直到t2时刻getA执行完成返回结果之后，getB才开始执行，直到t3时刻执行结束。\n\n## 三、处理方法\n\n### 1、合并调用函数\n\n​\t\t该方法是将底层的getA和getB两个函数，合并为一个函数getC执行，之后使用一次apply_async执行即可。修改代码如下：\n\n``` python\nfrom multiprocessing import Pool\n\ndef getA(info):\n    info['test1'] = 'test1'\n    info['test2'] = 'test2'\n    return info\n\ndef getB(info):\n    a = {}\n    a['test'] = info['test1'] + '_' + info['test2']\n    return a\n\n# 可以添加一个合并了getA和getB函数的getC\ndef getC(info):\n    info_a = getA(info)\n    info_b = getB(info_a)\n    print(info_b)\n    return info_b\n\nif __name__ == '__main__':\n    try:\n        msg = 'success'\n        pool = Pool(4)\n        infoList = [{'a': 'a1', 'b': 'b1'}, {'a': 'a2', 'b': 'b2'}]\n        for info in infoList:\n            basicinfo = pool.apply_async(getC, (info, ))     # 直接调用getC\n        pool.close()\n        pool.join()\n        print(msg)\n    except Exception as err:\n        print(err)\n```\n\n**执行结果：**\n\n``` python\n{'test': 'test1_test2'}\n{'test': 'test1_test2'}\nsuccess\n```\n\n### 2、使用回调函数\n\n​\t\t另外一种方式是使用apply_async所包含的回调函数，回调函数的格式为`apply_async(func1, args=(input, ), callback=func2)`,意思就是将func1函数的返回传递给func2，并且由主进程继续执行func2函数，修改代码如下：\n\n``` python\nfrom multiprocessing import Pool\nimport  os\n\ndef getA(info):\n    info['test1'] = 'test1'\n    info['test2'] = 'test2'\n    print('getA pid', os.getpid())\n    return info\n\ndef getB(info):\n    a = {}\n    a['test'] = info['test1'] + '_' + info['test2']\n    print(a)\n    print('getB pid', os.getpid())\n    return a\n\nif __name__ == '__main__':\n    try:\n        print(\"主进程pid：\", os.getpid())\n        msg = 'success'\n        pool = Pool(4)\n        infoList = [{'a': 'a1', 'b': 'b1'}, {'a': 'a2', 'b': 'b2'}]\n        for info in infoList:\n            basicinfo = pool.apply_async(getA, args=(info, ), callback=getB)\t\t# 将getB看为回调函数\n        pool.close()\n        pool.join()\n        print(msg)\n    except Exception as err:\n        print(err)\n```\n\n**执行结果：**\n\n``` python\n主进程pid： 20006\ngetA pid 20007\ngetA pid 20008\n{'test': 'test1_test2'}\ngetB pid 20006\n{'test': 'test1_test2'}\ngetB pid 20006\nsuccess\n\n# 可以看到所有的getB函数都由主进程来完成\n```\n\n\n\n","tags":["multiprocessing","python"]},{"title":"ClickHouse的多种连接方式","url":"/2020/03/07/clickhouse/ClickHouse的多种连接方式/","content":"\n## 一、ClickHouse多种连接方式\n\nClickHouse官方以及一些第三方提供了[多种方式连接到服务端](https://clickhouse.tech/docs/zh/interfaces/)\n\n- 命令行接口：clickhouse-client\n- HTTP接口\n- MySQL客户端接口\n- C++客户端\n- JDBC驱动\n- ODBC驱动\n- 第三方提供\n  - 各种客户端库：Python/Go/Perl/Ruby/......\n  - 可视界面：Tabix/DataGrip/......\n  - 集成产品：puppet/Prometheus/Zabbix/......\n\n\n\n官方提供了许多方式连接到服务端，这里目前只测试了需要使用到的HTTP接口、MySQL客户端接口以及可视界面这几种方法，后续其他有需要再进行更新\n\n## 二、HTTP接口连接ClickHouse\n\n2.1、修改配置文件\n\n```shell\n# 默认官方rpm包、docker等安装后提供的http端口为8123，可根据需要修改配置文件，默认配置文件路径为'/etc/clickhouse-server/config.xml'\nvim /etc/clickhouse-server/config.xml\n    <http_port>8123</http_port>             ## 可将端口修改为需要的端口，重启clickhouse服务即可\n# 利用rpm包等进行安装的重启服务即可\n# 若利用docker安装需要在外部可以直接访问需要重新docker run并使用-p参数将容器端口映射到本地端口\ndocker run -d --name clickhouse-test-server --ulimit nofile=262144:262144 -p 8123:8123 --volume=/work/clickhouse/clickhouse_test_db:/var/lib/clickhouse yandex/clickhouse-server\n```\n\n2.2、通过http接口访问\n\n2.2.1、端口检查\n\n```shell\ncurl 'http://localhost:8123/'\n```\n\n2.2.2、接口使用\n\n```shell\n# select 示例\necho '1' | curl 'http://localhost:8123/?query=SELECT' --data-binary @-\n\ncurl 'http://localhost:8123/?query=SELECT%201'\n\n## 利用format指定输出格式\necho 'SELECT 1 FORMAT Pretty' | curl 'http://localhost:8123/?' --data-binary @-\n\n# 创建数据必须通过post接口实现\necho 'INSERT INTO t VALUES (1),(2),(3)' | POST 'http://localhost:8123/'\n```\n\n<img src=\"ClickHouse的多种连接方式/1.png\" style=\"zoom:33%;\" />\n\n## 三、MySQL客户端连接ClickHouse\n\n​        目前MySQL数据库使用率比较高，通过以下方法可以直接从MySQL客户端直接连接到ClickHouse\n\n3.1、修改配置文件\n\n``` shell\n# 在配置文件中新增mysql端口\nvim /etc/clickhouse-server/config.xml\n    <mysql_port>9004</mysql_port>            ## 开启mysql接口，但此时仅可以本地访问\n    ## 若需要其他ip访问，添加下面配置，并写入允许访问地址\n    <listen_host>::</listen_host>            ## 开启对应的可访问地址\n    \n# 配置完成后重启服务即可\n```\n\n3.2、MySQL连接ClickHouse\n\n```shell\nmysql --protocol tcp -u default -P 9004 -h[服务器ip]\n```\n\n<img src=\"ClickHouse的多种连接方式/2.png\" style=\"zoom:25%;\" />\n\n## 四、可视界面连接ClickHouse\n\n​        很多软件官方都提供了clickhouse的连接方法，仅对web页面tabix以及DataGrip连接做了测试，配置好的页面如下：\n\n其余方法可参考官方提供的入口：https://clickhouse.tech/docs/zh/interfaces/third-party/gui/\n\n4.1、tabix连接\n\n​\t**使用tabix连接必须打开ClickHouse的HTTP连接接口**\n\n​\t[tabix访问页面](http://ui.tabix.io/#!/login)\n\n​\t输入对应配置即可看到对应数据库界面：\n\n<img src=\"ClickHouse的多种连接方式/3.png\" style=\"zoom:25%;\" />\n\n<img src=\"ClickHouse的多种连接方式/4.png\" style=\"zoom:25%;\" />\n\n4.2、DataGrip连接测试\n\n​        和tabix连接类似，新增数据库类型为ClickHouse并输入配置参数连接即可，最终效果图如下：\n\n<img src=\"ClickHouse的多种连接方式/5.png\" style=\"zoom:33%;\" />","tags":["clickhouse"],"categories":["clickhouse"]},{"title":"利用docker安装启动ClickHouse","url":"/2020/03/07/clickhouse/利用docker安装启动ClickHouse/","content":"\n## 一、clickhouse简介\n\n​        ClickHouse是一个面向列存储的数据库管理系统，可以使用SQL查询实时生成分析数据报告，主要用于OLAP(在线分析处理查询)场景。关于clickhouse原理以及基础知识在以后学习中慢慢总结。(^_^)\n\n## 二、安装启动\n\n这里主要描述如何使用docker安装并启动clickhouse，其他安装方法均参考了官方文档: https://clickhouse.tech/docs/zh/getting_started/install/\n\n### 1、Debian/Ubuntu/RPM安装ClickHouse\n\n对于以上方法安装，官方均提供了安装包，直接通过`apt-get install`或`rpm -ivh`安装即可，安装包路径如下：\n\n```shell\n# Debian/Ubuntu\n## 安装包位置：https://repo.yandex.ru/clickhouse/deb/stable/main/\ndeb http://repo.yandex.ru/clickhouse/deb/stable/ main/\nsudo apt-get install dirmngr    # optional\nsudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv E0C56BD4    # optional\nsudo apt-get update\nsudo apt-get install clickhouse-client clickhouse-server\n\n# rpm安装\n## 安装包位置：https://repo.yandex.ru/clickhouse/rpm/stable/x86_64\nsudo yum install yum-utils\nsudo rpm --import https://repo.yandex.ru/clickhouse/CLICKHOUSE-KEY.GPG\nsudo yum-config-manager --add-repo https://repo.yandex.ru/clickhouse/rpm/stable/x86_64\nsudo yum install clickhouse-server clickhouse-client\n```\n\n### 2、docker安装ClickHouse\n\n#### 2.1 docker安装\n\nCentos安装docker参考于docker官方文档：https://docs.docker.com/install/linux/docker-ce/centos/\n\n2.1.1、卸载老版本docker\n\n```shel\nyum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine\n```\n\n2.1.2、安装依赖包并设置官方镜像源\n\n``` shel\nyum install -y yum-utils device-mapper-persistent-data lvm2\nyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n```\n\n2.1.3、安装最新版docker\n\n``` shel\nyum install docker-ce docker-ce-cli containerd.io\n```\n\n2.1.4、启动docker\n\n目前docker最新版本为19.03版本，安装该版本启动时(安装17.03版本并没有报错)有可能产生以下报错：\n\n``` shell\n# systemctl start docker\nA dependency job for docker.service failed. See 'journalctl -xe' for details.\n## 报错具体如下图：出现该报错的原因是，由于主机之前对/etc/group等文件进行过`chattr +i`加锁操作，导致docker安装时执行groupadd docker报错\n## 解决方法，对相关文件解锁之后，执行groupadd docker即可\n此时执行systemctl start docker即可成功启动\n\n启动完成后可利用官方提供的hello-world进行测试\ndocker run hello-world\n```\n\n<img src=\"利用docker安装启动ClickHouse/1.jpg\" style=\"zoom:50%;\" />\n\n#### 2.2 安装ClickHouse\n\n​        docker环境搭建好之后，利用docker安装clickhouse比较简单，clickhouse官方提供了默认的镜像，直接使用即可。官方文档参考：https://hub.docker.com/r/yandex/clickhouse-server/\n\n​\t\t目前正在研究如何根据源码包修改docker文件，安装之后得到想要的配置，预计下周出个文章详解^_^\n\n2.2.1、拉取clickhouse的docker镜像\n\n```shell\ndocker pull yandex/clickhouse-server\ndocker pull yandex/clickhouse-clinet\n```\n\n2.2.2、启动server端\n\n```shell\n# 默认直接启动即可\ndocker run -d --name [启动之后的名称] --ulimit nofile=262144:262144 yandex/clickhouse-server\n\n# 如果想指定目录启动，这里以clickhouse-test-server命令为例，可以随意写\nmkdir /work/clickhouse/clickhouse-test-db       ## 创建数据文件目录\n# 使用以下路径启动，在外只能访问clickhouse提供的默认9000端口，只能通过clickhouse-client连接server\ndocker run -d --name clickhouse-test-server --ulimit nofile=262144:262144 --volume=/work/clickhouse/clickhouse_test_db:/var/lib/clickhouse yandex/clickhouse-server\n```\n\n#### 2.3 启动并连接clickhouse-server\n\n2.3.1、docker启动clickhouse-client\n\n``` shell\ndocker run -it --rm --link clickhouse-test-server:clickhouse-server yandex/clickhouse-client --host clickhouse-server\n```\n\n<img src=\"利用docker安装启动ClickHouse/2.png\" style=\"zoom:50%;\" />\n\n2.3.2、使用clickhouse-client连接\n\n<img src=\"利用docker安装启动ClickHouse/3.png\" style=\"zoom:50%;\" />\n\n### 3、客户端常用参数\n\n```shell\nclickhouse-client\n    --host, -h     \t：服务端host名称，默认 localhost\n    --port         \t：连接端口，默认9000\n    --user, -u     \t：用户名，默认 default\n    --password     \t：密码，默认空\n    --query, -q    \t：非交互模式下的查询语句\n    --database, -d \t：默认当前操作的数据库，默认default\n    --multiline, -m ：允许多行语句查询，在clickhouse中默认回车即为sql结束，可使用该参数多行输入\n    --format, -f\t\t：使用指定的默认格式输出结果      csv,以逗号分隔\n    --time, -t\t\t\t：非交互模式下会打印查询执行的时间\n    --stacktrace\t\t：出现异常会打印堆栈跟踪信息\n    --config-file\t\t：配置文件名称\n```\n\n","tags":["clickhouse","docker"],"categories":["clickhouse"]},{"title":"利用github+hexo搭建个人博客","url":"/2020/02/26/other/利用github-hexo搭建个人博客/","content":"\n# 利用github+hexo搭建个人博客\n\n参考网页：\n\nhttps://pages.github.com/\n\nhttps://www.jianshu.com/p/3db6a61d3782\n\n\n\n搭建之前电脑所需安装软件：\n\n```\n- github账号\n- nodejs 安装包链接: https://nodejs.org/zh-cn/download/\n\tmac利用brew install node@12安装后，需通过brew info node@12得到写入环境变量的命令执行并重新导入环境变量使其生效\n```\n\n#### 1. 在本机创建github.io页面\n\n1.1、在自己的github账号上创建repository\n\n<img src=\"利用github-hexo搭建个人博客/createblog_github1.png\" style=\"zoom:25%;\" />\n\n1.2、 设置github page，设置如下图所示\n\n<img src=\"利用github-hexo搭建个人博客/createblog_github2.png\" style=\"zoom:25%;\" />\n\n#### 2. 安装hexo\n\n```\nnpm install -g hexo-cli --registry=https://registry.npm.taobao.org\n```\n\n#### 3. 初始化页面\n\n```\n# 在想要放置页面的目录下，初始化github上新建的repository：schnappi.github.io\nhexo init schnappi.github.io\n# 安装hexo index/archive/tag等插件\nnpm install -g hexo-deployer-git --registry=https://registry.npm.taobao.org\nnpm install --save hexo-generator-index  --registry=https://registry.npm.taobao.org\nnpm install --save hexo-generator-archive  --registry=https://registry.npm.taobao.org\nnpm install --save hexo-generator-tag  --registry=https://registry.npm.taobao.org\n# 安裝 hexo-deployer-git\nnpm install hexo-deployer-git --save --registry=https://registry.npm.taobao.org\n```\n\n#### 4. 修改配置文件\n\n```\n## 配置文件title等根据需要修改\n# Site\ntitle: Hexo\nsubtitle: ''\ndescription: ''\nkeywords:\nauthor: schnappi\nlanguage: zh\ntimezone: 'Asia/Shanghai'\n\n# url必须指向github.io的地址\nurl: https://schnappi.github.io\n\n## 与github共通刷新必须执行以下内容，其中repo为用户的schnappi.github.io上的github地址，可直接在github页面复制\n# Deployment\n## Docs: https://hexo.io/docs/deployment.html\ndeploy:\n  type: 'git'\n  repo: https://github.com/Schnappi618/schnappi618.github.io.git\n  branch: master\n```\n\n#### 5. 测试\n\n```\n# 在github目录下执行以下命令\n## 生成页面\nhexo gen\n## 本地测试\nhexo server\n\n执行完后，访问本地http://localhost:4000即可查看默认样式\n```\n\n<img src=\"利用github-hexo搭建个人博客/createblog_github3.png\" style=\"zoom:25%;\" />\n\n\n\n#### 6. 部署\n\n```\n# 执行以下命令进行推送\nhexo clean && hexo deploy\n```\n\n执行完成后，即可通过github page地址 https://schnappi.github.io 进行访问\n\n*之后需要将修改部署上去，执行以下命令即可*\n\n```\nhexo gen\nhexo clean && hexo deploy\n```\n\n\n\n#### 7. 其他配置\n\n1、修改默认主题\n\n```\n上图中显示的是hexo中默认的主题，若需要修改主题可以进入 https://hexo.io/themes 选择喜欢的主题\n\ncd schnappi.github.io/themes\ngit clone https://xxxx.git       # 将其主题clone下来即可\n```\n\n2、文章图片显示\n\n```\n# 下载hexo支持的插入图片插件\nnpm install https://github.com/7ym0n/hexo-asset-image --sa\n\n# 修改配置文件_config.yml\npost_asset_folder: true\n\n# 在之后通过hexo new post [name]创建新文件时，在source/_post目录下会生成一个和name同名的目录，将需要的图片放入其中\n文章中引用直接通过相对路径 name/xxx.png即可\n```\n\n\n\n\n\n\n","tags":["hexo"],"categories":["hexo"]},{"title":"Hello World","url":"/2020/02/22/other/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"}]